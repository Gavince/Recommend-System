{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多目标学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据\n",
    "### 人口普查数据简介\n",
    "\n",
    "\n",
    "数据集信息：\n",
    "```\n",
    "Barry Becker 从 1994 年人口普查数据库中提取。使用以下条件提取了一组合理干净的记录： ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "\n",
    "预测任务是确定一个人是否赚了超过 50K年。\n",
    "\n",
    ">50K，<=50K。\n",
    "属性列表：\n",
    "年龄：连续。\n",
    "工作班级：私人、Self-emp-not-inc、Self-emp-inc、联邦政府、地方政府、州政府、无薪、从未工作。\n",
    "fnlwgt：连续。\n",
    "教育：学士，一些大学，11th，HS-grad，教授学校，Assoc-acdm，Assoc-voc，9th，7th-8th，12th，硕士，1st-4th，10th，博士，5th-6th，学前班。\n",
    "教育编号：连续。\n",
    "婚姻状况：已婚公民配偶、离婚、未婚、分居、丧偶、已婚配偶缺席、已婚 AF 配偶。\n",
    "职业：技术支持、工艺维修、其他服务、销售、执行管理、专业教授、处理清洁工、机器操作检查、行政文员、农业-捕鱼、运输-搬家、私人住宅- serv，保护性服务，武装部队。\n",
    "关系：妻子、自己的孩子、丈夫、非家庭成员、其他亲属、未婚。\n",
    "种族：白人、亚太岛民、美洲印第安人-爱斯基摩人、其他、黑人。\n",
    "性别：女，男。\n",
    "资本收益：持续。\n",
    "资本损失：持续。\n",
    "每周小时数：连续。\n",
    "祖国：美国、柬埔寨、英国、波多黎各、加拿大、德国、美国边远地区（关岛-USVI-etc）、印度、日本、希腊、南部、中国、古巴、伊朗、洪都拉斯、菲律宾、意大利、波兰、牙买加、越南、墨西哥、葡萄牙、爱尔兰、法国、多米尼加共和国、老挝、厄瓜多尔、台湾、海地、哥伦比亚、匈牙利、危地马拉、尼加拉瓜、苏格兰、泰国、南斯拉夫、萨尔瓦多、特立纳达和多巴哥、秘鲁、香港，荷兰-荷兰。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult.data  adult.names  adult.test\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country income_50k  \n",
       "0          2174             0              40   United-States      <=50K  \n",
       "1             0             0              13   United-States      <=50K  \n",
       "2             0             0              40   United-States      <=50K  \n",
       "3             0             0              40   United-States      <=50K  \n",
       "4             0             0              40            Cuba      <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation',\n",
    "                'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "                'income_50k']\n",
    "train_df = pd.read_csv(\"./data/adult.data\", header=None, names=column_names)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education_num   32561 non-null  int64 \n",
      " 5   marital_status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital_gain    32561 non-null  int64 \n",
      " 11  capital_loss    32561 non-null  int64 \n",
      " 12  hours_per_week  32561 non-null  int64 \n",
      " 13  native_country  32561 non-null  object\n",
      " 14  income_50k      32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>|1x3 Cross validator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    age   workclass    fnlwgt      education  education_num  \\\n",
       "0  |1x3 Cross validator         NaN       NaN            NaN            NaN   \n",
       "1                    25     Private  226802.0           11th            7.0   \n",
       "2                    38     Private   89814.0        HS-grad            9.0   \n",
       "3                    28   Local-gov  336951.0     Assoc-acdm           12.0   \n",
       "4                    44     Private  160323.0   Some-college           10.0   \n",
       "\n",
       "        marital_status          occupation relationship    race    sex  \\\n",
       "0                  NaN                 NaN          NaN     NaN    NaN   \n",
       "1        Never-married   Machine-op-inspct    Own-child   Black   Male   \n",
       "2   Married-civ-spouse     Farming-fishing      Husband   White   Male   \n",
       "3   Married-civ-spouse     Protective-serv      Husband   White   Male   \n",
       "4   Married-civ-spouse   Machine-op-inspct      Husband   Black   Male   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country income_50k  \n",
       "0           NaN           NaN             NaN             NaN        NaN  \n",
       "1           0.0           0.0            40.0   United-States     <=50K.  \n",
       "2           0.0           0.0            50.0   United-States     <=50K.  \n",
       "3           0.0           0.0            40.0   United-States      >50K.  \n",
       "4        7688.0           0.0            40.0   United-States      >50K.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"./data/adult.test\", delimiter=\",\"\n",
    "                      , names=column_names\n",
    "                      , header=None\n",
    "                     )\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置标记\n",
    "train_df[\"tag\"] = 1\n",
    "test_df[\"tag\"] = 0\n",
    "# 划分数据\n",
    "test_df.dropna(inplace=True)\n",
    "# 规范化数据\n",
    "test_df[\"income_50k\"] = test_df[\"income_50k\"].apply(lambda x: x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "data = pd.concat([train_df, test_df])\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns = ['income_50k', 'marital_status']\n",
    "\n",
    "# categorical columns\n",
    "categorical_columns = ['workclass', 'education', 'occupation', 'relationship', 'race', 'sex', 'native_country']\n",
    "for col in label_columns:\n",
    "    if col == 'income_50k':\n",
    "        data[col] = data[col].apply(lambda x: 0 if x == ' <=50K' else 1)\n",
    "    else:\n",
    "        data[col] = data[col].apply(lambda x: 0 if x == ' Never-married' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engine\n",
    "for col in column_names:\n",
    "    if col not in label_columns + ['tag']:\n",
    "        if col in categorical_columns:\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "        else:\n",
    "            mm = MinMaxScaler()\n",
    "            data[col] = mm.fit_transform(data[[col]]).reshape(-1)\n",
    "            \n",
    "data = data[['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'occupation',\n",
    "             'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'income_50k', 'marital_status', 'tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码用户特征和物品特征\n",
    "user_feat_dict, item_feat_dict = dict(), dict()\n",
    "\n",
    "for idx, col in enumerate(data.columns):\n",
    "    if col not in label_columns + [\"tag\"]:\n",
    "        #　用户特征\n",
    "        if idx < 7:\n",
    "            if col in categorical_columns:\n",
    "                user_feat_dict[col] = (data[col].nunique() + 1, idx)\n",
    "            else:\n",
    "                user_feat_dict[col] = (1, idx)\n",
    "        # 物品特征\n",
    "        else:\n",
    "            if col in categorical_columns:\n",
    "                item_feat_dict[col] = (data[col].nunique() + 1, idx)\n",
    "            else:\n",
    "                item_feat_dict[col] = (1, idx)\n",
    "\n",
    "                user_feat_dict, item_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新划分数据集\n",
    "train_data, test_data = data[data[\"tag\"] == 1], data[data[\"tag\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gavin/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "train_data.drop(columns=\"tag\", inplace=True)\n",
    "test_data.drop(columns=\"tag\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import torchsnooper\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDateSet(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \n",
    "        self.features = data[0]\n",
    "        self.label1 = data[1]\n",
    "        self.label2 = data[2]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        return self.features[index], self.label1[index], self.label2[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Dataloader\n",
    "train_datasets = (train_data.iloc[:, :-2].values, train_data.iloc[:, -2].values, train_data.iloc[:, -1].values)\n",
    "test_datasets = (test_data.iloc[:, :-2].values, test_data.iloc[:, -2].values, test_data.iloc[:, -1].values)\n",
    "train_datasets = TrainDateSet(train_datasets)\n",
    "test_datasets = TrainDateSet(test_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESMM模型\n",
    "![](./imgs/ESMM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMM(nn.Module):\n",
    "\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, hidden_dim=[128, 64], dropouts=[0.5, 0.5],\n",
    "                 output_size=1, task_name=[\"ctr\", \"cvr\"]):\n",
    "        \"\"\"\n",
    "\n",
    "        :param user_feature_dict: 用户特征\n",
    "        :param item_feature_dict:　物品特征\n",
    "        :param emb_dim: 128\n",
    "        :param hidden_dim: [128, 64]\n",
    "        :param dropout: 0.5\n",
    "        :param output_size: 1\n",
    "        :param num_tasks:2\n",
    "        \"\"\"\n",
    "        super(ESMM, self).__init__()\n",
    "\n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            Exception(\"用户特征和物品特征不能为空！\")\n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict):\n",
    "            Exception(\"输入数据类型必须为字典类型！\")\n",
    "\n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "        self.num_tasks = len(task_name)\n",
    "        self.task_name = task_name\n",
    "\n",
    "        # 共享Embedding(Share bottom)\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "        \n",
    "        # 用户特征Embedding编码\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            # 必须为Spase Feature\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "                \n",
    "        # 物品特征\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # 构建独立任务（tower）\n",
    "        # Spase feat + Dense feat\n",
    "        hidden_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) \\\n",
    "                      + (len(self.user_feature_dict) - user_cate_feature_nums) \\\n",
    "                      + (len(self.item_feature_dict) - item_cate_feature_nums)\n",
    "\n",
    "        for i in range(self.num_tasks):\n",
    "            setattr(self, 'task_{}_dnn'.format(self.task_name[i]), nn.ModuleList())\n",
    "            hid_dim = [hidden_size] + hidden_dim\n",
    "            for j in range(len(hid_dim) - 1):\n",
    "                getattr(self, 'task_{}_dnn'.format(self.task_name[i])).add_module('hidden_{}'.format(j),\n",
    "                                                                      nn.Linear(hid_dim[j], hid_dim[j + 1]))\n",
    "                getattr(self, 'task_{}_dnn'.format(self.task_name[i])).add_module('batchnorm_{}'.format(j),\n",
    "                                                                      nn.BatchNorm1d(hid_dim[j + 1]))\n",
    "                getattr(self, \"task_{}_dnn\".format(self.task_name[i])).add_module(\"{}_activation\".format(task_name[i])\n",
    "                                                                             , nn.ReLU())\n",
    "                getattr(self, 'task_{}_dnn'.format(self.task_name[i])).add_module('dropout_{}'.format(j),\n",
    "                                                                      nn.Dropout(dropouts[j]))\n",
    "            getattr(self, 'task_{}_dnn'.format(self.task_name[i])).add_module('task_{}_last_layer'.format(j),\n",
    "                                                                  nn.Linear(hid_dim[-1], output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "#         assert x.size()[1] != len(self.item_feature_dict) + len(self.user_feature_dict)\n",
    "        # 编码Embedding向量\n",
    "        user_embed_list, item_embed_list = list(), list()\n",
    "        for user_feature, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_embed_list.append(getattr(self, user_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                user_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        for item_feature, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_embed_list.append(getattr(self, item_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                item_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        # 拼接向量\n",
    "        user_embed = torch.cat(user_embed_list, dim=1)\n",
    "        item_embed = torch.cat(item_embed_list, dim=1)\n",
    "        # hidden_input\n",
    "        hidden = torch.cat([user_embed, item_embed], axis=1).float()\n",
    "\n",
    "        # 子网络\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_tasks):\n",
    "            x = hidden\n",
    "            #　Module list\n",
    "            for mod in getattr(self,'task_{}_dnn'.format(self.task_name[i])):\n",
    "                x = mod(x)\n",
    "            task_outputs.append(x)\n",
    "        \n",
    "        if self.num_tasks == 2:\n",
    "            \n",
    "            pCTCVR = torch.mul(task_outputs[0], task_outputs[1])\n",
    "            pCVR = task_outputs[0]\n",
    "            \n",
    "            return pCTCVR, pCVR\n",
    "        \n",
    "        elif len(self.num_tasks) == 1:\n",
    "            return task_outputs\n",
    "        else:\n",
    "            Exception(\"目标数目为：1或２!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESMM(\n",
       "  (user_id): Embedding(11, 128)\n",
       "  (user_list): Embedding(12, 128)\n",
       "  (item_id): Embedding(8, 128)\n",
       "  (item_cate): Embedding(6, 128)\n",
       "  (task_ctr_dnn): ModuleList(\n",
       "    (hidden_0): Linear(in_features=514, out_features=128, bias=True)\n",
       "    (batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ctr_activation): ReLU()\n",
       "    (dropout_0): Dropout(p=0.5, inplace=False)\n",
       "    (hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "    (task_1_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (task_cvr_dnn): ModuleList(\n",
       "    (hidden_0): Linear(in_features=514, out_features=128, bias=True)\n",
       "    (batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cvr_activation): ReLU()\n",
       "    (dropout_0): Dropout(p=0.5, inplace=False)\n",
       "    (hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "    (task_1_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([[1, 2, 4, 2, 0.5, 0.1],\n",
    "                               [4, 5, 3, 8, 0.6, 0.43],\n",
    "                               [6, 3, 2, 9, 0.12, 0.32],\n",
    "                               [9, 1, 1, 1, 0.12, 0.45],\n",
    "                               [8, 3, 1, 4, 0.21, 0.67]]))\n",
    "\n",
    "user_cate_dict = {'user_id': (11, 0), 'user_list': (12, 3), 'user_num': (1, 4)}\n",
    "item_cate_dict = {'item_id': (8, 1), 'item_cate': (6, 2), 'item_num': (1, 5)}\n",
    "esmm = ESMM(user_cate_dict, item_cate_dict)\n",
    "esmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-1.4044],\n",
      "        [-0.4822],\n",
      "        [ 0.0017],\n",
      "        [ 0.0052],\n",
      "        [-0.4014]], grad_fn=<MulBackward0>), tensor([[-1.1930],\n",
      "        [ 0.6939],\n",
      "        [-0.7318],\n",
      "        [-0.2432],\n",
      "        [ 0.5550]], grad_fn=<AddmmBackward>))\n"
     ]
    }
   ],
   "source": [
    "tasks = esmm(a)\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = SummaryWriter(log_dir=\"./log\", comment=\"model info\")\n",
    "w.add_graph(esmm, a)\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMoE\n",
    "![](./imgs/mmoe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torchsnooper.snoop()\n",
    "class MMoE(nn.Module):\n",
    "\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, n_expert=3, mmoe_hidden_dim=128,\n",
    "                 hidden_dim=[128, 64], output_size=1, num_tasks=2, expert_activation=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param user_feature_dict:\n",
    "        :param item_feature_dict:\n",
    "        :param emb_dim:\n",
    "        :param n_expert:\n",
    "        :param mmoe_hidden_dim:\n",
    "        :param hidden_dim:\n",
    "        :param output_size:\n",
    "        :param num_tasks:\n",
    "        \"\"\"\n",
    "        super(MMoE, self).__init__()\n",
    "\n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            Exception(\"用户特征和物品特征不能为空！\")\n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict):\n",
    "            Exception(\"输入数据类型必须为字典类型！\")\n",
    "\n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        # 共享Embedding(Share bottom)\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "        # 用户特征Embedding编码\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            # 必须为Spase Feature\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "        # 物品特征\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # 构建独立任务（tower）\n",
    "        # Spase feat + Dense feat\n",
    "        hidden_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) \\\n",
    "                      + (len(self.user_feature_dict) - user_cate_feature_nums) \\\n",
    "                      + (len(self.item_feature_dict) - item_cate_feature_nums)\n",
    "\n",
    "        # 专家网络\n",
    "        self.erperts = torch.nn.Parameter(torch.rand(hidden_size, mmoe_hidden_dim, n_expert), requires_grad=True)\n",
    "        self.erperts.data.normal_(0, 1)\n",
    "        self.erperts_bias = torch.nn.Parameter(torch.rand(mmoe_hidden_dim, n_expert), requires_grad=True)\n",
    "\n",
    "        # 门控网络\n",
    "        self.gates = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(hidden_size, n_expert), requires_grad=True)\n",
    "                      for _ in range(num_tasks)])\n",
    "        for gate in self.gates:\n",
    "            gate.data.normal_(0, 1,)\n",
    "\n",
    "        self.gate_bias = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(n_expert), requires_grad=True) for _ in range(num_tasks)])\n",
    "\n",
    "        for i in range(self.num_tasks):\n",
    "            setattr(self, 'task_{}_dnn'.format(i + 1), nn.ModuleList())\n",
    "            # input: mmoe_hidden_dim + hidden_dim\n",
    "            hid_dim = [mmoe_hidden_dim] + hidden_dim\n",
    "            for j in range(len(hid_dim) - 1):\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('hidden_{}'.format(j),\n",
    "                                                                      nn.Linear(hid_dim[j], hid_dim[j + 1]))\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('batchnorm_{}'.format(j),\n",
    "                                                                      nn.BatchNorm1d(hid_dim[j + 1]))\n",
    "            getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('task_last_layer',\n",
    "                                                                  nn.Linear(hid_dim[-1], output_size))\n",
    "            \n",
    "        self.Softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        assert x.size()[1] == len(self.item_feature_dict) + len(self.user_feature_dict)\n",
    "        # 编码Embedding向量\n",
    "        user_embed_list, item_embed_list = list(), list()\n",
    "        for user_feature, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_embed_list.append(getattr(self, user_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                user_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        for item_feature, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_embed_list.append(getattr(self, item_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                item_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        # 拼接向量\n",
    "        user_embed = torch.cat(user_embed_list, dim=1)\n",
    "        item_embed = torch.cat(item_embed_list, dim=1)\n",
    "        # hidden_input\n",
    "        # B*hidden\n",
    "        hidden = torch.cat([user_embed, item_embed], dim=1).float()\n",
    "        # MMoE\n",
    "        expert_outs = torch.matmul(hidden, self.erperts.permute(1, 0, 2)).permute(1, 0, 2)  # B*mmoe_hidden_dim*experts\n",
    "        expert_outs += self.erperts_bias\n",
    "        # 门控单元\n",
    "        gates_out = list()\n",
    "        for idx, gate in enumerate(self.gates):\n",
    "            gate_out = torch.mm(hidden, gate)  # B * num_experts\n",
    "            if self.gate_bias:\n",
    "                gate_out += self.gate_bias[idx]\n",
    "            # 归一化\n",
    "            gate_out = self.Softmax(gate_out)\n",
    "            gates_out.append(gate_out)\n",
    "        # 各个模块\n",
    "        outs = list()\n",
    "        for gate_out in gates_out:\n",
    "            expand_gate_out = torch.unsqueeze(gate_out, dim=1)  # B * 1 * experts\n",
    "            weighted_expert_output = expert_outs * expand_gate_out.expand_as(expert_outs)  # B * mmoe_hidden * expert\n",
    "            outs.append(torch.sum(weighted_expert_output, 2))  # B * mmoe_hidden\n",
    "\n",
    "        # task_tower\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_tasks):\n",
    "            x = outs[i]\n",
    "            for mod in getattr(self, 'task_{}_dnn'.format(i + 1)):\n",
    "                x = mod(x)\n",
    "            task_outputs.append(x)\n",
    "\n",
    "        return task_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMoE(\n",
       "  (user_id): Embedding(11, 128)\n",
       "  (user_list): Embedding(12, 128)\n",
       "  (item_id): Embedding(8, 128)\n",
       "  (item_cate): Embedding(6, 128)\n",
       "  (gates): ParameterList(\n",
       "      (0): Parameter containing: [torch.FloatTensor of size 514x3]\n",
       "      (1): Parameter containing: [torch.FloatTensor of size 514x3]\n",
       "  )\n",
       "  (gate_bias): ParameterList(\n",
       "      (0): Parameter containing: [torch.FloatTensor of size 3]\n",
       "      (1): Parameter containing: [torch.FloatTensor of size 3]\n",
       "  )\n",
       "  (task_1_dnn): ModuleList(\n",
       "    (hidden_0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (task_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (task_2_dnn): ModuleList(\n",
       "    (hidden_0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (task_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (Softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmoe = MMoE(user_cate_dict, item_cate_dict)\n",
    "mmoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.1936],\n",
       "         [-0.5239],\n",
       "         [ 0.5940],\n",
       "         [ 0.3665],\n",
       "         [-0.0912]], grad_fn=<AddmmBackward>),\n",
       " tensor([[ 0.2057],\n",
       "         [ 0.2599],\n",
       "         [-0.3309],\n",
       "         [-0.3445],\n",
       "         [ 0.1629]], grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = mmoe(a)\n",
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = SummaryWriter(log_dir=\"./log\", comment=\"model info\")\n",
    "w.add_graph(esmm, a)\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-22 19:29:05.920514: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lcoal/cuda-10.1/lib64:\n",
      "2021-11-22 19:29:05.920554: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "W1122 19:29:16.926579 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:16.926889 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:16.941798 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:16.942142 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:16.990051 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:16.990489 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.079274 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.079512 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.097072 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.097378 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.102733 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.103089 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.162651 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.163057 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.197019 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.197279 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.270795 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.271105 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.287890 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.288157 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.332351 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.332605 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.348337 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.348788 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.381629 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.381914 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.588493 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.588711 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.589622 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.589900 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.667037 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.667348 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.701476 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.701812 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.735266 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.736076 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.842292 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.842545 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.862849 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.863187 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.885221 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.885431 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:17.903899 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:17.904243 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:18.031815 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:18.032038 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "W1122 19:29:18.032944 140120317765376 plugin_event_accumulator.py:320] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "W1122 19:29:18.033106 140120317765376 plugin_event_accumulator.py:358] Found more than one \"run metadata\" event with tag step1. Overwriting it with the newest event.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.4.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir ./log/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "count = 0\n",
    "writer = SummaryWriter(\"./log\", comment=\"mertics\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = MMoE(user_feat_dict, item_feat_dict)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr = learning_rate)\n",
    "loss_fun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_dataload = DataLoader(train_datasets, batch_size = 64, shuffle = True)\n",
    "test_dataload = DataLoader(test_datasets, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7134879486148624 0.8589090067395307 0.9182721976730421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:06<10:10,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6581966375603395 0.8767561784095812 0.9326415761314085\n",
      "0.6719974691600837 0.8717420003929226 0.9291301322352661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:11<09:27,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.670862022451326 0.8756476266288288 0.9347652694236518\n",
      "0.6594614575677396 0.8756502569887188 0.9330729396840634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:16<08:56,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6431583658152935 0.8800620010325142 0.9407865343838423\n",
      "0.6481030554106287 0.8770978822008122 0.9381252372630308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:21<08:47,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6369938169039931 0.8805162612616286 0.9439524365722732\n",
      "0.6327112291908451 0.878372615791444 0.9450717092172237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:25<08:14,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6145372372047574 0.8841828992821957 0.9539998644104557\n",
      "0.6129984452822822 0.8819975177155678 0.9520447211724097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:31<08:12,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6020808457159529 0.8856642685490291 0.9559097310233933\n",
      "0.6031981532723589 0.8846006531925581 0.9552584059516622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:36<08:10,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6065269106743383 0.8871708442925573 0.9572458529907353\n",
      "0.5966423655071521 0.8873194753822844 0.9562008455371342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:41<07:52,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6009359171577529 0.8886856270390743 0.9584637836968095\n",
      "0.5920291548276463 0.8885254320394541 0.9576879776756276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:46<07:33,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5917320820630766 0.8903621347909806 0.9604472388543173\n",
      "0.5871770969191328 0.890815965493801 0.9584202429585416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:50<07:14,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5918824527777877 0.8928483444122647 0.9604264898537387\n",
      "0.597069631918006 0.8844444128015174 0.9578501185554638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:54<06:55,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5857271664282855 0.8879804207045643 0.9599228388270231\n",
      "0.5882012526740727 0.8893357162520963 0.9588848191938792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:59<06:41,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5786383621832903 0.8926936659291864 0.9594545611986767\n",
      "0.5801289377840189 0.8943497280496799 0.9588654158560586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:03<06:29,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5711258086503721 0.8966299536581382 0.9604757411609173\n",
      "0.5765526722128592 0.8958253443541521 0.959559124759971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:07<06:20,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5742072131119522 0.8965570420163007 0.960804696800097\n",
      "0.5758752908360044 0.8963457759168986 0.9594951001630248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [01:12<06:13,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5789870921303244 0.8972899012462308 0.9616642534148223\n",
      "0.5720961389583783 0.8985082174273558 0.9599123660548228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [01:16<06:12,  4.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5673243423302968 0.8981047677773617 0.9615191461360424\n",
      "0.5767200903011914 0.8969289559196143 0.9590380456626129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [01:21<06:15,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5695473646416384 0.8985812339610594 0.9599789018461656\n",
      "0.571458490693499 0.8986316145239382 0.9598926760524741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:26<06:18,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.576927653130363 0.8991555359842058 0.9609567006191346\n",
      "0.5696167560598002 0.899577399252704 0.960079031527767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:30<06:09,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5644997853858799 0.8985419867136462 0.9616886500320194\n",
      "0.5688184966975439 0.9001408841130084 0.9599245813865709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:35<06:02,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5623557502148198 0.9005964870681679 0.9619821050303891\n",
      "0.5657414086675363 0.9016163430627079 0.9603571752734611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:39<05:58,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5639102150412166 0.9003427599910592 0.9619802048766157\n",
      "0.5652050966715297 0.9022331273378791 0.9603639418398917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:43<05:51,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5663874039462968 0.9014121586174263 0.9619516516730395\n",
      "0.5636013382076046 0.9026389040224626 0.9604558263782315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:48<05:45,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5637088349052504 0.9015424670062798 0.9613051073860028\n",
      "0.5643054437777851 0.9023661075980585 0.9604505508952031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:52<05:41,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5673334786704942 0.9010820802755714 0.9618347243533446\n",
      "0.5678452048414114 0.9014125608937174 0.9597813689227259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:57<05:45,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5709808607896169 0.8979505806689847 0.9598668776018322\n",
      "0.5664796483774316 0.9020793375539495 0.9598746889229925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [02:03<05:55,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5597550635244332 0.9017759536276102 0.9618067819134813\n",
      "0.5625866053732065 0.9032146573958394 0.9603330355530675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [02:07<05:48,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.560952916098576 0.9019047669827983 0.9615659204570521\n",
      "0.5630473503897842 0.9033175184048333 0.9604169384096641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [02:12<05:42,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.559250314913544 0.9020638260190641 0.9616622345014381\n",
      "0.5616538259978379 0.9037758464242185 0.9606343285290324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [02:16<05:31,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5653258394961264 0.9013843279907312 0.9614761721225794\n",
      "0.5625163927410816 0.9032063459683541 0.9604261694353198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [02:21<05:25,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5588048206824883 0.9021719911820196 0.9614413246596291\n",
      "0.5658829324606125 0.9022384645022079 0.9602149276282881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [02:26<05:22,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5637386310334299 0.9019303707411667 0.9612244526445883\n",
      "0.5628174183293738 0.9033843529097115 0.9602288928972291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [02:30<05:14,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5715660269353904 0.90178262377781 0.9605305572041464\n",
      "0.5659629859484014 0.9029971956799975 0.9596826408036045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [02:35<05:15,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5611193614847519 0.9026428954222906 0.9611516954172938\n",
      "0.5632050235285506 0.9032301529715392 0.9605891446372893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:39<05:01,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5628741932850257 0.901697574135374 0.9615892652034103\n",
      "0.5614604462809085 0.9037683320889408 0.9606115066097524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:44<05:04,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5591508630444022 0.9018142181256209 0.9616825084635734\n",
      "0.5605278467733874 0.9044653595592662 0.9608013705165807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:49<04:59,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5591440302484175 0.9023613168089248 0.9619334135899473\n",
      "0.5642950139603118 0.9022915910847843 0.960230135823279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [02:54<04:59,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.575007000507093 0.9030088232077735 0.9617669635125347\n",
      "0.5613171691861742 0.9040523471347399 0.9607444932792443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [02:59<04:54,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5644969845519346 0.9024510501931938 0.9615841924714618\n",
      "0.5605637835730269 0.9045726007060224 0.9604954331474063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [03:04<04:51,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5731830439146828 0.9033469935500275 0.9617310641787455\n",
      "0.5612844776779354 0.9041460815669358 0.9606340525609424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [03:08<04:43,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5571377619808795 0.9032654358044044 0.9611226417267864\n",
      "0.5609285147578871 0.9042100062983183 0.9604774182071868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [03:13<04:35,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5614533256081974 0.9022648610005517 0.9615115285552904\n",
      "0.5612814498439519 0.9038790943711773 0.9606930626679377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [03:18<04:34,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5651972228405522 0.9025317924659085 0.9616566188684116\n",
      "0.5596658104997722 0.9048875604706652 0.9607437145785864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [03:23<04:33,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5652201705119189 0.9027948661171215 0.9615519916512671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [03:24<04:31,  4.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-077aa7edadf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# 梯度更新\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    y_train_income_true = []\n",
    "    y_train_income_predict = []\n",
    "    y_train_marry_true = []\n",
    "    y_train_marry_predict = []\n",
    "    total_loss, count = 0, 0\n",
    "    for x, y1, y2 in train_dataload:\n",
    "        x, y1, y2 = x.to(device), y1.to(device), y2.to(device)\n",
    "        predict = model(x)\n",
    "        y_train_income_true += list(y1.squeeze().cpu().numpy())\n",
    "        y_train_marry_true += list(y2.squeeze().cpu().numpy())\n",
    "        y_train_income_predict += list(predict[0].squeeze().cpu().detach().numpy())\n",
    "        y_train_marry_predict += list(predict[1].squeeze().cpu().detach().numpy())\n",
    "        loss1 = loss_fun(predict[0], y1.unsqueeze(1).float())\n",
    "        loss2 = loss_fun(predict[1], y2.unsqueeze(1).float())\n",
    "        loss = loss1 + loss2\n",
    "        # 梯度更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "        count += 1\n",
    "    \n",
    "    y1_auc = roc_auc_score(y_train_income_true, y_train_income_predict)\n",
    "    y2_auc = roc_auc_score(y_train_marry_true, y_train_marry_predict)\n",
    "    loss_value = total_loss / count\n",
    "    print(loss_value, y1_auc, y2_auc)\n",
    "    writer.add_scalar(\"Train loss\", loss_value, global_step = epoch)\n",
    "    writer.add_scalar(\"Train_y1_auc\", y1_auc, global_step = epoch)\n",
    "    writer.add_scalar(\"Train_y2_auc\", y2_auc, global_step = epoch)\n",
    "    \n",
    "    # 验证\n",
    "    total_eval_loss = 0\n",
    "    model.eval()\n",
    "    count_eval = 0\n",
    "    y_val_income_true = []\n",
    "    y_val_marry_true = []\n",
    "    y_val_income_predict = []\n",
    "    y_val_marry_predict = []\n",
    "    for x, y1, y2 in test_dataload:\n",
    "        x, y1, y2 = x.to(device), y1.to(device), y2.to(device)\n",
    "        predict = model(x)\n",
    "        y_val_income_true += list(y1.squeeze().cpu().numpy())\n",
    "        y_val_marry_true += list(y2.squeeze().cpu().numpy())\n",
    "        y_val_income_predict += list(predict[0].squeeze().cpu().detach().numpy())\n",
    "        y_val_marry_predict += list(predict[1].squeeze().cpu().detach().numpy())\n",
    "        loss_1 = loss_fun(predict[0], y1.unsqueeze(1).float())\n",
    "        loss_2 = loss_fun(predict[1], y2.unsqueeze(1).float())\n",
    "        loss = loss_1 + loss_2\n",
    "        total_eval_loss += float(loss)\n",
    "        count_eval += 1\n",
    "        \n",
    "    y1_val_auc = roc_auc_score(y_val_income_true, y_val_income_predict)\n",
    "    y2_val_auc = roc_auc_score(y_val_marry_true, y_val_marry_predict)\n",
    "    print(total_eval_loss / count_eval, y1_val_auc, y2_val_auc)\n",
    "    writer.add_scalar(\"Val loss\",   total_eval_loss / count_eval, global_step = epoch + 1)\n",
    "    writer.add_scalar(\"Val_y1_auc\", y1_val_auc, global_step = epoch + 1)\n",
    "    writer.add_scalar(\"Val_y2_auc\", y2_val_auc, global_step = epoch + 1)\n",
    "    \n",
    "writer.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCELoss和BCEWithLogitsLoss的区别\n",
    "[BCELoss和BCEWithLogitsLoss](https://blog.csdn.net/qq_22210253/article/details/85222093)\n",
    "\n",
    "$$\n",
    "BCELoss = − n/1∑(y_{n}×lnx_{n}+(1−y_{n})×ln(1−x_{n}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = torch.rand(3, 3)\n",
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.FloatTensor([[0, 1, 1]\n",
    "                           , [0, 0, 1]\n",
    "                           , [1, 0, 1]])\n",
    "activation = nn.Sigmoid()\n",
    "predict = activation(input_)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "loss(predict, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid + BCEloss\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "loss(input_, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## einsum函数\n",
    "[一文学会 Pytorch 中的 einsum](https://zhuanlan.zhihu.com/p/361209187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = torch.tensor([[5],[3]])\n",
    "\n",
    "B = torch.tensor([[[0, 1, 0],\n",
    "              [1, 1, 0],\n",
    "\n",
    "              [1, 1, 1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum('ij,jkl->ikl', A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = B.permute(1, 0, 2)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(A, C).permute(1,0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Parameter的使用\n",
    "[pytorch学习笔记（十六）：Parameters](https://blog.csdn.net/qq_43328040/article/details/107761093?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.no_search_link&spm=1001.2101.3001.4242.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
