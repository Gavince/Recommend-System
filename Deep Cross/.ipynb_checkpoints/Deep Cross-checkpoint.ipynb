{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep&Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    \n",
    "    pass\n",
    "\n",
    "class DCN(BaseModel):\n",
    "    \"\"\"Instantiates the Deep&Cross Network architecture. Including DCN-V (parameterization='vector')\n",
    "    and DCN-M (parameterization='matrix').\n",
    "\n",
    "    :param linear_feature_columns: An iterable containing all the features used by linear part of the model.\n",
    "    :param dnn_feature_columns: An iterable containing all the features used by deep part of the model.\n",
    "    :param cross_num: positive integet,cross layer number\n",
    "    :param cross_parameterization: str, ``\"vector\"`` or ``\"matrix\"``, how to parameterize the cross network.\n",
    "    :param dnn_hidden_units: list,list of positive integer or empty list, the layer number and units in each layer of DNN\n",
    "    :param l2_reg_embedding: float. L2 regularizer strength applied to embedding vector\n",
    "    :param l2_reg_cross: float. L2 regularizer strength applied to cross net\n",
    "    :param l2_reg_dnn: float. L2 regularizer strength applied to DNN\n",
    "    :param init_std: float,to use as the initialize std of embedding vector\n",
    "    :param seed: integer ,to use as random seed.\n",
    "    :param dnn_dropout: float in [0,1), the probability we will drop out a given DNN coordinate.\n",
    "    :param dnn_use_bn: bool. Whether use BatchNormalization before activation or not DNN\n",
    "    :param dnn_activation: Activation function to use in DNN\n",
    "    :param task: str, ``\"binary\"`` for  binary logloss or  ``\"regression\"`` for regression loss\n",
    "    :param device: str, ``\"cpu\"`` or ``\"cuda:0\"``\n",
    "    :return: A PyTorch model instance.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, linear_feature_columns, dnn_feature_columns, cross_num=2, cross_parameterization='vector',\n",
    "                 dnn_hidden_units=(128, 128), l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_cross=0.00001,\n",
    "                 l2_reg_dnn=0, init_std=0.0001, seed=1024, dnn_dropout=0, dnn_activation='relu', dnn_use_bn=False,\n",
    "                 task='binary', device='cpu'):\n",
    "\n",
    "        super(DCN, self).__init__(linear_feature_columns=linear_feature_columns,\n",
    "                                  dnn_feature_columns=dnn_feature_columns, l2_reg_embedding=l2_reg_embedding,\n",
    "                                  init_std=init_std, seed=seed, task=task, device=device)\n",
    "        self.dnn_hidden_units = dnn_hidden_units\n",
    "        self.cross_num = cross_num\n",
    "\n",
    "        self.dnn = DNN(self.compute_input_dim(dnn_feature_columns), dnn_hidden_units,\n",
    "                       activation=dnn_activation, use_bn=dnn_use_bn, l2_reg=l2_reg_dnn, dropout_rate=dnn_dropout,\n",
    "                       init_std=init_std, device=device)\n",
    "\n",
    "        # 计算堆叠层的输入特征维度\n",
    "        if len(self.dnn_hidden_units) > 0 and self.cross_num > 0:\n",
    "            dnn_linear_in_feature = self.compute_input_dim(dnn_feature_columns) + dnn_hidden_units[-1]\n",
    "        elif len(self.dnn_hidden_units) > 0:\n",
    "            dnn_linear_in_feature = dnn_hidden_units[-1]\n",
    "        elif self.cross_num > 0:\n",
    "            dnn_linear_in_feature = self.compute_input_dim(dnn_feature_columns)\n",
    "\n",
    "        #  logistic层\n",
    "        self.dnn_linear = nn.Linear(dnn_linear_in_feature, 1, bias=False).to(\n",
    "            device)\n",
    "\n",
    "        #  crossnet\n",
    "        self.crossnet = CrossNet(in_features=self.compute_input_dim(dnn_feature_columns),\n",
    "                                 layer_num=cross_num, parameterization=cross_parameterization, device=device)\n",
    "        self.add_regularization_weight(\n",
    "            filter(lambda x: 'weight' in x[0] and 'bn' not in x[0], self.dnn.named_parameters()), l2_reg_dnn)\n",
    "        self.add_regularization_weight(self.dnn_linear.weight, l2_reg_linear)\n",
    "        self.add_regularization_weight(self.crossnet.kernels, l2_reg_cross)\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        logit = self.linear_model(X)\n",
    "        sparse_embedding_list, dense_value_list = self.input_from_feature_columns(X, self.dnn_feature_columns,\n",
    "                                                                                  self.embedding_dict)\n",
    "\n",
    "        dnn_input = combined_dnn_input(sparse_embedding_list, dense_value_list)\n",
    "\n",
    "        if len(self.dnn_hidden_units) > 0 and self.cross_num > 0:  # Deep & Cross\n",
    "            # DNN和Cross网络中输入相同的数据\n",
    "            deep_out = self.dnn(dnn_input)\n",
    "            cross_out = self.crossnet(dnn_input)\n",
    "            stack_out = torch.cat((cross_out, deep_out), dim=-1)\n",
    "            logit += self.dnn_linear(stack_out)\n",
    "        elif len(self.dnn_hidden_units) > 0:  # Only Deep\n",
    "            deep_out = self.dnn(dnn_input)\n",
    "            logit += self.dnn_linear(deep_out)\n",
    "        elif self.cross_num > 0:  # Only Cross\n",
    "            cross_out = self.crossnet(dnn_input)\n",
    "            logit += self.dnn_linear(cross_out)\n",
    "        else:  # Error\n",
    "            pass\n",
    "        y_pred = self.out(logit)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross网络\n",
    "意义：Cross可以辅助Deep，减小了Deep的“工作量”，通过特殊的cross layer设计，用更少的参数量有效捕获有意义的、DNN难以捕捉的特征相关性.  \n",
    "1) 有限高阶：叉乘阶数由网络深度决定，深度$L_c$对应最高 $L_c + 1$ 阶的叉乘\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{x}_{1} &=\\boldsymbol{x}_{0} \\boldsymbol{x}_{0}^{T} \\boldsymbol{w}_{0}+\\boldsymbol{x}_{0}=\\left[\\begin{array}{c}\n",
    "x_{0,1} \\\\\n",
    "x_{0,2}\n",
    "\\end{array}\\right]\\left[x_{0,1}, x_{0,2}\\right]\\left[\\begin{array}{c}\n",
    "w_{0,1} \\\\\n",
    "w_{0,2}\n",
    "\\end{array}\\right]+\\left[\\begin{array}{l}\n",
    "x_{0,1} \\\\\n",
    "x_{0,2}\n",
    "\\end{array}\\right]=\\left[\\begin{array}{l}\n",
    "w_{0,1} x_{0,1}^{2}+w_{0,2} x_{0,1} x_{0,2}+x_{0,1} \\\\\n",
    "w_{0,1} x_{0,2} x_{0,1}+w_{0,2} x_{0,2}^{2}+x_{0,2}\n",
    "\\end{array}\\right] \\\\\n",
    "\\boldsymbol{x}_{2} &=\\boldsymbol{x}_{0} \\boldsymbol{x}_{1}^{T} \\boldsymbol{w}_{1}+\\boldsymbol{x}_{1} \\\\\n",
    "&=\\left[\\begin{array}{l}\n",
    "w_{1,1} x_{0,1} x_{1,1}+w_{1,2} x_{0,1} x_{1,2}+x_{1,1} \\\\\n",
    "w_{1,1} x_{0,2} x_{1,1}+w_{1,2} x_{0,2} x_{1,2}+x_{1,2} \\\\\n",
    "\\end{array}\\right] \n",
    "\\left[\\begin{array}= & \\left.w_{0,1} w_{1,1} x_{0,1}^{3}+\\left(w_{0,2} w_{1,1}+w_{0,1} w_{1,2}\\right) x_{0,1}^{2} x_{0,2}+w_{0,2} w_{1,2} x_{0,1} x_{0,2}^{2}+\\left(w_{0,1}+w_{1,1}\\right) x_{0,1}^{2}+\\left(w_{0,2}+w_{1,2}\\right) x_{0,1} x_{0,2}+x_{0,1}\\right]\n",
    "\\end{array}\\right.\n",
    "\\end{aligned}\n",
    "$$  \n",
    "\n",
    "\n",
    "2) 自动叉乘：Cross输出包含了原始特征从一阶（即本身）到 $L_c + 1$阶的所有叉乘组合，而模型参数量仅仅随输入维度成线性增长： $2*L_c*d$\n",
    "\n",
    "3) 参数共享：不同叉乘项对应的权重不同，但并非每个叉乘组合对应独立的权重（指数数量级）， 通过参数共享，Cross有效降低了参数量。此外，参数共享还使得模型有更强的泛化性和鲁棒性。例如，如果独立训练权重，当训练集中$x_i!=0 and x_j!=0$这个叉乘特征没有出现 ，对应权重肯定是零，而参数共享则不会，类似地，数据集中的一些噪声可以由大部分正常样本来纠正权重参数的学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossNet(nn.Module):\n",
    "    \"\"\"The Cross Network part of Deep&Cross Network model,\n",
    "    which leans both low and high degree cross feature.\n",
    "      Input shape\n",
    "        - 2D tensor with shape: ``(batch_size, units)``.\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, units)``.\n",
    "      Arguments\n",
    "        - **in_features** : Positive integer, dimensionality of input features.\n",
    "        - **input_feature_num**: Positive integer, shape(Input tensor)[-1]\n",
    "        - **layer_num**: Positive integer, the cross layer number\n",
    "        - **l2_reg**: float between 0 and 1. L2 regularizer strength applied to the kernel weights matrix\n",
    "        - **seed**: A Python integer to use as random seed.\n",
    "      References\n",
    "        - [Wang R, Fu B, Fu G, et al. Deep & cross network for ad click predictions[C]//Proceedings of the ADKDD'17. ACM, 2017: 12.](https://arxiv.org/abs/1708.05123)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, layer_num=5, seed=1024, device='cpu'):\n",
    "        super(CrossNet, self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.kernels = torch.nn.ParameterList(\n",
    "            [nn.Parameter(nn.init.xavier_normal_(torch.empty(in_features, 1))) for i in range(self.layer_num)])\n",
    "        self.bias = torch.nn.ParameterList(\n",
    "            [nn.Parameter(nn.init.zeros_(torch.empty(in_features, 1))) for i in range(self.layer_num)])\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x_0 = inputs.unsqueeze(2)\n",
    "        print(x_0.shape)\n",
    "        x_l = x_0 # [B, d, 1]\n",
    "        for i in range(self.layer_num):\n",
    "            # 对应维度做点乘运算\n",
    "            # [B, d, 1] dot [d, 1] = [B, 1, 1]\n",
    "            xl_w = torch.tensordot(x_l, self.kernels[i], dims=([1], [0]))\n",
    "            print(xl_w.shape)\n",
    "            dot_ = torch.matmul(x_0, xl_w)\n",
    "            print(\"dot_\", dot_.shape)\n",
    "            x_l = dot_ + self.bias[i] + x_l\n",
    "            \n",
    "        x_l = torch.squeeze(x_l, dim=2)\n",
    "        return x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossNet(\n",
       "  (kernels): ParameterList(\n",
       "      (0): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "      (1): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "      (2): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "      (3): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "      (4): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "  )\n",
       "  (bias): ParameterList(\n",
       "      (0): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "      (1): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "      (2): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "      (3): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "      (4): Parameter containing: [torch.FloatTensor of size 100x1]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrossNet(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 100, 1])\n",
      "torch.Size([128, 1, 1])\n",
      "dot_ torch.Size([128, 100, 1])\n",
      "torch.Size([128, 1, 1])\n",
      "dot_ torch.Size([128, 100, 1])\n",
      "torch.Size([128, 1, 1])\n",
      "dot_ torch.Size([128, 100, 1])\n",
      "torch.Size([128, 1, 1])\n",
      "dot_ torch.Size([128, 100, 1])\n",
      "torch.Size([128, 1, 1])\n",
      "dot_ torch.Size([128, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "A  = CrossNet(100)(torch.rand((128, 100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考\n",
    "[Deep Cross Network (深度交叉网络, DCN) 介绍与代码分析](https://blog.csdn.net/Eric_1993/article/details/105600937)  \n",
    "[揭秘 Deep & Cross : 如何自动构造高阶交叉特征](https://zhuanlan.zhihu.com/p/55234968)  \n",
    "[【论文导读】Wide&Deep模型的进阶---Cross&Deep模型，附TF2.0复现代码](https://mp.weixin.qq.com/s/DkoaMaXhlgQv1NhZHF-7og)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensordot计算　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((1, 2, 1)) # 各个维度权重相乘再相加\n",
    "b = torch.rand((2, 1))\n",
    "c = torch.tensordot(a, b, dims=([1], [0]))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2487],\n",
       "         [0.1692]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4675],\n",
       "        [0.2660]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1613]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45963594999999996"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8825*0.5069+0.013*0.9459"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6680],\n",
       "         [0.4520]],\n",
       "\n",
       "        [[0.5840],\n",
       "         [0.1657]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((2, 2, 1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9874]],\n",
       "\n",
       "        [[0.5792]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand((2, 1, 1))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6596],\n",
       "         [0.4463]],\n",
       "\n",
       "        [[0.3383],\n",
       "         [0.0960]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16751391999999998"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3604*0.4648"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
