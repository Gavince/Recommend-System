{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "save_path = './temp_results/'\n",
    "offline = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取数据的时候，发现click_article_id是一个浮点数，所以将其转换成int类型\n",
    "trn_user_item_feats_df = pd.read_csv(save_path + 'trn_user_item_feats_df.csv')\n",
    "trn_user_item_feats_df['click_article_id'] = trn_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df = pd.read_csv(save_path + 'val_user_item_feats_df.csv')\n",
    "    val_user_item_feats_df['click_article_id'] = val_user_item_feats_df['click_article_id'].astype(int)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = pd.read_csv(save_path + 'tst_user_item_feats_df.csv')\n",
    "tst_user_item_feats_df['click_article_id'] = tst_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "# 做特征的时候为了方便，给测试集也打上了一个无效的标签，这里直接删掉就行\n",
    "del tst_user_item_feats_df['label']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>word_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>191890</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>1603305000</td>\n",
       "      <td>80</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.996221</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>191890</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>1600533000</td>\n",
       "      <td>54</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343551</td>\n",
       "      <td>0.992781</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>191890</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>1595980000</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343456</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>191890</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>1599786000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.996370</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343011</td>\n",
       "      <td>0.992780</td>\n",
       "      <td>213.500000</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>191890</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>1605934000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>0.995544</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342910</td>\n",
       "      <td>0.992766</td>\n",
       "      <td>244.500000</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180281</th>\n",
       "      <td>190410</td>\n",
       "      <td>255667</td>\n",
       "      <td>0.248752</td>\n",
       "      <td>12916156000</td>\n",
       "      <td>66</td>\n",
       "      <td>0.248752</td>\n",
       "      <td>0.248752</td>\n",
       "      <td>0.248752</td>\n",
       "      <td>0.248752</td>\n",
       "      <td>0.878177</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.024216</td>\n",
       "      <td>0.968344</td>\n",
       "      <td>206.333333</td>\n",
       "      <td>389</td>\n",
       "      <td>1507532356000</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180282</th>\n",
       "      <td>190814</td>\n",
       "      <td>223086</td>\n",
       "      <td>0.142165</td>\n",
       "      <td>49740944000</td>\n",
       "      <td>172</td>\n",
       "      <td>0.142165</td>\n",
       "      <td>0.142165</td>\n",
       "      <td>0.142165</td>\n",
       "      <td>0.142165</td>\n",
       "      <td>0.949023</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.251930</td>\n",
       "      <td>0.959082</td>\n",
       "      <td>189.375000</td>\n",
       "      <td>354</td>\n",
       "      <td>1457628889000</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180283</th>\n",
       "      <td>191418</td>\n",
       "      <td>337052</td>\n",
       "      <td>0.359244</td>\n",
       "      <td>166246000</td>\n",
       "      <td>12</td>\n",
       "      <td>0.359244</td>\n",
       "      <td>0.359244</td>\n",
       "      <td>0.359244</td>\n",
       "      <td>0.359244</td>\n",
       "      <td>0.985636</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0.130341</td>\n",
       "      <td>0.969127</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>437</td>\n",
       "      <td>1507731534000</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180284</th>\n",
       "      <td>193649</td>\n",
       "      <td>99177</td>\n",
       "      <td>0.637963</td>\n",
       "      <td>7058577000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.637963</td>\n",
       "      <td>0.637963</td>\n",
       "      <td>0.637963</td>\n",
       "      <td>0.637963</td>\n",
       "      <td>0.973198</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198660</td>\n",
       "      <td>0.950548</td>\n",
       "      <td>82.975000</td>\n",
       "      <td>223</td>\n",
       "      <td>1507297762000</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180285</th>\n",
       "      <td>196012</td>\n",
       "      <td>245343</td>\n",
       "      <td>0.199934</td>\n",
       "      <td>5432626000</td>\n",
       "      <td>91</td>\n",
       "      <td>0.199934</td>\n",
       "      <td>0.199934</td>\n",
       "      <td>0.199934</td>\n",
       "      <td>0.199934</td>\n",
       "      <td>0.900594</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047858</td>\n",
       "      <td>0.959771</td>\n",
       "      <td>217.625000</td>\n",
       "      <td>385</td>\n",
       "      <td>1501152580000</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180286 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id      sim0   time_diff0  word_diff0  \\\n",
       "0             0            191890  0.215748   1603305000          80   \n",
       "1            11            191890  0.068161   1600533000          54   \n",
       "2            31            191890 -0.023481   1595980000          28   \n",
       "3            86            191890  0.263226   1599786000          30   \n",
       "4            94            191890 -0.002702   1605934000           2   \n",
       "...         ...               ...       ...          ...         ...   \n",
       "180281   190410            255667  0.248752  12916156000          66   \n",
       "180282   190814            223086  0.142165  49740944000         172   \n",
       "180283   191418            337052  0.359244    166246000          12   \n",
       "180284   193649             99177  0.637963   7058577000           7   \n",
       "180285   196012            245343  0.199934   5432626000          91   \n",
       "\n",
       "         sim_max   sim_min   sim_sum  sim_mean     score  ...  click_country  \\\n",
       "0       0.215748  0.215748  0.215748  0.215748  0.996221  ...              1   \n",
       "1       0.068161  0.068161  0.068161  0.068161  0.996075  ...              1   \n",
       "2      -0.023481 -0.023481 -0.023481 -0.023481  0.995851  ...              1   \n",
       "3       0.263226  0.263226  0.263226  0.263226  0.996370  ...              1   \n",
       "4      -0.002702 -0.002702 -0.002702 -0.002702  0.995544  ...              1   \n",
       "...          ...       ...       ...       ...       ...  ...            ...   \n",
       "180281  0.248752  0.248752  0.248752  0.248752  0.878177  ...              1   \n",
       "180282  0.142165  0.142165  0.142165  0.142165  0.949023  ...              1   \n",
       "180283  0.359244  0.359244  0.359244  0.359244  0.985636  ...              1   \n",
       "180284  0.637963  0.637963  0.637963  0.637963  0.973198  ...              1   \n",
       "180285  0.199934  0.199934  0.199934  0.199934  0.900594  ...              1   \n",
       "\n",
       "        click_region  click_referrer_type  user_time_hob1  user_time_hob2  \\\n",
       "0                 25                    2        0.343715        0.992865   \n",
       "1                 25                    2        0.343551        0.992781   \n",
       "2                 25                    1        0.343456        0.992715   \n",
       "3                 25                    2        0.343011        0.992780   \n",
       "4                 25                    2        0.342910        0.992766   \n",
       "...              ...                  ...             ...             ...   \n",
       "180281            21                    7        0.024216        0.968344   \n",
       "180282            25                    5        0.251930        0.959082   \n",
       "180283            22                    5        0.130341        0.969127   \n",
       "180284            21                    1        0.198660        0.950548   \n",
       "180285            25                    1        0.047858        0.959771   \n",
       "\n",
       "          word_hbo  category_id  created_at_ts  words_count  is_cat_hab  \n",
       "0       266.000000          309  1506581786000          242           0  \n",
       "1       200.000000          309  1506581786000          242           0  \n",
       "2       218.000000          309  1506581786000          242           0  \n",
       "3       213.500000          309  1506581786000          242           0  \n",
       "4       244.500000          309  1506581786000          242           0  \n",
       "...            ...          ...            ...          ...         ...  \n",
       "180281  206.333333          389  1507532356000          143           0  \n",
       "180282  189.375000          354  1457628889000          275           0  \n",
       "180283  240.000000          437  1507731534000          182           0  \n",
       "180284   82.975000          223  1507297762000           41           0  \n",
       "180285  217.625000          385  1501152580000          145           0  \n",
       "\n",
       "[180286 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    \"\"\"变换为提交的格式\"\"\"\n",
    "    \n",
    "    recall_df = rank_results.sort_values(by=[\"user_id\", \"pred_score\"])\n",
    "    # 排序（由大到小）\n",
    "    recall_df[\"rank\"] = recall_df.groupby(\"user_id\")[\"pred_score\"].rank(ascending=False, method=\"first\")\n",
    "    # 为每一个用户推荐5篇新闻文章\n",
    "    tmp = recall_df.groupby(\"user_id\").apply(lambda x:x[\"rank\"].max())\n",
    "\n",
    "    assert tmp.min() > topk\n",
    "\n",
    "    # 获取排名前五的文章\n",
    "    submit = recall_df[recall_df[\"rank\"] <=topk].set_index([\"user_id\", \"rank\"]).unstack(-1).reset_index()\n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "\n",
    "    save_name = save_path + model_name + \"_\" + datetime.today().strftime(\"%m-%d\") + \".csv\"\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序结果归一化\n",
    "def norm_sim(sim_df, weight=0.0):\n",
    "\n",
    "    min_sim = sim_df.min()\n",
    "    max_sim = sim_df.max()\n",
    "    if max_sim == min_sim:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0)\n",
    "    else:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0 * (sim - min_sim) / (max_sim - min_sim))\n",
    "\n",
    "    sim_df = sim_df.apply(lambda sim: sim + weight)  # plus one\n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 传统机器学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB排序模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank数据\n",
    "trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model = val_user_item_feats_df.copy()\n",
    "\n",
    "tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>word_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>191890</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>1603305000</td>\n",
       "      <td>80</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.996221</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.0</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>191890</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>1600533000</td>\n",
       "      <td>54</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343551</td>\n",
       "      <td>0.992781</td>\n",
       "      <td>200.0</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>191890</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>1595980000</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343456</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>218.0</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>191890</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>1599786000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.996370</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343011</td>\n",
       "      <td>0.992780</td>\n",
       "      <td>213.5</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>191890</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>1605934000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>0.995544</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342910</td>\n",
       "      <td>0.992766</td>\n",
       "      <td>244.5</td>\n",
       "      <td>309</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id      sim0  time_diff0  word_diff0   sim_max  \\\n",
       "0        0            191890  0.215748  1603305000          80  0.215748   \n",
       "1       11            191890  0.068161  1600533000          54  0.068161   \n",
       "2       31            191890 -0.023481  1595980000          28 -0.023481   \n",
       "3       86            191890  0.263226  1599786000          30  0.263226   \n",
       "4       94            191890 -0.002702  1605934000           2 -0.002702   \n",
       "\n",
       "    sim_min   sim_sum  sim_mean     score  ...  click_country  click_region  \\\n",
       "0  0.215748  0.215748  0.215748  0.996221  ...              1            25   \n",
       "1  0.068161  0.068161  0.068161  0.996075  ...              1            25   \n",
       "2 -0.023481 -0.023481 -0.023481  0.995851  ...              1            25   \n",
       "3  0.263226  0.263226  0.263226  0.996370  ...              1            25   \n",
       "4 -0.002702 -0.002702 -0.002702  0.995544  ...              1            25   \n",
       "\n",
       "   click_referrer_type  user_time_hob1  user_time_hob2  word_hbo  category_id  \\\n",
       "0                    2        0.343715        0.992865     266.0          309   \n",
       "1                    2        0.343551        0.992781     200.0          309   \n",
       "2                    1        0.343456        0.992715     218.0          309   \n",
       "3                    2        0.343011        0.992780     213.5          309   \n",
       "4                    2        0.342910        0.992766     244.5          309   \n",
       "\n",
       "   created_at_ts  words_count  is_cat_hab  \n",
       "0  1506581786000          242           0  \n",
       "1  1506581786000          242           0  \n",
       "2  1506581786000          242           0  \n",
       "3  1506581786000          242           0  \n",
       "4  1506581786000          242           0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_rank_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义特征列\n",
    "lgb_cols = ['sim0', 'time_diff0', 'word_diff0','sim_max', 'sim_min', 'sim_sum', \n",
    "            'sim_mean', 'score','click_size', 'time_diff_mean', 'active_level',\n",
    "            'click_environment','click_deviceGroup', 'click_os', 'click_country', \n",
    "            'click_region','click_referrer_type', 'user_time_hob1', 'user_time_hob2',\n",
    "            'word_hbo', 'category_id', 'created_at_ts','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先排序\n",
    "trn_user_item_feats_df_rank_model.sort_values(by=\"user_id\", inplace=True)\n",
    "# 排序模型独有，优化只在所在空间内\n",
    "g_train = trn_user_item_feats_df_rank_model.groupby([\"user_id\"], as_index=False).count()[\"label\"].values\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model.sort_values(by=\"user_id\", inplace=True)\n",
    "    g_val = val_user_item_feats_df_rank_model.groupby([\"user_id\"], as_index=False).count()[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型定义\n",
    "lgb_rank = lgb.LGBMRanker(n_estimators=300, n_jobs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Model\n",
    "if offline:\n",
    "    lgb_ranker.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'], group=g_train,\n",
    "                eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                eval_group= [g_val], eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_rank.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model[\"label\"], group=g_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_rank.best_iteration_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_user_item_feats_df_rank_model[\"pred_score\"] = lgb_rank.predict(tst_user_item_feats_df_rank_model[lgb_cols], num_iteration=lgb_rank.best_iteration_)\n",
    "tst_user_item_feats_df_rank_model[[\"user_id\", \"click_article_id\", \"pred_score\"]].to_csv(save_path + \"lgb_ranker_score.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>123938</td>\n",
       "      <td>-4.050364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>123938</td>\n",
       "      <td>2.547849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>123938</td>\n",
       "      <td>-4.093964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200004</td>\n",
       "      <td>123938</td>\n",
       "      <td>3.312659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200006</td>\n",
       "      <td>123938</td>\n",
       "      <td>-4.059014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id  pred_score\n",
       "0   200000            123938   -4.050364\n",
       "1   200001            123938    2.547849\n",
       "2   200002            123938   -4.093964\n",
       "3   200004            123938    3.312659\n",
       "4   200006            123938   -4.059014"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_results = tst_user_item_feats_df_rank_model[[\"user_id\", \"click_article_id\", \"pred_score\"]]\n",
    "rank_results[\"click_article_id\"] = rank_results[\"click_article_id\"].astype(\"int\")\n",
    "rank_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(rank_results, model_name=\"lgb_ranker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold_users(trn_df, n=5):\n",
    "    \"\"\"对用户执行五折交叉验证\"\"\"\n",
    "    \n",
    "    user_ids = trn_df.user_id.unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    \n",
    "    return user_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在执行第1折交叉验证......\n",
      "[1]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[3]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[4]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[5]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[6]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[7]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[8]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[9]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[10]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[11]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[12]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[13]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[14]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[15]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[16]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[17]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[18]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[19]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[20]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[21]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[22]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[23]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[24]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[25]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[26]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[27]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[28]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[29]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[30]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[31]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[32]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[33]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[34]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[35]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[36]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[37]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[38]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[39]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[40]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[41]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[42]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[43]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[44]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[45]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[46]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[47]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[48]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[49]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[50]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[51]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "正在执行第2折交叉验证......\n",
      "[1]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[3]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[4]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[5]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[6]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[7]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[8]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[9]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[10]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[11]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[12]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[13]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[14]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[15]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[16]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[17]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[18]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[19]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[20]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[21]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[22]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[23]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[24]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[25]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[26]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[27]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[28]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[29]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[30]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[31]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[32]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[33]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[34]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[35]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[36]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[37]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[38]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[39]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[40]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[41]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[42]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[43]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[44]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[45]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[46]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[47]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[48]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[49]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[50]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "[51]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.999972\tvalid_0's ndcg@2: 0.99999\tvalid_0's ndcg@3: 0.99999\tvalid_0's ndcg@4: 0.99999\tvalid_0's ndcg@5: 0.99999\n",
      "正在执行第3折交叉验证......\n",
      "[1]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[3]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[4]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[5]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[6]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[7]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[8]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[9]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[10]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[11]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[12]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[13]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[14]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[15]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[16]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[17]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[18]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[19]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[20]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[21]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[22]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[23]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[24]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[25]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[26]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[27]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[28]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[29]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[30]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[31]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[32]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[33]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[34]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[35]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[36]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[37]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[38]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[39]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[40]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[41]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[42]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[43]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[44]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[45]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[46]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[47]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[48]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[49]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[50]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "[51]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.999944\tvalid_0's ndcg@2: 0.999979\tvalid_0's ndcg@3: 0.999979\tvalid_0's ndcg@4: 0.999979\tvalid_0's ndcg@5: 0.999979\n",
      "正在执行第4折交叉验证......\n",
      "[1]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[3]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[4]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[5]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[6]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[7]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[8]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[9]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[10]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[11]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[12]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[13]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[14]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[15]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[16]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[17]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[18]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[19]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[20]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[21]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[22]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[23]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[24]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[25]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[26]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[27]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[28]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[29]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[30]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[31]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[32]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[33]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[34]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[35]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[36]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[37]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[38]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[39]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[40]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[41]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[42]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[43]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[44]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[45]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[46]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[47]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[48]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[49]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[50]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[51]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "正在执行第5折交叉验证......\n",
      "[1]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[2]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[3]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[4]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[5]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[6]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[7]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[8]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[9]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[10]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[11]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[12]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[13]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[14]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[15]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[16]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[17]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[18]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[19]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[20]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[21]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[22]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[23]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[24]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[25]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[26]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[27]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[28]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[29]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[30]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[31]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[32]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[33]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[34]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[35]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[36]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[37]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[38]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[39]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[40]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[41]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[42]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[43]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[44]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[45]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[46]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[47]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[48]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[49]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[50]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "[51]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's ndcg@1: 0.999917\tvalid_0's ndcg@2: 0.999969\tvalid_0's ndcg@3: 0.999969\tvalid_0's ndcg@4: 0.999969\tvalid_0's ndcg@5: 0.999969\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证模型\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "sore_list = []\n",
    "score_df = trn_df[[\"user_id\", \"click_article_id\", \"label\"]]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    print(\"正在执行第{}折交叉验证......\".format(n_fold+1))\n",
    "    # 五折划分数据集\n",
    "    train_idx = trn_df[~trn_df[\"user_id\"].isin(valid_user)]\n",
    "    valid_idx = trn_df[trn_df[\"user_id\"].isin(valid_user)]\n",
    "    \n",
    "    # 训练集和验证集进行分组构建，利于排序\n",
    "    train_idx.sort_values(\"user_id\", inplace=True)\n",
    "    g_train = train_idx.groupby(\"user_id\", as_index=False).count()['label'].values\n",
    "    \n",
    "    valid_idx.sort_values(\"user_id\", inplace=True)\n",
    "    g_val = valid_idx.groupby(\"user_id\", as_index=False).count()['label'].values\n",
    "    \n",
    "    lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                        max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                        learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16)\n",
    "    \n",
    "    lgb_ranker.fit(train_idx[lgb_cols], train_idx['label'], group=g_train,\n",
    "                   eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], eval_group= [g_val], \n",
    "                   eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_ranker.predict(valid_idx[lgb_cols], num_iteration=lgb_ranker.best_iteration_)\n",
    "    \n",
    "    # 归一化\n",
    "    valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    valid_idx.sort_values(by=[\"user_id\", \"pred_score\"], inplace=True)\n",
    "    \n",
    "    # rank\n",
    "    valid_idx[\"pred_rank\"] = valid_idx.groupby(\"user_id\")[\"pred_score\"].rank(ascending=False, method=\"first\")\n",
    "    sore_list.append(valid_idx[[\"user_id\", \"click_article_id\", \"pred_score\", \"pred_rank\"]])\n",
    "    \n",
    "    # 线上验证,五折求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_ranker.predict(tst_user_item_feats_df_rank_model[lgb_cols], lgb_ranker.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接所有的验证集上的预测数据，构成stacking数据类型\n",
    "score_df_ = pd.concat(sore_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_ranker_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_ranker_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_results = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_ranker')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGB分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型及参数的定义\n",
    "lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=500, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 21, number of negative: 180265\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042669\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000008 seconds, init for row-wise cost 0.008362 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3786\n",
      "[LightGBM] [Info] Number of data points in the train set: 180286, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000116 -> initscore=-9.057661\n",
      "[LightGBM] [Info] Start training from score -9.057661\n",
      "[LightGBM] [Debug] Re-bagging, using 126322 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126119 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125822 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126015 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126073 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126450 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126148 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126297 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126294 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126197 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125887 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126284 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126470 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126422 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126114 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126593 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126395 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126270 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126170 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126314 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125893 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126306 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126012 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126755 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126359 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126584 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126178 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125815 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126156 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126262 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126041 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126163 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126207 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125888 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126312 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126183 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126043 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125862 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126280 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126127 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126659 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126371 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126200 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126212 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126405 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126211 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126139 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125846 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126287 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126129 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125950 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126010 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126376 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126107 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126368 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126085 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126217 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126434 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126043 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126577 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126133 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126220 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126315 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126259 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125990 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126164 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126135 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126304 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125960 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126109 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125715 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125949 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126138 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126136 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126013 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126195 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126143 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126219 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125923 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126050 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126537 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126185 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126042 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126140 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126210 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126085 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126355 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126036 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125730 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126293 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126433 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126410 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126115 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126439 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126299 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126196 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126094 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125690 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125999 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125916 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126087 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126214 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126305 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126208 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125978 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126270 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126161 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126016 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126345 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126152 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126207 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126193 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126229 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125580 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126159 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126321 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126431 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126141 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126394 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126336 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126189 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126223 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126261 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126138 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126073 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126356 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126103 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126280 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126183 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126147 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126038 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126144 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125977 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126417 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126119 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125957 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126658 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126293 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126300 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126259 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126317 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126288 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126344 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126191 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126205 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126293 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126458 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126256 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126351 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126446 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126329 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126159 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126397 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126227 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125556 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126068 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126020 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126278 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126008 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126325 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126174 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126405 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126252 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126039 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126441 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126132 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126277 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126384 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125929 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126250 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126082 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126389 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126047 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126505 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126198 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125948 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126207 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126140 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126245 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126174 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126083 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125960 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126183 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126498 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126151 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126262 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126451 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126342 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125864 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126354 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126243 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126110 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126277 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126349 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126342 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126209 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126138 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126026 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126577 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126047 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126086 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126158 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126390 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126162 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126446 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126243 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126171 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126179 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126106 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126258 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126127 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125993 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126236 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125914 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125905 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126474 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126439 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126214 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125789 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126390 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125975 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126205 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126053 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126263 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126320 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125973 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126538 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126449 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126454 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125961 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126467 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126368 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126219 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126084 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126101 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126189 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126318 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126029 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126198 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126161 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126093 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125979 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126081 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126521 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126102 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126125 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126408 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126484 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126517 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126425 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126618 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126227 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126623 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126414 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126007 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125798 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126292 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126030 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126331 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125901 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126100 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126316 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126344 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126178 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126209 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126375 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126008 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125996 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126018 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126239 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126317 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126112 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126341 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126428 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126215 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126409 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125885 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126283 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126264 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126112 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126203 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126307 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126383 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125994 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125974 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126276 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126313 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125866 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125921 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126060 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126409 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126535 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126377 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126314 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125968 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126091 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126002 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126283 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126194 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126274 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126191 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126434 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126327 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126382 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126559 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126172 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126373 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126287 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125944 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125933 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126460 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126180 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126339 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126350 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126207 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126219 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126279 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126369 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126474 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126400 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126071 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126226 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126633 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126003 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125747 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126013 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126199 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126187 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125867 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126030 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126372 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125813 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126354 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126104 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126407 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126219 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126490 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126198 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126068 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126202 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126068 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126426 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126013 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126497 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125910 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126208 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126042 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126285 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126102 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126294 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125932 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126559 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126228 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126314 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126081 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126414 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126173 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126081 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126391 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126381 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126125 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126306 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126096 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126219 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126648 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126272 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126097 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125934 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126290 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126153 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125952 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126286 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125853 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126006 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126217 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126152 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125921 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126394 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126234 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126289 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126041 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126230 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126041 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126399 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126191 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126286 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126181 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126416 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126083 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126168 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125943 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126114 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126425 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126379 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126143 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126405 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126304 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126190 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126075 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126284 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126233 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126163 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126645 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126346 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126144 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126490 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126307 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126029 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126237 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126106 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126075 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126027 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126456 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126433 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126372 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125904 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126346 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126265 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126070 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125864 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126044 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126077 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126135 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125929 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125663 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126453 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126105 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126239 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126224 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126120 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125928 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126137 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126110 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126218 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126361 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126098 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126045 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126383 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126224 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126016 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126505 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125990 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126039 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126216 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126376 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125967 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126258 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125997 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126278 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125994 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126241 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126647 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126043 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126164 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126301 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126128 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126349 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126253 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126278 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126471 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125802 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126190 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126193 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126582 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125907 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125910 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126222 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125805 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125951 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126185 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126721 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126105 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126142 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126058 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126403 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126031 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126137 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126179 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126321 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126236 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125848 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126266 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126229 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125965 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126386 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126141 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126207 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126443 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125878 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126545 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125891 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 125984 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126066 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126148 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Debug] Re-bagging, using 126284 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "if offline:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'],\n",
    "                    eval_set=[(val_user_item_feats_df_rank_model[lgb_cols], val_user_item_feats_df_rank_model['label'])], \n",
    "                    eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "else:\n",
    "    lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_cols], trn_user_item_feats_df_rank_model['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_user_item_feats_df['pred_score'] = lgb_Classfication.predict_proba(tst_user_item_feats_df[lgb_cols])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这里的排序结果保存一份，用户后面的模型融合\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_path + 'lgb_cls_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results['click_article_id'] = rank_results['click_article_id'].astype(int)\n",
    "submit(rank_results, topk=5, model_name='lgb_cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在执行第1折交叉验证......\n",
      "[LightGBM] [Info] Number of positive: 16, number of negative: 144216\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042686\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000009 seconds, init for row-wise cost 0.006024 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 3770\n",
      "[LightGBM] [Info] Number of data points in the train set: 144232, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000111 -> initscore=-9.106479\n",
      "[LightGBM] [Info] Start training from score -9.106479\n",
      "[LightGBM] [Debug] Re-bagging, using 100874 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 101017 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100562 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100680 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100921 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101126 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100840 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101064 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100980 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100982 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100647 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100967 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101114 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101340 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100870 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101305 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101122 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100998 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100964 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101106 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100694 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101084 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100785 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101352 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100998 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101305 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101056 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100611 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100942 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100966 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100756 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101127 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100869 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100611 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101188 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100971 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100763 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100883 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101106 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101004 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101252 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101066 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101006 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101023 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101032 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101071 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100957 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100700 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 101204 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100915 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "[LightGBM] [Debug] Re-bagging, using 100636 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025258\n",
      "正在执行第2折交叉验证......\n",
      "[LightGBM] [Info] Number of positive: 16, number of negative: 144209\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042647\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000009 seconds, init for row-wise cost 0.006089 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3749\n",
      "[LightGBM] [Info] Number of data points in the train set: 144225, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000111 -> initscore=-9.106430\n",
      "[LightGBM] [Info] Start training from score -9.106430\n",
      "[LightGBM] [Debug] Re-bagging, using 100870 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 101009 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100564 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100670 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100915 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101121 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100839 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101056 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100973 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100983 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100634 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100964 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101113 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101331 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100867 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101302 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101113 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101003 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100962 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101085 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100688 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101093 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100775 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101342 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100990 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101299 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101064 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100608 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100917 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100979 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100739 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101137 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100864 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100598 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101178 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100974 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100753 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100877 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101112 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100987 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101243 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101068 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101001 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101020 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101022 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101069 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100947 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100710 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 101185 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100914 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "[LightGBM] [Debug] Re-bagging, using 100627 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.0025253\n",
      "正在执行第3折交叉验证......\n",
      "[LightGBM] [Info] Number of positive: 17, number of negative: 144213\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042645\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000010 seconds, init for row-wise cost 0.004526 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 3766\n",
      "[LightGBM] [Info] Number of data points in the train set: 144230, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000118 -> initscore=-9.045833\n",
      "[LightGBM] [Info] Start training from score -9.045833\n",
      "[LightGBM] [Debug] Re-bagging, using 100873 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 101016 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100563 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100674 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100919 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101128 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100839 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101061 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100976 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100982 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100646 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100968 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101113 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101334 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100867 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101308 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101121 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101002 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100957 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101102 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100691 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101089 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100782 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101348 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100999 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101294 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101066 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100610 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100934 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100966 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100750 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101140 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100865 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100611 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101172 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100971 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100764 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100880 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101115 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101000 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101245 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101069 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101000 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101022 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101034 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101071 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100952 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100704 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 101196 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100918 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "[LightGBM] [Debug] Re-bagging, using 100634 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200708\n",
      "正在执行第4折交叉验证......\n",
      "[LightGBM] [Info] Number of positive: 17, number of negative: 144220\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042680\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000010 seconds, init for row-wise cost 0.004521 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 3765\n",
      "[LightGBM] [Info] Number of data points in the train set: 144237, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000118 -> initscore=-9.045882\n",
      "[LightGBM] [Info] Start training from score -9.045882\n",
      "[LightGBM] [Debug] Re-bagging, using 100878 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 101023 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100561 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100684 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100927 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101127 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100843 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101069 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100976 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100993 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100650 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100972 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101121 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101333 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100876 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101316 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101118 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100999 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100969 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101116 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100694 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101089 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100795 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101344 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101006 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101309 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101061 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100621 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100941 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100958 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100761 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101133 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100889 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100585 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101205 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100966 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100773 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100894 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101111 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100998 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101257 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101067 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101025 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101015 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101038 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101072 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100964 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100697 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 101204 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100928 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "[LightGBM] [Debug] Re-bagging, using 100635 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00200748\n",
      "正在执行第5折交叉验证......\n",
      "[LightGBM] [Info] Number of positive: 18, number of negative: 144202\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.042686\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000009 seconds, init for row-wise cost 0.004454 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Dense Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 3759\n",
      "[LightGBM] [Info] Number of data points in the train set: 144220, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000125 -> initscore=-8.988599\n",
      "[LightGBM] [Info] Start training from score -8.988599\n",
      "[LightGBM] [Debug] Re-bagging, using 100868 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Debug] Re-bagging, using 101003 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[2]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100558 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[3]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100673 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[4]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100909 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[5]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101118 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[6]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100835 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[7]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101052 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[8]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100971 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[9]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100978 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[10]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100632 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[11]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100961 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[12]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101103 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[13]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101333 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[14]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100868 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[15]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101296 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[16]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101107 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[17]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100995 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[18]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100958 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[19]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101078 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[20]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100693 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[21]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101090 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[22]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[23]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101337 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[24]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100987 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[25]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101302 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[26]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101053 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[27]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100602 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[28]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100918 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[29]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100971 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[30]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100740 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[31]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101135 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[32]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100861 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[33]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100599 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[34]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101166 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[35]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100979 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[36]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100749 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[37]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100869 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[38]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101104 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[39]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100987 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[40]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101238 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[41]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101082 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[42]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100985 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[43]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101025 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[44]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101013 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[45]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101057 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[46]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100945 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[47]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100703 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[48]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 101189 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[49]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100908 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[50]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "[LightGBM] [Debug] Re-bagging, using 100635 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 1 and max_depth = 1\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[51]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.5\tvalid_0's binary_logloss: 0.00149537\n"
     ]
    }
   ],
   "source": [
    "# 五折交叉验证，这里的五折交叉是以用户为目标进行五折划分\n",
    "#  这一部分与前面的单独训练和验证是分开的\n",
    "def get_kfold_users(trn_df, n=5):\n",
    "    user_ids = trn_df['user_id'].unique()\n",
    "    user_set = [user_ids[i::n] for i in range(n)]\n",
    "    return user_set\n",
    "\n",
    "k_fold = 5\n",
    "trn_df = trn_user_item_feats_df_rank_model\n",
    "user_set = get_kfold_users(trn_df, n=k_fold)\n",
    "\n",
    "score_list = []\n",
    "score_df = trn_df[['user_id', 'click_article_id', 'label']]\n",
    "sub_preds = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set):\n",
    "    print(\"正在执行第{}折交叉验证......\".format(n_fold+1))\n",
    "    train_idx = trn_df[~trn_df['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df[trn_df['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 模型及参数的定义\n",
    "    lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=100, subsample=0.7, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=2018, n_jobs= 16, verbose=10)  \n",
    "    # 训练模型\n",
    "    lgb_Classfication.fit(train_idx[lgb_cols], train_idx['label'],eval_set=[(valid_idx[lgb_cols], valid_idx['label'])], \n",
    "                          eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_Classfication.predict_proba(valid_idx[lgb_cols], \n",
    "                                                              num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "    # 对输出结果进行归一化 分类模型输出的值本身就是一个概率值不需要进行归一化\n",
    "    # valid_idx['pred_score'] = valid_idx[['pred_score']].transform(lambda x: norm_sim(x))\n",
    "    \n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    \n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_cols], \n",
    "                                                     num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    \n",
    "score_df_ = pd.concat(score_list, axis=0)\n",
    "score_df = score_df.merge(score_df_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_path + 'trn_lgb_cls_feats.csv', index=False)\n",
    "    \n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds / k_fold\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = tst_user_item_feats_df_rank_model['pred_score'].transform(lambda x: norm_sim(x))\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_path + 'tst_lgb_cls_feats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>pred_score</th>\n",
       "      <th>pred_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>123938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001</td>\n",
       "      <td>123938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200002</td>\n",
       "      <td>123938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200004</td>\n",
       "      <td>123938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200006</td>\n",
       "      <td>123938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949995</th>\n",
       "      <td>247562</td>\n",
       "      <td>304976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949996</th>\n",
       "      <td>240259</td>\n",
       "      <td>255640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949997</th>\n",
       "      <td>241876</td>\n",
       "      <td>324987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949998</th>\n",
       "      <td>244133</td>\n",
       "      <td>272312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949999</th>\n",
       "      <td>248440</td>\n",
       "      <td>272312</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id  pred_score  pred_rank\n",
       "0        200000            123938         1.0        1.0\n",
       "1        200001            123938         1.0        1.0\n",
       "2        200002            123938         1.0        1.0\n",
       "3        200004            123938         1.0        1.0\n",
       "4        200006            123938         1.0        1.0\n",
       "...         ...               ...         ...        ...\n",
       "949995   247562            304976         1.0       19.0\n",
       "949996   240259            255640         1.0       19.0\n",
       "949997   241876            324987         1.0       19.0\n",
       "949998   244133            272312         1.0       19.0\n",
       "949999   248440            272312         1.0       19.0\n",
       "\n",
       "[950000 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过用户日志数据，统计历史点击情况\n",
    "if offline:\n",
    "    all_data = pd.read_csv(\"./data/train_click_log.csv\")\n",
    "else:\n",
    "    trn_data = pd.read_csv(\"./data/train_click_log.csv\")\n",
    "    tst_data = pd.read_csv(\"./data/testA_click_log.csv\")\n",
    "    all_data = trn_data.append(tst_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364046"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"click_article_id\"].values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35380"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"click_article_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"click_article_id\"] = all_data[\"click_article_id\"].rank(method=\"dense\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2343, 16105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[29121, 6678]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[3222, 17493]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[5196, 3222]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4359, 3789]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id click_article_id\n",
       "                      list\n",
       "0       0    [2343, 16105]\n",
       "1       1    [29121, 6678]\n",
       "2       2    [3222, 17493]\n",
       "3       3     [5196, 3222]\n",
       "4       4     [4359, 3789]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 每一位用户的历史点击文章，作为DIN的输入\n",
    "hist_click_article = all_data[[\"user_id\", \"click_article_id\"]].groupby(\"user_id\").agg({list}).reset_index()\n",
    "hist_click_article.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_behavior_df = pd.DataFrame()\n",
    "hist_behavior_df[\"user_id\"] = hist_click_article[\"user_id\"]\n",
    "hist_behavior_df[\"hist_click_article_id\"] = hist_click_article[\"click_article_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>hist_click_article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[2343, 16105]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[29121, 6678]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[3222, 17493]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[5196, 3222]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4359, 3789]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id hist_click_article_id\n",
       "0        0         [2343, 16105]\n",
       "1        1         [29121, 6678]\n",
       "2        2         [3222, 17493]\n",
       "3        3          [5196, 3222]\n",
       "4        4          [4359, 3789]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_behavior_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计用户的历史点击文章的数量\n",
    "click_num = hist_behavior_df[\"hist_click_article_id\"].apply(lambda x: len(x))\n",
    "click_num.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy数据\n",
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df.copy()\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df.copy()\n",
    "else: \n",
    "    val_user_item_feats_df_din_model = None\n",
    "    \n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每一个用户制作一个用户历史特征数据\n",
    "trn_user_item_feats_df_din_model = trn_user_item_feats_df_din_model.merge(hist_behavior_df, on='user_id')\n",
    "\n",
    "if offline:\n",
    "    val_user_item_feats_df_din_model = val_user_item_feats_df_din_model.merge(hist_behavior_df, on='user_id')\n",
    "else:\n",
    "    val_user_item_feats_df_din_model = None\n",
    "\n",
    "tst_user_item_feats_df_din_model = tst_user_item_feats_df_din_model.merge(hist_behavior_df, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2\n",
       "1          2\n",
       "2          2\n",
       "3          2\n",
       "4          2\n",
       "          ..\n",
       "180281     8\n",
       "180282     8\n",
       "180283     9\n",
       "180284     6\n",
       "180285    40\n",
       "Name: length_name, Length: 180286, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理得到用户的真实点击次数\n",
    "\n",
    "trn_user_item_feats_df_din_model[\"length_name\"]  = trn_user_item_feats_df_din_model[\"hist_click_article_id\"].apply(lambda x: len(x))\n",
    "trn_user_item_feats_df_din_model[\"length_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'click_article_id', 'sim0', 'time_diff0', 'word_diff0',\n",
       "       'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'score', 'rank', 'label',\n",
       "       'click_size', 'time_diff_mean', 'active_level', 'click_environment',\n",
       "       'click_deviceGroup', 'click_os', 'click_country', 'click_region',\n",
       "       'click_referrer_type', 'user_time_hob1', 'user_time_hob2', 'word_hbo',\n",
       "       'category_id', 'created_at_ts', 'words_count', 'is_cat_hab',\n",
       "       'hist_click_article_id', 'length_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_din_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "# from deepctr_torch.models import DIN\n",
    "# from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names, DenseFeat\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepctr.models import DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import * \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把特征分开\n",
    "sparse_fea = ['user_id', 'click_article_id', 'category_id', 'click_environment', 'click_deviceGroup', \n",
    "              'click_os', 'click_country', 'click_region', 'click_referrer_type', 'is_cat_hab']\n",
    "\n",
    "# 行为特征\n",
    "behavior_fea = ['click_article_id']\n",
    "\n",
    "# 历史兴趣\n",
    "hist_behavior_fea = ['hist_click_article_id']\n",
    "\n",
    "dense_fea = ['sim0', 'time_diff0', 'word_diff0', 'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'score',\n",
    "             'rank','click_size','time_diff_mean','active_level','user_time_hob1','user_time_hob2',\n",
    "             'word_hbo','words_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id：维度不匹配, 其维度数据目180001， 最大索引199999，最小索引0\n",
      "click_article_id：维度不匹配, 其维度数据目214， 最大索引360826，最小索引12185\n",
      "category_id：维度不匹配, 其维度数据目85， 最大索引455，最小索引7\n",
      "click_environment：维度不匹配, 其维度数据目4， 最大索引4，最小索引1\n",
      "click_deviceGroup：维度不匹配, 其维度数据目5， 最大索引5，最小索引1\n",
      "click_os：维度不匹配, 其维度数据目9， 最大索引20，最小索引2\n"
     ]
    }
   ],
   "source": [
    "df = trn_user_item_feats_df_din_model\n",
    "\n",
    "# 检查数据的输入维度是否匹配\n",
    "\n",
    "for feat in sparse_fea:\n",
    "    max_index = df[feat].nunique()+1\n",
    "    feat_un = df[feat].unique()\n",
    "    raw2idx = {}\n",
    "    \n",
    "    if len(df[feat]) == df[feat].apply(lambda x: 0 <= x < max_index).sum():\n",
    "        continue\n",
    "    else:\n",
    "        print(feat + \"：维度不匹配, 其维度数据目{}， 最大索引{}，最小索引{}\".format(max_index, feat_un.max(), feat_un.min()))\n",
    "        \n",
    "        tmp = dict(zip(df[feat].values, df[feat].rank(method=\"dense\").astype(\"int\").values))\n",
    "        # 编码索引\n",
    "        raw2idx[feat] = tmp\n",
    "        df[feat] = df[feat].rank(method=\"dense\").astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>score</th>\n",
       "      <th>...</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>word_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "      <th>hist_click_article_id</th>\n",
       "      <th>length_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>1603305000</td>\n",
       "      <td>80</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.996221</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>266.0</td>\n",
       "      <td>47</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>[2343, 16105]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>1600533000</td>\n",
       "      <td>54</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.068161</td>\n",
       "      <td>0.996075</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343551</td>\n",
       "      <td>0.992781</td>\n",
       "      <td>200.0</td>\n",
       "      <td>47</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>[5196, 23679]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>108</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>1595980000</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>-0.023481</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343456</td>\n",
       "      <td>0.992715</td>\n",
       "      <td>218.0</td>\n",
       "      <td>47</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>[15942, 16656]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>108</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>1599786000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.263226</td>\n",
       "      <td>0.996370</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343011</td>\n",
       "      <td>0.992780</td>\n",
       "      <td>213.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>[23679, 1398]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>108</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>1605934000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.002702</td>\n",
       "      <td>0.995544</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342910</td>\n",
       "      <td>0.992766</td>\n",
       "      <td>244.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1506581786000</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>[21611, 4850]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id      sim0  time_diff0  word_diff0   sim_max  \\\n",
       "0        1               108  0.215748  1603305000          80  0.215748   \n",
       "1       11               108  0.068161  1600533000          54  0.068161   \n",
       "2       29               108 -0.023481  1595980000          28 -0.023481   \n",
       "3       77               108  0.263226  1599786000          30  0.263226   \n",
       "4       83               108 -0.002702  1605934000           2 -0.002702   \n",
       "\n",
       "    sim_min   sim_sum  sim_mean     score  ...  click_referrer_type  \\\n",
       "0  0.215748  0.215748  0.215748  0.996221  ...                    2   \n",
       "1  0.068161  0.068161  0.068161  0.996075  ...                    2   \n",
       "2 -0.023481 -0.023481 -0.023481  0.995851  ...                    1   \n",
       "3  0.263226  0.263226  0.263226  0.996370  ...                    2   \n",
       "4 -0.002702 -0.002702 -0.002702  0.995544  ...                    2   \n",
       "\n",
       "   user_time_hob1  user_time_hob2  word_hbo  category_id  created_at_ts  \\\n",
       "0        0.343715        0.992865     266.0           47  1506581786000   \n",
       "1        0.343551        0.992781     200.0           47  1506581786000   \n",
       "2        0.343456        0.992715     218.0           47  1506581786000   \n",
       "3        0.343011        0.992780     213.5           47  1506581786000   \n",
       "4        0.342910        0.992766     244.5           47  1506581786000   \n",
       "\n",
       "   words_count  is_cat_hab  hist_click_article_id  length_name  \n",
       "0          242           0          [2343, 16105]            2  \n",
       "1          242           0          [5196, 23679]            2  \n",
       "2          242           0         [15942, 16656]            2  \n",
       "3          242           0          [23679, 1398]            2  \n",
       "4          242           0          [21611, 4850]            2  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_din_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_din_feats_columns(df, dense_fea, sparse_fea, behavior_fea, hist_behavior_fea, emb_dim=32, max_len=100):\n",
    "    \"\"\"\n",
    "    数据准备函数:\n",
    "    df: 数据集\n",
    "    dense_fea: 数值型特征列\n",
    "    sparse_fea: 离散型特征列\n",
    "    behavior_fea: 用户的候选行为特征列\n",
    "    his_behavior_fea: 用户的历史行为特征列\n",
    "    embedding_dim: embedding的维度， 这里为了简单， 统一把离散型特征列采用一样的隐向量维度\n",
    "    max_len: 用户序列的最大长度\n",
    "    \"\"\"\n",
    "        \n",
    "    # 系数特征\n",
    "    \n",
    "    sparse_feature_columns = [SparseFeat(name=feat, vocabulary_size=df[feat].nunique()+1, embedding_dim=emb_dim) for feat in sparse_fea]\n",
    "    \n",
    "    # 稠密特征\n",
    "    dense_feature_columns = [DenseFeat(name=feat, dimension=1,) for feat in dense_fea]\n",
    "    \n",
    "    # 可变特征\n",
    "    varlen_feature_columns = [VarLenSparseFeat(SparseFeat(name=feat, vocabulary_size=35380+1\n",
    "                                                          , embedding_dim=emb_dim, embedding_name=\"click_article_id\"), maxlen=max_len, length_name=\"length_name\") for feat in hist_behavior_fea]\n",
    "    \n",
    "    dnn_featue_columns = sparse_feature_columns + dense_feature_columns + varlen_feature_columns\n",
    "    \n",
    "    # 构建数据为字典类型的格式\n",
    "    x = {}\n",
    "    for name in get_feature_names(dnn_featue_columns):\n",
    "        if name in hist_behavior_fea:\n",
    "            hist_list = [l for l in df[name]]\n",
    "            x[name] = pad_sequences(hist_list, maxlen=max_len, padding=\"post\")\n",
    "        else:\n",
    "            x[name] = df[name].values\n",
    "    \n",
    "    return x, dnn_featue_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 数据预处理\n",
    "# 稠密数据进行归一化操作\n",
    "MMS = MinMaxScaler()\n",
    "\n",
    "# 替换无群值\n",
    "trn_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "tst_user_item_feats_df_din_model.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "\n",
    "for feat in dense_fea:\n",
    "#     print(feat)\n",
    "    trn_user_item_feats_df_din_model[feat] = MMS.fit_transform(trn_user_item_feats_df_din_model[[feat]])\n",
    "    if val_user_item_feats_df_din_model is not None:\n",
    "        val_user_item_feats_df_din_model[feat] = MMS.fit_transform(val_user_item_feats_df_din_model[[feat]])\n",
    "        \n",
    "    tst_user_item_feats_df_din_model[feat] = MMS.fit_transform(tst_user_item_feats_df_din_model[[feat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练:x\n",
    "X_trn, dnn_feature_columns = get_din_feats_columns(trn_user_item_feats_df_din_model\n",
    "                                                   , dense_fea, sparse_fea, behavior_fea\n",
    "                                                   , hist_behavior_fea, max_len=50\n",
    "                                                  )\n",
    "# 训练:label\n",
    "trn_user_item_feats_df_din_model[\"label\"][1]= 1\n",
    "Y_trn = trn_user_item_feats_df_din_model[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_din_model[\"label\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='user_id', vocabulary_size=180001, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b433d00>, embedding_name='user_id', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_article_id', vocabulary_size=214, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b433af0>, embedding_name='click_article_id', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='category_id', vocabulary_size=85, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b4334f0>, embedding_name='category_id', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_environment', vocabulary_size=4, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b433a30>, embedding_name='click_environment', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_deviceGroup', vocabulary_size=5, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b41a580>, embedding_name='click_deviceGroup', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_os', vocabulary_size=9, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b41a730>, embedding_name='click_os', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_country', vocabulary_size=12, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b41a670>, embedding_name='click_country', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_region', vocabulary_size=29, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b41a4f0>, embedding_name='click_region', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='click_referrer_type', vocabulary_size=8, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b41ac40>, embedding_name='click_referrer_type', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='is_cat_hab', vocabulary_size=2, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b41adf0>, embedding_name='is_cat_hab', group_name='default_group', trainable=True),\n",
       " DenseFeat(name='sim0', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='time_diff0', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='word_diff0', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='sim_max', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='sim_min', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='sim_sum', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='sim_mean', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='score', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='rank', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='click_size', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='time_diff_mean', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='active_level', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='user_time_hob1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='user_time_hob2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='word_hbo', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='words_count', dimension=1, dtype='float32'),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_click_article_id', vocabulary_size=35381, embedding_dim=32, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7fa93b41aee0>, embedding_name='click_article_id', group_name='default_group', trainable=True), maxlen=50, combiner='mean', length_name='length_name', weight_name=None, weight_norm=True)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id voca_size: 180001\n",
      "click_article_id voca_size: 214\n",
      "category_id voca_size: 85\n",
      "click_environment voca_size: 4\n",
      "click_deviceGroup voca_size: 5\n",
      "click_os voca_size: 9\n",
      "click_country voca_size: 12\n",
      "click_region voca_size: 29\n",
      "click_referrer_type voca_size: 8\n",
      "is_cat_hab voca_size: 2\n"
     ]
    }
   ],
   "source": [
    "for feat in sparse_fea:\n",
    "    print(\"{} voca_size: {}\".format(feat, trn_user_item_feats_df_din_model[feat].nunique()+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>89994.516685</td>\n",
       "      <td>51967.609432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44977.25</td>\n",
       "      <td>89992.5</td>\n",
       "      <td>135000.75</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_article_id</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>113.819038</td>\n",
       "      <td>67.289505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>108.0</td>\n",
       "      <td>187.00</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>47.202772</td>\n",
       "      <td>25.547243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_environment</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>2.968145</td>\n",
       "      <td>0.193526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>1.486183</td>\n",
       "      <td>0.568238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_os</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>4.546776</td>\n",
       "      <td>2.581990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_country</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>1.300828</td>\n",
       "      <td>1.589765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_region</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>18.182599</td>\n",
       "      <td>7.093410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_referrer_type</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>2.069101</td>\n",
       "      <td>1.293896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_cat_hab</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count          mean           std  min       25%  \\\n",
       "user_id              180286.0  89994.516685  51967.609432  1.0  44977.25   \n",
       "click_article_id     180286.0    113.819038     67.289505  1.0     40.00   \n",
       "category_id          180286.0     47.202772     25.547243  1.0     18.00   \n",
       "click_environment    180286.0      2.968145      0.193526  1.0      3.00   \n",
       "click_deviceGroup    180286.0      1.486183      0.568238  1.0      1.00   \n",
       "click_os             180286.0      4.546776      2.581990  1.0      1.00   \n",
       "click_country        180286.0      1.300828      1.589765  1.0      1.00   \n",
       "click_region         180286.0     18.182599      7.093410  1.0     13.00   \n",
       "click_referrer_type  180286.0      2.069101      1.293896  1.0      1.00   \n",
       "is_cat_hab           180286.0      0.000000      0.000000  0.0      0.00   \n",
       "\n",
       "                         50%        75%       max  \n",
       "user_id              89992.5  135000.75  180000.0  \n",
       "click_article_id       108.0     187.00     213.0  \n",
       "category_id             47.0      73.00      84.0  \n",
       "click_environment        3.0       3.00       3.0  \n",
       "click_deviceGroup        1.0       2.00       4.0  \n",
       "click_os                 6.0       6.00       8.0  \n",
       "click_country            1.0       1.00      11.0  \n",
       "click_region            21.0      25.00      28.0  \n",
       "click_referrer_type      2.0       2.00       7.0  \n",
       "is_cat_hab               0.0       0.00       0.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_din_model[sparse_fea].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>89994.516685</td>\n",
       "      <td>51967.609432</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44977.25</td>\n",
       "      <td>89992.5</td>\n",
       "      <td>135000.75</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_article_id</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>113.819038</td>\n",
       "      <td>67.289505</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>108.0</td>\n",
       "      <td>187.00</td>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>47.202772</td>\n",
       "      <td>25.547243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>47.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_environment</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>2.968145</td>\n",
       "      <td>0.193526</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>1.486183</td>\n",
       "      <td>0.568238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_os</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>4.546776</td>\n",
       "      <td>2.581990</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_country</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>1.300828</td>\n",
       "      <td>1.589765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_region</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>18.182599</td>\n",
       "      <td>7.093410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>click_referrer_type</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>2.069101</td>\n",
       "      <td>1.293896</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_cat_hab</th>\n",
       "      <td>180286.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count          mean           std  min       25%  \\\n",
       "user_id              180286.0  89994.516685  51967.609432  1.0  44977.25   \n",
       "click_article_id     180286.0    113.819038     67.289505  1.0     40.00   \n",
       "category_id          180286.0     47.202772     25.547243  1.0     18.00   \n",
       "click_environment    180286.0      2.968145      0.193526  1.0      3.00   \n",
       "click_deviceGroup    180286.0      1.486183      0.568238  1.0      1.00   \n",
       "click_os             180286.0      4.546776      2.581990  1.0      1.00   \n",
       "click_country        180286.0      1.300828      1.589765  1.0      1.00   \n",
       "click_region         180286.0     18.182599      7.093410  1.0     13.00   \n",
       "click_referrer_type  180286.0      2.069101      1.293896  1.0      1.00   \n",
       "is_cat_hab           180286.0      0.000000      0.000000  0.0      0.00   \n",
       "\n",
       "                         50%        75%       max  \n",
       "user_id              89992.5  135000.75  180000.0  \n",
       "click_article_id       108.0     187.00     213.0  \n",
       "category_id             47.0      73.00      84.0  \n",
       "click_environment        3.0       3.00       3.0  \n",
       "click_deviceGroup        1.0       2.00       4.0  \n",
       "click_os                 6.0       6.00       8.0  \n",
       "click_country            1.0       1.00      11.0  \n",
       "click_region            21.0      25.00      28.0  \n",
       "click_referrer_type      2.0       2.00       7.0  \n",
       "is_cat_hab               0.0       0.00       0.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trn = X_trn.copy()\n",
    "x_trn.pop(\"hist_click_article_id\")\n",
    "\n",
    "pd.DataFrame(x_trn)[sparse_fea].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建模评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/kernel:0' shape=(40, 1) dtype=float32>\n",
      "  <tf.Variable 'attention_sequence_pooling_layer/local_activation_unit/bias:0' shape=(1,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    }
   ],
   "source": [
    "# # 模型建立\n",
    "# import torch\n",
    "# device = 'cpu'\n",
    "# use_cuda = False\n",
    "\n",
    "# if use_cuda and torch.cuda.is_available():\n",
    "#     print('cuda ready...')\n",
    "#     device = 'cuda:0'\n",
    "    \n",
    "model = DIN(dnn_feature_columns, history_feature_list=behavior_fea, seed=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7fa9393e49a0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2343, 16105,     0, ...,     0,     0,     0],\n",
       "       [ 5196, 23679,     0, ...,     0,     0,     0],\n",
       "       [15942, 16656,     0, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [15979, 28355,  2456, ...,     0,     0,     0],\n",
       "       [24211,  9215,  9214, ...,     0,     0,     0],\n",
       "       [ 5846,  5224, 28702, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trn[\"hist_click_article_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "705/705 [==============================] - 45s 64ms/step - loss: 0.0104 - binary_crossentropy: 0.0104\n",
      "Epoch 2/10\n",
      "177/705 [======>.......................] - ETA: 32s - loss: 3.2455e-04 - binary_crossentropy: 2.9636e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-734e9d935895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"binary_crossentropy\"])\n",
    "model.fit(x=X_trn, y=Y_trn, epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     1,     11,     29, ..., 166040, 171342, 174255])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_din_model[\"user_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_trn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识点\n",
    "[torch.nn.Embedding的使用](https://blog.csdn.net/weixin_43532000/article/details/104429609?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1.control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-6dda0ec798cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_data = torch.tensor([[1,1,2,2,2,3,4,2,3,1,2,2,2],\n\u001b[0m\u001b[1;32m      2\u001b[0m \t\t\t[4,3,2,5,3,2,7,7,3,6,3,2,3]]\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = torch.tensor([[1,1,2,2,2,3,4,2,3,1,2,2,2],\n",
    "\t\t\t[4,3,2,5,3,2,7,7,3,6,3,2,3]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-8468f3588345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-d9b03476d8f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-0ce2c05765e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_data.unique())+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-c2862c589ed5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "embedd=nn.Embedding(len(train_data.unique())+2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5020,  0.5123, -0.4282, -0.8447, -0.5466],\n",
       "         [ 0.5020,  0.5123, -0.4282, -0.8447, -0.5466],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [-0.0121, -2.9470, -0.9865,  0.1426,  0.6155],\n",
       "         [-0.8315,  1.9206,  0.1890,  0.0061,  0.9114],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [-0.0121, -2.9470, -0.9865,  0.1426,  0.6155],\n",
       "         [ 0.5020,  0.5123, -0.4282, -0.8447, -0.5466],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698]],\n",
       "\n",
       "        [[-0.8315,  1.9206,  0.1890,  0.0061,  0.9114],\n",
       "         [-0.0121, -2.9470, -0.9865,  0.1426,  0.6155],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [ 1.4615,  0.2073,  1.0874, -1.0680,  0.6290],\n",
       "         [-0.0121, -2.9470, -0.9865,  0.1426,  0.6155],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [ 0.4230,  0.0837,  1.0295, -0.3290,  0.0098],\n",
       "         [ 0.4230,  0.0837,  1.0295, -0.3290,  0.0098],\n",
       "         [-0.0121, -2.9470, -0.9865,  0.1426,  0.6155],\n",
       "         [ 0.4656, -1.1798, -1.0277,  0.2871, -0.5350],\n",
       "         [-0.0121, -2.9470, -0.9865,  0.1426,  0.6155],\n",
       "         [ 0.1316, -2.2351,  0.7376, -1.4687,  0.5698],\n",
       "         [-0.0121, -2.9470, -0.9865,  0.1426,  0.6155]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_put = embedd(train_data)\n",
    "out_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 5])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_put.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 0, 1, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "\n",
    "# Let's say you have 2 sentences(lowercased, punctuations removed) :\n",
    "sentences = \"i am new to PyTorch i am having fun\"\n",
    "words = sentences.split(' ')\n",
    "\n",
    "vocab = Counter(words)  # create a dictionary\n",
    "vocab = sorted(vocab, key=vocab.get, reverse=True)\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# map words to unique indices\n",
    "word2idx = {word: ind for ind, word in enumerate(vocab)}\n",
    "\n",
    "# word2idx = {'i': 0, 'am': 1, 'new': 2, 'to': 3, 'pytorch': 4, 'having': 5, 'fun': 6}\n",
    "\n",
    "encoded_sentences = [word2idx[word] for word in words]\n",
    "\n",
    "# encoded_sentences = [0, 1, 2, 3, 4, 0, 1, 5, 6]\n",
    "print(encoded_sentences)\n",
    "# let's say you want embedding dimension to be 3\n",
    "emb_dim = 3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.51319199744696"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
