{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMM(nn.Module):\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, hidden_dim=[128, 64], dropouts=[0.5, 0.5],\n",
    "                 output_size=1, num_task=2):\n",
    "        \"\"\"\n",
    "        esmm model input parameters\n",
    "        :param user_feature_dict: user feature dict include: {feature_name: (feature_unique_num, feature_index)}\n",
    "        :param item_feature_dict: item feature dict include: {feature_name: (feature_unique_num, feature_index)}\n",
    "        :param emb_dim: int, embedding size\n",
    "        :param hidden_dim: list of ctr and ctcvr dnn hidden sizes\n",
    "        :param dropouts: list of ctr and ctcvr dnn drop out probability\n",
    "        :param output_size: int out put size\n",
    "        :param num_task: int default 2 multitask numbers\n",
    "        \"\"\"\n",
    "        super(ESMM, self).__init__()\n",
    "        \n",
    "        # check input parameters\n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            raise Exception(\"input parameter user_feature_dict and item_feature_dict must be not None\")\n",
    "            \n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict) is False:\n",
    "            raise Exception(\"input parameter user_feature_dict and item_feature_dict must be dict\")\n",
    "        \n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "        self.num_task = num_task\n",
    "        \n",
    "        # embedding初始化\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "        # 用户特征\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "        # 物品特征\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "                \n",
    "        # user embedding + item embedding\n",
    "        hidden_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) + \\\n",
    "                      (len(user_feature_dict) - user_cate_feature_nums) + (len(item_feature_dict) - item_cate_feature_nums)\n",
    "        \n",
    "        # esmm 独立任务的DNN结构\n",
    "        for i in range(self.num_task):\n",
    "            setattr(self, 'task_{}_dnn'.format(i + 1), nn.ModuleList())\n",
    "            hid_dim = [hidden_size] + hidden_dim\n",
    "            for j in range(len(hid_dim) - 1):\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('ctr_hidden_{}'.format(j),\n",
    "                                                                      nn.Linear(hid_dim[j], hid_dim[j + 1]))\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('ctr_batchnorm_{}'.format(j),\n",
    "                                                                      nn.BatchNorm1d(hid_dim[j + 1]))\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('ctr_dropout_{}'.format(j),\n",
    "                                                                      nn.Dropout(dropouts[j]))\n",
    "            getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('task_last_layer',\n",
    "                                                                  nn.Linear(hid_dim[-1], output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "#         assert x.size()[1] == len(self.item_feature_dict) + len(self.user_feature_dict)\n",
    "        # embedding\n",
    "        user_embed_list, item_embed_list = list(), list()\n",
    "        for user_feature, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_embed_list.append(getattr(self, user_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                user_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "                \n",
    "        for item_feature, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_embed_list.append(getattr(self, item_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                item_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "            \n",
    "        # embedding 融合\n",
    "        user_embed = torch.cat(user_embed_list, axis=1)\n",
    "        item_embed = torch.cat(item_embed_list, axis=1)\n",
    "        \n",
    "        # hidden layer\n",
    "        hidden = torch.cat([user_embed, item_embed], axis=1).float()\n",
    "\n",
    "        # task tower\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_task):\n",
    "            x = hidden\n",
    "            for mod in getattr(self, 'task_{}_dnn'.format(i + 1)):\n",
    "                x = mod(x)\n",
    "            task_outputs.append(x)\n",
    "\n",
    "        return task_outputs\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([[1, 2, 4, 2, 0.5, 0.1],\n",
    "                               [4, 5, 3, 8, 0.6, 0.43],\n",
    "                               [6, 3, 2, 9, 0.12, 0.32],\n",
    "                               [9, 1, 1, 1, 0.12, 0.45],\n",
    "                               [8, 3, 1, 4, 0.21, 0.67]]))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 5., 3., 1., 3.], dtype=torch.float64),\n",
       " tensor([[2.],\n",
       "         [5.],\n",
       "         [3.],\n",
       "         [1.],\n",
       "         [3.]], dtype=torch.float64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, 1], a[:, 1].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-1.6505],\n",
      "        [ 1.0325],\n",
      "        [-0.0688],\n",
      "        [ 0.1978],\n",
      "        [-0.2421]], grad_fn=<AddmmBackward>), tensor([[ 0.3390],\n",
      "        [ 0.3304],\n",
      "        [-1.8689],\n",
      "        [ 0.0599],\n",
      "        [ 0.5291]], grad_fn=<AddmmBackward>)]\n"
     ]
    }
   ],
   "source": [
    "# Spase featue 和 Dese feature ()考虑使用name_tuple\n",
    "user_cate_dict = {'user_id': (11, 0), 'user_list': (12, 3), 'user_num': (1, 4)}\n",
    "item_cate_dict = {'item_id': (8, 1), 'item_cate': (6, 2), 'item_num': (1, 5)}\n",
    "esmm = ESMM(user_cate_dict, item_cate_dict)\n",
    "tasks = esmm(a)\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3390,  0.3304, -1.8689,  0.0599,  0.5291],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks[1].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESMM(\n",
       "  (user_id): Embedding(11, 128)\n",
       "  (user_list): Embedding(12, 128)\n",
       "  (item_id): Embedding(8, 128)\n",
       "  (item_cate): Embedding(6, 128)\n",
       "  (task_1_dnn): ModuleList(\n",
       "    (ctr_hidden_0): Linear(in_features=514, out_features=128, bias=True)\n",
       "    (ctr_batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ctr_dropout_0): Dropout(p=0.5, inplace=False)\n",
       "    (ctr_hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (ctr_batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ctr_dropout_1): Dropout(p=0.5, inplace=False)\n",
       "    (task_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (task_2_dnn): ModuleList(\n",
       "    (ctr_hidden_0): Linear(in_features=514, out_features=128, bias=True)\n",
       "    (ctr_batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ctr_dropout_0): Dropout(p=0.5, inplace=False)\n",
       "    (ctr_hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (ctr_batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ctr_dropout_1): Dropout(p=0.5, inplace=False)\n",
       "    (task_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = SummaryWriter()\n",
    "w.add_graph(esmm, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[论文地址](https://arxiv.org/abs/1804.07931)  \n",
    "[阿里CVR预估模型之ESMM](https://zhuanlan.zhihu.com/p/57481330)  \n",
    "[CVR预估的新思路：完整空间多任务模型](https://zhuanlan.zhihu.com/p/37562283)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
