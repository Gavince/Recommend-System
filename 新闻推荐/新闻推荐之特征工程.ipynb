{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新闻推荐之特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import logging\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "save_path = \"./data/\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 节省内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 节省内存的一个函数\n",
    "# 减少内存\n",
    "def reduce_mem(df):\n",
    "    starttime = time.time()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,\n",
    "                                                                                                           100*(start_mem-end_mem)/start_mem,\n",
    "                                                                                                           (time.time()-starttime)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trn_val_split(all_click_df, sample_user_num):\n",
    "    \"\"\"划分数据集\"\"\"\n",
    "    \n",
    "    all_click = all_click_df \n",
    "    all_user_ids = all_click.user_id.unique()\n",
    "    sample_user_ids = np.random.choice(all_user_ids, size=sample_user_num, replace=False) # 无放回抽样数据\n",
    "    \n",
    "    click_val = all_click[all_click[\"user_id\"].isin(sample_user_ids)]\n",
    "    click_trn = all_click[~all_click[\"user_id\"].isin(sample_user_ids)]\n",
    "    \n",
    "    # 抽取验证集中最后一次点击的数据作为预测答案\n",
    "    click_val = click_val.sort_values([\"user_id\", \"click_timestamp\"])\n",
    "    val_ans = click_val.groupby(\"user_id\").tail(1)  # 每一个分组的最后一个数据\n",
    "    \n",
    "    click_val = click_val.groupby(\"user_id\").apply(lambda x:x[:-1]).reset_index(drop=True)\n",
    "    \n",
    "    # 验证集的答案和历史数据中的用户，双方互存在\n",
    "    val_ans = val_ans[val_ans.user_id.isin(click_val.user_id.unique())]\n",
    "    click_val = click_val[click_val.user_id.isin(val_ans.user_id.unique())]\n",
    "    \n",
    "    return click_trn, click_val, val_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取历史点击和最后一次点击的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取当前数据的历史点击和最后一次点击\n",
    "def get_hist_and_last_click(all_click):\n",
    "    \n",
    "    all_click = all_click.sort_values(by=['user_id', 'click_timestamp'])\n",
    "    click_last_df = all_click.groupby('user_id').tail(1)\n",
    "\n",
    "    # 如果用户只有一个点击，hist为空了，会导致训练的时候这个用户不可见，此时默认泄露一下\n",
    "    def hist_func(user_df):\n",
    "        if len(user_df) == 1:\n",
    "            return user_df\n",
    "        else:\n",
    "            return user_df[:-1]\n",
    "\n",
    "    click_hist_df = all_click.groupby('user_id').apply(hist_func).reset_index(drop=True)\n",
    "\n",
    "    return click_hist_df, click_last_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trn_val_tst_data(data_path, offline=True):\n",
    "    if offline:\n",
    "        click_trn_data = pd.read_csv(data_path+'train_click_log.csv')  # 训练集用户点击日志\n",
    "        click_trn_data = reduce_mem(click_trn_data)\n",
    "        click_trn, click_val, val_ans = trn_val_split(click_trn_data, sample_user_nums)\n",
    "    else:\n",
    "        click_trn = pd.read_csv(data_path+'train_click_log.csv')\n",
    "        click_trn = reduce_mem(click_trn)\n",
    "        click_val = None\n",
    "        val_ans = None\n",
    "    \n",
    "    click_tst = pd.read_csv(data_path+'testA_click_log.csv')\n",
    "    \n",
    "    return click_trn, click_val, click_tst, val_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 返回多路召回列表或者单路召回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_list(save_path, single_recall_model=None, multi_recall=False):\n",
    "    \n",
    "    if multi_recall:\n",
    "        return pickle.load(open(save_path + 'final_recall_items_dict.pkl', 'rb'))\n",
    "    \n",
    "    if single_recall_model == 'i2i_itemcf':\n",
    "        return pickle.load(open(save_path + 'itemcf_recall_dict.pkl', 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'i2i_emb_itemcf':\n",
    "        return pickle.load(open(save_path + 'embedding_sim_item_recall.pkl', 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'user_cf':\n",
    "        return pickle.load(open(save_path + 'youtubednn_usercf_dict.pkl', 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'youtubednn':\n",
    "        return pickle.load(open(save_path + 'youtube_u2i_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_item_word2vect(click_df, embed_size = 64, save_path=\"./data/\", split_char=\" \"):\n",
    "    \"\"\"训练文章的向量\"\"\"\n",
    "\n",
    "    click_df = click_df.sort_values(by=[\"click_timestamp\"])\n",
    "    \n",
    "    # str\n",
    "    click_df[\"click_article_id\"] = click_df[\"click_article_id\"].astype(str)\n",
    "    \n",
    "    # sentences\n",
    "    docs = click_df.groupby(\"user_id\")[\"click_article_id\"].apply(lambda x:list(x)).reset_index()\n",
    "    docs = docs[\"click_article_id\"].values.tolist()\n",
    "    \n",
    "    # 打印log信息\n",
    "    logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s', level=logging.INFO)\n",
    "    w2v = Word2Vec(sentences=docs, size=16, window=5, seed=2020, workers=8, min_count=1, iter=1)\n",
    "\n",
    "    item_w2v_dict = {k:w2v[k] for k in click_df[\"click_article_id\"]}\n",
    "    pickle.dump(item_w2v_dict, open(save_path + \"item_w2v_emb.pkl\", \"wb\"))\n",
    "    \n",
    "\n",
    "    return item_w2v_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可以通过字典查询对应的item的Embedding\n",
    "def get_embedding(save_path, all_click_df):\n",
    "    if os.path.exists(save_path + 'item_content_emb.pkl'):\n",
    "        item_content_emb_dict = pickle.load(open(save_path + 'item_content_emb.pkl', 'rb'))\n",
    "    else:\n",
    "        print('item_content_emb.pkl 文件不存在...')\n",
    "        \n",
    "    # w2v Embedding是需要提前训练好的\n",
    "    if os.path.exists(save_path + 'item_w2v_emb.pkl'):\n",
    "        item_w2v_emb_dict = pickle.load(open(save_path + 'item_w2v_emb.pkl', 'rb'))\n",
    "    else:\n",
    "        item_w2v_emb_dict = train_item_word2vect(all_click_df)\n",
    "        \n",
    "    if os.path.exists(save_path + 'item_youtube_emb.pkl'):\n",
    "        item_youtube_emb_dict = pickle.load(open(save_path + 'item_youtube_emb.pkl', 'rb'))\n",
    "    else:\n",
    "        print('item_youtube_emb.pkl 文件不存在...')\n",
    "    \n",
    "    if os.path.exists(save_path + 'user_youtube_emb.pkl'):\n",
    "        user_youtube_emb_dict = pickle.load(open(save_path + 'user_youtube_emb.pkl', 'rb'))\n",
    "    else:\n",
    "        print('user_youtube_emb.pkl 文件不存在...')\n",
    "    \n",
    "    return item_content_emb_dict, item_w2v_emb_dict, item_youtube_emb_dict, user_youtube_emb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_info_df():\n",
    "    article_info_df = pd.read_csv(\"./data/\" + 'articles.csv')\n",
    "    article_info_df = reduce_mem(article_info_df)\n",
    "    \n",
    "    return article_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Mem. usage decreased to 23.34 Mb (69.4% reduction),time spend:0.00 min\n"
     ]
    }
   ],
   "source": [
    "# 这里offline的online的区别就是验证集是否为空\n",
    "click_trn, click_val, click_tst, val_ans = get_trn_val_tst_data(\"./data/\", offline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分的情况\n",
    "click_trn_hist, click_trn_last = get_hist_and_last_click(click_trn)\n",
    "\n",
    "# 划分验证集（历史、最后一次点击）\n",
    "if click_val is not None:\n",
    "    click_val_hist, click_val_last = click_val, val_ans\n",
    "else:\n",
    "    click_val_hist, click_val_last = None, None\n",
    "\n",
    "# 划分测试集\n",
    "click_tst_hist = click_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 样本不平衡（负采样）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 装换数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将召回列表转换为DF的形式\n",
    "def recall_dict_2_df(recall_list_dict):\n",
    "    \"\"\"装换数据类型\"\"\"\n",
    "    \n",
    "    df_row_list = []\n",
    "    \n",
    "    for user, item_list in tqdm(recall_list_dict.items()):\n",
    "        for item, score in item_list:\n",
    "            df_row_list.append([user, item, score])\n",
    "    \n",
    "    # 转为DF\n",
    "    df_cols = [\"user_id\", \"sim_item\", \"score\"]\n",
    "    recall_list_df = pd.DataFrame(df_row_list, columns=df_cols)\n",
    "    \n",
    "    return recall_list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 召回数据打标签（做成监督数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank_label_df(recall_list_df, label_df, is_test=False):\n",
    "    \"\"\"\n",
    "    构建有监督数据集, 数据格式:user_id, sim_item, label\n",
    "    \"\"\"\n",
    "    \n",
    "    if is_test:\n",
    "        recall_list_df[\"label\"] = -1\n",
    "        return recall_list_df\n",
    "    \n",
    "    label_df = label_df.rename(columns={\"click_article_id\":\"sim_item\"})\n",
    "    \n",
    "    recall_list_df_ = recall_list_df.merge(label_df[[\"user_id\", \"sim_item\", \"click_timestamp\"]], how=\"left\", on=[\"user_id\", \"sim_item\"])\n",
    "    \n",
    "    # 打标签,最后一次点击作为正样本\n",
    "    recall_list_df_[\"label\"] = recall_list_df_[\"click_timestamp\"].apply(lambda x: 0.0 if np.isnan(x) else 1.0)\n",
    "    \n",
    "    del recall_list_df_[\"click_timestamp\"] # 删除冗余列\n",
    "    \n",
    "    return recall_list_df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 负采样（样本不均衡）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_sample_recall_data(recall_list_df, sample_rate=0.001):\n",
    "    \"\"\"采样数据集\"\"\"\n",
    "    \n",
    "    pos_data = recall_list_df[recall_list_df[\"label\"] == 1]\n",
    "    neg_data = recall_list_df[recall_list_df[\"label\"] == 0]\n",
    "    \n",
    "    print(\"pos_data nums:\", len(pos_data), \"neg_data_nums:\", len(neg_data), \"pos_num/neg_num:\", len(pos_data)/len(neg_data))\n",
    "    \n",
    "    def neg_sample_func(groupby_df):\n",
    "        \"\"\"采样\"\"\"\n",
    "        neg_num = len(groupby_df)\n",
    "        sample_num = max(int(neg_num*sample_rate), 1) # 最少采样１个\n",
    "        sample_num = min(sample_num, 5)  # 最多采样5个\n",
    "        \n",
    "        return groupby_df.sample(sample_num, replace=True) # 有放回\n",
    "    \n",
    "    \n",
    "    # 保证每一位用户都能被采到\n",
    "    neg_data_user_sample = neg_data.groupby(\"user_id\", group_keys=False).apply(neg_sample_func)\n",
    "    # 保证每一篇新闻都能被采到\n",
    "    neg_data_item_sample = neg_data.groupby(\"sim_item\", group_keys=False).apply(neg_sample_func)\n",
    "    \n",
    "    # 数据合并\n",
    "    neg_data_new = neg_data_user_sample.append(neg_data_item_sample)\n",
    "    neg_data_new = neg_data_new.sort_values([\"user_id\", \"score\"]).drop_duplicates([\"user_id\", \"score\"], keep=\"last\")\n",
    "    \n",
    "    data_new = pd.concat([pos_data, neg_data_new], ignore_index=True)\n",
    "    \n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取指定数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recall_item_label_df(click_trn_hist, click_val_hist, click_tst_hist, click_trn_last, click_val_last, recall_list_df):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    # 构建训练集的召回列表(从召回列表中选择出在候选列表中的用户)\n",
    "    trn_user_item_df = recall_list_df[recall_list_df[\"user_id\"].isin(click_trn_hist[\"user_id\"].unique())]\n",
    "    \n",
    "    # 打标签\n",
    "    trn_user_item_label_df = get_rank_label_df(trn_user_item_df, click_trn_last, is_test=False)\n",
    "    trn_user_item_label_df = neg_sample_recall_data(trn_user_item_label_df)\n",
    "    \n",
    "    if click_val is not None:\n",
    "        val_user_items_df = recall_list_df[recall_list_df['user_id'].isin(click_val_hist['user_id'].unique())]\n",
    "        val_user_item_label_df = get_rank_label_df(val_user_items_df, click_val_last, is_test=False)\n",
    "        val_user_item_label_df = neg_sample_recall_data(val_user_item_label_df)\n",
    "    else:\n",
    "        val_user_item_label_df = None\n",
    "        \n",
    "    # 测试数据不需要进行负采样，直接对所有的召回商品进行打-1标签\n",
    "    tst_user_items_df = recall_list_df[recall_list_df['user_id'].isin(click_tst_hist['user_id'].unique())]\n",
    "    tst_user_item_label_df = get_rank_label_df(tst_user_items_df, None, is_test=True)\n",
    "    \n",
    "    return trn_user_item_label_df, val_user_item_label_df, tst_user_item_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_list(save_path, single_recall_model=None, multi_recall=False):\n",
    "    \n",
    "    if multi_recall:\n",
    "        return pickle.load(open(save_path + 'final_recall_items_dict.pkl', 'rb'))\n",
    "    \n",
    "    if single_recall_model == 'i2i_itemcf':\n",
    "        return pickle.load(open(save_path + 'itemcf_recall_dict.pkl', 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'i2i_emb_itemcf':\n",
    "        return pickle.load(open(save_path + 'embedding_sim_item_recall.pkl', 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'user_cf':\n",
    "        return pickle.load(open(save_path + 'youtubednn_usercf_recall.pkl', 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'youtubednn':\n",
    "        return pickle.load(open(save_path + 'youtube_u2i_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recall_list(save_path, single_recall_model=None, multi_recall=False):\n",
    "    \n",
    "    if multi_recall:\n",
    "        return pickle.load(open(save_path + 'final_recall_items_dict.pkl', 'rb'))\n",
    "    \n",
    "    if single_recall_model == 'i2i_itemcf':\n",
    "        return pickle.load(open(\"./source code/temp_resluts/itemcf_recall_dict.pkl\", 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'i2i_emb_itemcf':\n",
    "        return pickle.load(open(save_path + 'embedding_sim_item_recall.pkl', 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'user_cf':\n",
    "        return pickle.load(open(save_path + 'youtubednn_usercf_recall.pkl', 'rb'))\n",
    "    \n",
    "    elif single_recall_model == 'youtubednn':\n",
    "        return pickle.load(open(save_path + 'youtube_u2i_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:07<00:00, 33937.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# 读取召回列表\n",
    "# recall_list_dict = get_recall_list(\"./data/\", single_recall_model='i2i_itemcf') # 这里只选择了单路召回的结果，也可以选择多路召回结果\n",
    "# recall_list_dict = get_recall_list(\"./data/\", multi_recall=True)\n",
    "# 将召回数据转换成df\n",
    "# recall_list_dict = recall_list_dict[\"itemcf_sim_itemcf_recall\"]\n",
    "recall_list_dict = pickle.load(open(\"./source code/itemcf_recall_dict.pkl\", \"rb\"))\n",
    "recall_list_df = recall_dict_2_df(recall_list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_data nums: 0 neg_data_nums: 2000000 pos_num/neg_num: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-0251f266dd34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 给训练验证数据打标签，并负采样（这一部分时间比较久）\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trn_user_item_label_df, val_user_item_label_df, tst_user_item_label_df = get_user_recall_item_label_df(click_trn_hist, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                                                        \u001b[0mclick_val_hist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                                                        \u001b[0mclick_tst_hist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                                                        \u001b[0mclick_trn_last\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-92-96eb4a608d37>\u001b[0m in \u001b[0;36mget_user_recall_item_label_df\u001b[0;34m(click_trn_hist, click_val_hist, click_tst_hist, click_trn_last, click_val_last, recall_list_df)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# 打标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrn_user_item_label_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rank_label_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_user_item_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclick_trn_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrn_user_item_label_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_sample_recall_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_user_item_label_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclick_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-1e8d6f6a37a6>\u001b[0m in \u001b[0;36mneg_sample_recall_data\u001b[0;34m(recall_list_df, sample_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# 保证每一位用户都能被采到\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mneg_data_user_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m# 保证每一篇新闻都能被采到\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mneg_data_item_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sim_item\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_sample_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    184\u001b[0m         ):\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mresult_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidApply\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, sdata, names)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0;31m# must return keys::list, values::list, mutated::bool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.apply_frame_axis0\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-1e8d6f6a37a6>\u001b[0m in \u001b[0;36mneg_sample_func\u001b[0;34m(groupby_df)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msample_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 最多采样5个\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgroupby_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 有放回\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   4913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4914\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4915\u001b[0;31m         \u001b[0maxis_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4917\u001b[0m         \u001b[0;31m# Process random_state argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zwynn/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 给训练验证数据打标签，并负采样（这一部分时间比较久）\n",
    "trn_user_item_label_df, val_user_item_label_df, tst_user_item_label_df = get_user_recall_item_label_df(click_trn_hist, \n",
    "                                                                                                       click_val_hist, \n",
    "                                                                                                       click_tst_hist,\n",
    "                                                                                                       click_trn_last, \n",
    "                                                                                                       click_val_last, \n",
    "                                                                                                       recall_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tuple_func(group_df):\n",
    "    \n",
    "    row_data = []\n",
    "    \n",
    "    for name, row_df in group_df.iterrows():\n",
    "        row_data.append((row_df[\"sim_item\"], row_df[\"score\"], row_df[\"label\"]))\n",
    "    \n",
    "    return row_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:为什么要存储为这种格式的数据\n",
    "trn_user_item_label_tuples = trn_user_item_label_df.groupby('user_id').apply(make_tuple_func).reset_index()\n",
    "trn_user_item_label_tuples_dict = dict(zip(trn_user_item_label_tuples['user_id'], trn_user_item_label_tuples[0]))\n",
    "\n",
    "if val_user_item_label_df is not None:\n",
    "    val_user_item_label_tuples = val_user_item_label_df.groupby('user_id').apply(make_tuple_func).reset_index()\n",
    "    val_user_item_label_tuples_dict = dict(zip(val_user_item_label_tuples['user_id'], val_user_item_label_tuples[0]))\n",
    "else:\n",
    "    val_user_item_label_tuples_dict = None\n",
    "    \n",
    "tst_user_item_label_tuples = tst_user_item_label_df.groupby('user_id').apply(make_tuple_func).reset_index()\n",
    "tst_user_item_label_tuples_dict = dict(zip(tst_user_item_label_tuples['user_id'], tst_user_item_label_tuples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程\n",
    "方法：特征创造、特征组合和特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面基于data做历史相关的特征,现有数据类型为：{user_id:sim_item, score, label}\n",
    "\n",
    "def create_feature(users_id, recall_list, click_hist_df,  articles_info, articles_emb, user_emb=None, N=1):\n",
    "    \"\"\"\n",
    "    基于用户的历史行为做相关特征(通过计算召回用户的新闻与其历史点击文章计算相关关系，从而增加新的特征数据（特征创造）)\n",
    "    :param users_id: 用户id\n",
    "    :param recall_list: 对于每个用户召回的候选文章列表\n",
    "    :param click_hist_df: 用户的历史点击信息\n",
    "    :param articles_info: 文章信息\n",
    "    :param articles_emb: 文章的embedding向量, 这个可以用item_content_emb, item_w2v_emb, item_youtube_emb\n",
    "    :param user_emb: 用户的embedding向量， 这个是user_youtube_emb, 如果没有也可以不用， 但要注意如果要用的话， articles_emb就要用item_youtube_emb的形式， 这样维度才一样\n",
    "    :param N: 最近的N次点击  由于testA日志里面很多用户只存在一次历史点击， 所以为了不产生空值，默认是1\n",
    "    \"\"\"\n",
    "    \n",
    "    all_user_feas = []\n",
    "    \n",
    "    i = 0\n",
    "    for user_id in tqdm(users_id):\n",
    "        \n",
    "        # 用户历史N次点击的文章\n",
    "        hist_user_items = click_hist_df[click_hist_df[\"user_id\"] == user_id][\"click_article_id\"][-N:]\n",
    "        \n",
    "        # 遍历召回数据\n",
    "        for rank, (article_id, score, label) in enumerate(recall_list[user_id]):\n",
    "            \n",
    "            # 计算召回新闻的信息\n",
    "            a_create_time = articles_info[articles_info[\"article_id\"] == article_id][\"created_at_ts\"].values[0]\n",
    "            a_create_word = articles_info[articles_info[\"article_id\"] == article_id][\"words_count\"].values[0]\n",
    "            \n",
    "            # 存储\n",
    "            sigle_user_feas = [user_id, article_id]\n",
    "            sim_fea = []\n",
    "            time_fea = []\n",
    "            word_fea = []\n",
    "            \n",
    "            # 计算与历史用户新闻的相似度(Ｎ)\n",
    "            for hist_item in hist_user_items:\n",
    "                b_create_time = articles_info[articles_info[\"article_id\"] == hist_item][\"created_at_ts\"].values[0]\n",
    "                b_create_word = articles_info[articles_info[\"article_id\"] == hist_item][\"words_count\"].values[0]\n",
    "                \n",
    "                # 计算文章相似度\n",
    "                sim_fea.append(np.dot(articles_emb[hist_item], articles_emb[article_id]))\n",
    "                # 计算创建时间差\n",
    "                time_fea.append(abs(a_create_time - b_create_time))\n",
    "                # 计算文章字数的差值\n",
    "                word_fea.append(abs(a_create_word - b_create_word))\n",
    "            \n",
    "            sigle_user_feas.extend(sim_fea)\n",
    "            sigle_user_feas.extend(time_fea)\n",
    "            sigle_user_feas.extend(word_fea)\n",
    "            \n",
    "            #加入相似性的统计变量\n",
    "            sigle_user_feas.extend([max(sim_fea), min(sim_fea), sum(sim_fea), sum(sim_fea)/len(sim_fea)])\n",
    "            \n",
    "            # 计算用户与文章的相似度\n",
    "            if user_emb:\n",
    "                sigle_user_feas.append(np.dot(user_emb[user_id], articles_emb[article_id]))\n",
    "\n",
    "            sigle_user_feas.extend([score, rank, label])\n",
    "            all_user_feas.append(sigle_user_feas) #追加一个list\n",
    "    \n",
    "    # 构建个DataFrame\n",
    "    id_cols = [\"user_id\", \"click_article_id\"]\n",
    "    sim_cols = [\"sim\" + str(i) for i in range(N)]\n",
    "    time_cols = [\"time_diff\" + str(i) for i in range(N)]\n",
    "    word_cols = [\"word_diff\" + str(i) for i in range(N)]\n",
    "    sat_cols = [\"sim_max\", \"sim_min\", \"sim_sum\", \"sim_mean\"]\n",
    "    user_item_sim_cols = [\"user_item_sim\"] if user_emb else []\n",
    "    user_score_rank_label = [\"score\", \"rank\", \"label\"]\n",
    "    \n",
    "    cols = id_cols + sim_cols + time_cols + word_cols + sat_cols + user_item_sim_cols + user_score_rank_label\n",
    "    \n",
    "    df = pd.DataFrame(all_user_feas, columns=cols)\n",
    "    \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Mem. usage decreased to  5.56 Mb (50.0% reduction),time spend:0.00 min\n"
     ]
    }
   ],
   "source": [
    "# 加载文章信息\n",
    "articles_info = get_article_info_df()\n",
    "\n",
    "all_click_df = click_trn.append(click_tst)\n",
    "# 加载embedding向量\n",
    "item_content_emb_dict, item_w2v_emb_dict, item_youtube_emb_dict, user_youtube_emb_dict = get_embedding(\"./data/\", all_click_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [14:08<00:00, 235.65it/s]\n",
      "100%|██████████| 50000/50000 [51:06<00:00, 16.31it/s] \n"
     ]
    }
   ],
   "source": [
    "# 获取训练验证及测试数据中召回列文章相关特征\n",
    "trn_user_item_feats_df = create_feature(trn_user_item_label_tuples_dict.keys(), trn_user_item_label_tuples_dict, \\\n",
    "                                            click_trn_hist, articles_info, item_content_emb_dict)\n",
    "\n",
    "if val_user_item_label_tuples_dict is not None:\n",
    "    val_user_item_feats_df = create_feature(val_user_item_label_tuples_dict.keys(), val_user_item_label_tuples_dict, \\\n",
    "                                                click_val_hist, articles_info, item_content_emb_dict)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = create_feature(tst_user_item_label_tuples_dict.keys(), tst_user_item_label_tuples_dict, \\\n",
    "                                            click_tst_hist, articles_info, item_content_emb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存一份省的每次都要重新跑，每次跑的时间都比较长\n",
    "trn_user_item_feats_df.to_csv(save_path + 'trn_user_item_feats_df.csv', index=False)\n",
    "\n",
    "if val_user_item_feats_df is not None:\n",
    "    val_user_item_feats_df.to_csv(save_path + 'val_user_item_feats_df.csv', index=False)\n",
    "\n",
    "tst_user_item_feats_df.to_csv(save_path + 'tst_user_item_feats_df.csv', index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用户与文章特征\n",
    "这一块，正式进行特征工程，既要拼接上已有的特征， 也会做更多的特征出来，我们来梳理一下已有的特征和可构造特征：\n",
    "1. 文章自身的特征， 文章字数，文章创建时间， 文章的embedding （articles表中)\n",
    "2. 用户点击环境特征， 那些设备的特征(这个在df中)\n",
    "3. 对于用户和商品还可以构造的特征：\n",
    "    * 基于用户的点击文章次数和点击时间构造可以表现<font color=\"red\">用户活跃度的特征</font>\n",
    "    * 基于文章被点击次数和时间构造可以反映<font color=\"red\">文章热度的特征</font>\n",
    "    * 用户的时间统计特征： 根据其点击的历史文章列表的点击时间和文章的创建时间做统计特征，比如求均值， 这个可以反映用户对于文章时效的偏好\n",
    "    * 用户的主题爱好特征， 对于用户点击的历史文章主题进行一个统计， 然后对于当前文章看看是否属于用户已经点击过的主题\n",
    "    * 用户的字数爱好特征， 对于用户点击的历史文章的字数统计， 求一个均值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户相关特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>249999</td>\n",
       "      <td>160974</td>\n",
       "      <td>1506959142820</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>249999</td>\n",
       "      <td>160417</td>\n",
       "      <td>1506959172820</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249998</td>\n",
       "      <td>160974</td>\n",
       "      <td>1506959056066</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249998</td>\n",
       "      <td>202557</td>\n",
       "      <td>1506959086066</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>249997</td>\n",
       "      <td>183665</td>\n",
       "      <td>1506959088613</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "0   249999            160974    1506959142820                  4   \n",
       "1   249999            160417    1506959172820                  4   \n",
       "2   249998            160974    1506959056066                  4   \n",
       "3   249998            202557    1506959086066                  4   \n",
       "4   249997            183665    1506959088613                  4   \n",
       "\n",
       "   click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                  1        17              1            13   \n",
       "1                  1        17              1            13   \n",
       "2                  1        12              1            13   \n",
       "3                  1        12              1            13   \n",
       "4                  1        17              1            15   \n",
       "\n",
       "   click_referrer_type  \n",
       "0                    2  \n",
       "1                    2  \n",
       "2                    2  \n",
       "3                    2  \n",
       "4                    5  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Mem. usage decreased to  5.56 Mb (50.0% reduction),time spend:0.00 min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1408468313000</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1407071171000</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  created_at_ts  words_count\n",
       "0           0            0  1513144419000          168\n",
       "1           1            1  1405341936000          189\n",
       "2           2            1  1408667706000          250\n",
       "3           3            1  1408468313000          230\n",
       "4           4            1  1407071171000          162"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_csv(\"data/articles.csv\")\n",
    "articles = reduce_mem(articles)\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Mem. usage decreased to 46.65 Mb (62.5% reduction),time spend:0.00 min\n"
     ]
    }
   ],
   "source": [
    "# 获取全量数据集\n",
    "if click_val is not None:\n",
    "    all_data = click_trn.append(click_val)\n",
    "    \n",
    "all_data = click_trn.append(click_tst)\n",
    "all_data = reduce_mem(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199999</td>\n",
       "      <td>160417</td>\n",
       "      <td>1507029570190</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199999</td>\n",
       "      <td>5408</td>\n",
       "      <td>1507029571478</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199999</td>\n",
       "      <td>50823</td>\n",
       "      <td>1507029601478</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199998</td>\n",
       "      <td>157770</td>\n",
       "      <td>1507029532200</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199998</td>\n",
       "      <td>96613</td>\n",
       "      <td>1507029671831</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "0   199999            160417    1507029570190                  4   \n",
       "1   199999              5408    1507029571478                  4   \n",
       "2   199999             50823    1507029601478                  4   \n",
       "3   199998            157770    1507029532200                  4   \n",
       "4   199998             96613    1507029671831                  4   \n",
       "\n",
       "   click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                  1        17              1            13   \n",
       "1                  1        17              1            13   \n",
       "2                  1        17              1            13   \n",
       "3                  1        17              1            25   \n",
       "4                  1        17              1            25   \n",
       "\n",
       "   click_referrer_type  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    5  \n",
       "4                    5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接文章信息　TODO:拼接数据的方法\n",
    "all_data = all_data.merge(articles, left_on=\"click_article_id\", right_on=\"article_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199999</td>\n",
       "      <td>160417</td>\n",
       "      <td>1507029570190</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>160417</td>\n",
       "      <td>281</td>\n",
       "      <td>1506942089000</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199991</td>\n",
       "      <td>160417</td>\n",
       "      <td>1507029620497</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>160417</td>\n",
       "      <td>281</td>\n",
       "      <td>1506942089000</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199989</td>\n",
       "      <td>160417</td>\n",
       "      <td>1507029634489</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>160417</td>\n",
       "      <td>281</td>\n",
       "      <td>1506942089000</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199973</td>\n",
       "      <td>160417</td>\n",
       "      <td>1507029621819</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>160417</td>\n",
       "      <td>281</td>\n",
       "      <td>1506942089000</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199968</td>\n",
       "      <td>160417</td>\n",
       "      <td>1507029586033</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>160417</td>\n",
       "      <td>281</td>\n",
       "      <td>1506942089000</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "0   199999            160417    1507029570190                  4   \n",
       "1   199991            160417    1507029620497                  4   \n",
       "2   199989            160417    1507029634489                  4   \n",
       "3   199973            160417    1507029621819                  4   \n",
       "4   199968            160417    1507029586033                  4   \n",
       "\n",
       "   click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                  1        17              1            13   \n",
       "1                  1        17              1             2   \n",
       "2                  1        17              1            10   \n",
       "3                  1        17              1            16   \n",
       "4                  1        17              1            25   \n",
       "\n",
       "   click_referrer_type  article_id  category_id  created_at_ts  words_count  \n",
       "0                    1      160417          281  1506942089000          173  \n",
       "1                    2      160417          281  1506942089000          173  \n",
       "2                    1      160417          281  1506942089000          173  \n",
       "3                    2      160417          281  1506942089000          173  \n",
       "4                    1      160417          281  1506942089000          173  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析一下点击时间和点击文章的次数，区分用户活跃度\n",
    "如果某个用户点击文章之间的时间间隔比较小， 同时点击的文章次数很多的话， 那么我们认为这种用户一般就是活跃用户, 当然衡量用户活跃度的方式可能多种多样， 这里我们只提供其中一种，我们写一个函数， 得到可以衡量用户活跃度的特征，逻辑如下：\n",
    "1. 首先根据用户user_id分组， 对于每个用户，计算点击文章的次数， 两两点击文章时间间隔的均值\n",
    "2. 把点击次数取倒数和时间间隔的均值统一归一化，然后两者相加合并，该值越小， 说明用户越活跃\n",
    "3. 注意， 上面两两点击文章的时间间隔均值， 会出现如果用户只点击了一次的情况，这时候时间间隔均值那里会出现空值， 对于这种情况最后特征那里给个大数进行区分\n",
    "\n",
    "这个的衡量标准就是先把点击的次数取到数然后归一化， 然后点击的时间差归一化， 然后两者相加进行合并， <font color=\"red\">该值越小， 说明被点击的次数越多， 且间隔时间短。 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate_level(all_data, cols):\n",
    "    \"\"\"\n",
    "    计算用户活跃等级(关注用户在一段时间内的点击行为)\n",
    "    \"\"\"\n",
    "    \n",
    "    data = all_data[cols]\n",
    "\n",
    "    data.sort_values(by=[\"user_id\", \"click_timestamp\"], inplace=True)\n",
    "\n",
    "    # 统计用户的点击次数和点击次数所在的时间\n",
    "    user_act = pd.DataFrame(data.groupby(\"user_id\", as_index=False)[[\"click_article_id\", \"click_timestamp\"\n",
    "                                            ]].agg({\"click_article_id\":np.size, \"click_timestamp\":{list}}).values, columns=[\"user_id\", \"click_size\", \"click_timestamp\"])\n",
    "\n",
    "    def time_diff_mean(l):\n",
    "        \"\"\"计算平均时间差值\"\"\"\n",
    "        if len(l) == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.mean([j - i for i, j in zip(l[:-1], l[1:])]) # 错位时间相减\n",
    "\n",
    "    user_act[\"time_diff_mean\"] = user_act[\"click_timestamp\"].apply(lambda x: time_diff_mean(x))\n",
    "\n",
    "    user_act[\"click_size\"] = 1 / user_act[\"click_size\"]\n",
    "\n",
    "    # 归一化数据, 用户点击次数\n",
    "    MM = MinMaxScaler()\n",
    "    user_act[\"click_size\"] = MM.fit_transform(user_act[\"click_size\"].values.reshape(-1, 1))\n",
    "\n",
    "    # 归一化数据, 用户点击时间差值\n",
    "    MM = MinMaxScaler()\n",
    "    user_act[\"time_diff_mean\"] = MM.fit_transform(user_act[\"time_diff_mean\"].values.reshape(-1, 1))\n",
    "\n",
    "    # 用户活跃级别，数值越小，其相对应的活跃度越高\n",
    "    user_act[\"active_level\"] =  user_act[\"time_diff_mean\"] + user_act[\"click_size\"]\n",
    "    user_act[\"user_id\"] = user_act[\"user_id\"].astype(\"int\")\n",
    "    \n",
    "    del user_act[\"click_timestamp\"]\n",
    "    \n",
    "    return user_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_act_fea = activate_level(all_data, cols=['user_id', 'click_article_id', 'click_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_size</th>\n",
       "      <th>time_diff_mean</th>\n",
       "      <th>active_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>249995</td>\n",
       "      <td>0.028376</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>0.062970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>249996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>249997</td>\n",
       "      <td>0.141942</td>\n",
       "      <td>0.117898</td>\n",
       "      <td>0.259840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>249998</td>\n",
       "      <td>0.199146</td>\n",
       "      <td>0.496823</td>\n",
       "      <td>0.695969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>249999</td>\n",
       "      <td>0.051621</td>\n",
       "      <td>0.068288</td>\n",
       "      <td>0.119909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_size  time_diff_mean  active_level\n",
       "249995   249995    0.028376        0.034594      0.062970\n",
       "249996   249996    1.000000        0.000000      1.000000\n",
       "249997   249997    0.141942        0.117898      0.259840\n",
       "249998   249998    0.199146        0.496823      0.695969\n",
       "249999   249999    0.051621        0.068288      0.119909"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_act_fea.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析一下点击时间和被点击文章的次数， 衡量文章热度特征\n",
    "和上面同样的思路， 如果一篇文章在很短的时间间隔之内被点击了很多次， 说明文章比较热门，实现的逻辑和上面的基本一致， 只不过这里是按照点击的文章进行分组：\n",
    "1. 根据文章进行分组， 对于每篇文章的用户， 计算点击的时间间隔\n",
    "2. 将用户的数量取倒数， 然后用户的数量和时间间隔归一化， 然后相加得到热度特征， 该值越小， 说明被点击的次数越大且时间间隔越短， 文章比较热\n",
    "\n",
    "当然， 这只是给出一种判断文章热度的一种方法， 这里大家也可以头脑风暴一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    " def hot_level(all_data, cols):\n",
    "    \"\"\"\n",
    "    制作衡量文章热度的特征\n",
    "    :param all_data: 数据集\n",
    "    :param cols: 用到的特征列\n",
    "    \"\"\"\n",
    "    data = all_data[cols]\n",
    "    data.sort_values(['click_article_id', 'click_timestamp'], inplace=True)\n",
    "    article_hot = pd.DataFrame(data.groupby('click_article_id', as_index=False)[['user_id', 'click_timestamp']].\\\n",
    "                               agg({'user_id':np.size, 'click_timestamp': {list}}).values, columns=['click_article_id', 'user_num', 'click_timestamp'])\n",
    "    \n",
    "    # 计算被点击时间间隔的均值\n",
    "    def time_diff_mean(l):\n",
    "        if len(l) == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return np.mean([j-i for i, j in list(zip(l[:-1], l[1:]))])\n",
    "        \n",
    "    article_hot['time_diff_mean'] = article_hot['click_timestamp'].apply(lambda x: time_diff_mean(x))\n",
    "    \n",
    "    # 点击次数取倒数\n",
    "    article_hot['user_num'] = 1 / article_hot['user_num']\n",
    "    \n",
    "    # 两者归一化\n",
    "    article_hot['user_num'] = (article_hot['user_num'] - article_hot['user_num'].min()) / (article_hot['user_num'].max() - article_hot['user_num'].min())\n",
    "    article_hot['time_diff_mean'] = (article_hot['time_diff_mean'] - article_hot['time_diff_mean'].min()) / (article_hot['time_diff_mean'].max() - article_hot['time_diff_mean'].min())     \n",
    "    article_hot['hot_level'] = article_hot['user_num'] + article_hot['time_diff_mean']\n",
    "    \n",
    "    article_hot['click_article_id'] = article_hot['click_article_id'].astype('int')\n",
    "    \n",
    "    del article_hot['click_timestamp']\n",
    "    \n",
    "    return article_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_hot_fea = hot_level(all_data, cols=['user_id', 'click_article_id', 'click_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>user_num</th>\n",
       "      <th>time_diff_mean</th>\n",
       "      <th>hot_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35375</th>\n",
       "      <td>364017</td>\n",
       "      <td>0.0587645</td>\n",
       "      <td>0.054643</td>\n",
       "      <td>0.113407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35376</th>\n",
       "      <td>364022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35377</th>\n",
       "      <td>364028</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35378</th>\n",
       "      <td>364043</td>\n",
       "      <td>0.19995</td>\n",
       "      <td>0.175634</td>\n",
       "      <td>0.375584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35379</th>\n",
       "      <td>364046</td>\n",
       "      <td>0.499969</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>1.2725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       click_article_id   user_num  time_diff_mean hot_level\n",
       "35375            364017  0.0587645        0.054643  0.113407\n",
       "35376            364022          1        0.000000         1\n",
       "35377            364028          1        0.000000         1\n",
       "35378            364043    0.19995        0.175634  0.375584\n",
       "35379            364046   0.499969        0.772532    1.2725"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_hot_fea.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户的系列习惯\n",
    "这个基于原来的日志表做一个类似于article的那种DataFrame， 存放用户特有的信息, 主要包括点击习惯， 爱好特征之类的\n",
    "* 用户的设备习惯， 这里取最常用的设备（众数）\n",
    "* 用户的时间习惯： 根据其点击过得历史文章的时间来做一个统计（这个感觉最好是把时间戳里的时间特征的h特征提出来，看看用户习惯一天的啥时候点击文章）， 但这里先用转换的时间吧， 求个均值\n",
    "* 用户的爱好特征， 对于用户点击的历史文章主题进行用户的爱好判别， 更偏向于哪几个主题， 这个最好是multi-hot进行编码， 先试试行不\n",
    "* 用户文章的字数差特征， 用户的爱好文章的字数习惯\n",
    "\n",
    "这些就是对用户进行分组， 然后统计即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用户设备习惯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_fea(all_data, cols):\n",
    "    \"\"\"取每一个用户的综述\"\"\"\n",
    "    \n",
    "    user_device_info = all_data[cols]\n",
    "    # 分组逐列进行\n",
    "    user_device_info = user_device_info.groupby(\"user_id\").agg(lambda x :x.value_counts().index[0]).reset_index()\n",
    "    \n",
    "    return user_device_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_cols = [\"user_id\",'click_environment',\n",
    "               'click_deviceGroup', 'click_os', 'click_country', 'click_region',\n",
    "               'click_referrer_type']\n",
    "\n",
    "user_device_info = device_fea(all_data, device_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>249995</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>249996</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>249997</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>249998</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>249999</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_environment  click_deviceGroup  click_os  \\\n",
       "249995   249995                  4                  1        17   \n",
       "249996   249996                  4                  3         2   \n",
       "249997   249997                  4                  1        17   \n",
       "249998   249998                  4                  1        12   \n",
       "249999   249999                  4                  1        17   \n",
       "\n",
       "        click_country  click_region  click_referrer_type  \n",
       "249995              1            13                    2  \n",
       "249996              1            20                    2  \n",
       "249997              1            15                    5  \n",
       "249998              1            13                    2  \n",
       "249999              1            13                    2  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_device_info.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用户时间习惯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_time_hob_fea(all_data, cols):\n",
    "    \n",
    "    user_time_hob_info = all_data[cols]\n",
    "    \n",
    "    MMS = MinMaxScaler()\n",
    "    \n",
    "    user_time_hob_info[\"click_timestamp\"] = MMS.fit_transform(user_time_hob_info[[\"click_timestamp\"]])\n",
    "    user_time_hob_info[\"created_at_ts\"] = MMS.fit_transform(user_time_hob_info[[\"created_at_ts\"]])\n",
    "    \n",
    "    # 每一位用户的时间均值\n",
    "    user_time_hob_info = user_time_hob_info.groupby(\"user_id\").agg(\"mean\").reset_index() #有区别\n",
    "    user_time_hob_info.rename(columns={\"click_timestamp\":\"user_time_hob1\", \"created_at_ts\":\"user_time_hob2\"}, inplace=True)\n",
    "    \n",
    "    return user_time_hob_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hob_cols = [\"user_id\", \"click_timestamp\", \"created_at_ts\"]\n",
    "user_time_hob_info = user_time_hob_fea(all_data, time_hob_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>249995</td>\n",
       "      <td>0.080467</td>\n",
       "      <td>0.989999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>249996</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.989092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>249997</td>\n",
       "      <td>0.085789</td>\n",
       "      <td>0.987338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>249998</td>\n",
       "      <td>0.095746</td>\n",
       "      <td>0.990157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>249999</td>\n",
       "      <td>0.093899</td>\n",
       "      <td>0.989754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  user_time_hob1  user_time_hob2\n",
       "249995   249995        0.080467        0.989999\n",
       "249996   249996        0.000011        0.989092\n",
       "249997   249997        0.085789        0.987338\n",
       "249998   249998        0.095746        0.990157\n",
       "249999   249999        0.093899        0.989754"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_time_hob_info.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用户的主题爱好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_cat_hot_fea(all_data, cols):\n",
    "    \"\"\"统计用户的主题爱好\"\"\"\n",
    "    \n",
    "    user_category_hob_info = all_data[cols]\n",
    "    user_category_hob_info = user_category_hob_info.groupby(\"user_id\").agg(list).reset_index()\n",
    "    \n",
    "    user_cat_hob_info = pd.DataFrame()\n",
    "    user_cat_hob_info[\"user_id\"] = user_category_hob_info[\"user_id\"]\n",
    "    user_cat_hob_info[\"cate_list\"] = user_category_hob_info[\"category_id\"]\n",
    "    \n",
    "    return user_cat_hob_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_hob_cols = [\"user_id\", \"category_id\"]\n",
    "user_cat_hob_info = user_cat_hot_fea(all_data, cat_hob_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cate_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>249995</td>\n",
       "      <td>[281, 7, 437, 421, 399, 323, 281, 281, 428, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>249996</td>\n",
       "      <td>[281]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>249997</td>\n",
       "      <td>[250, 301, 301, 209, 142, 250, 250]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>249998</td>\n",
       "      <td>[281, 327, 375, 375, 375]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>249999</td>\n",
       "      <td>[281, 281, 431, 281, 375, 375, 281, 348, 421, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                                          cate_list\n",
       "249995   249995  [281, 7, 437, 421, 399, 323, 281, 281, 428, 30...\n",
       "249996   249996                                              [281]\n",
       "249997   249997                [250, 301, 301, 209, 142, 250, 250]\n",
       "249998   249998                          [281, 327, 375, 375, 375]\n",
       "249999   249999  [281, 281, 431, 281, 375, 375, 281, 348, 421, ..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_cat_hob_info.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用户字数偏爱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每一位用户的阅读子数的均值\n",
    "user_wcou_info = all_data.groupby(\"user_id\")[\"words_count\"].agg(\"mean\").reset_index()\n",
    "user_wcou_info.rename(columns={\"words_count\":\"word_hbo\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>word_hbo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>249995</td>\n",
       "      <td>202.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>249996</td>\n",
       "      <td>259.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>249997</td>\n",
       "      <td>211.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>249998</td>\n",
       "      <td>212.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>249999</td>\n",
       "      <td>209.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id    word_hbo\n",
       "249995   249995  202.176471\n",
       "249996   249996  259.000000\n",
       "249997   249997  211.714286\n",
       "249998   249998  212.400000\n",
       "249999   249999  209.210526"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_wcou_info.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 合并特征信息并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_size</th>\n",
       "      <th>time_diff_mean</th>\n",
       "      <th>active_level</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>user_time_hob1</th>\n",
       "      <th>user_time_hob2</th>\n",
       "      <th>cate_list</th>\n",
       "      <th>word_hbo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.499466</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.499515</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343715</td>\n",
       "      <td>0.992865</td>\n",
       "      <td>[281, 26]</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.499466</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.499515</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.343618</td>\n",
       "      <td>0.992721</td>\n",
       "      <td>[133, 418]</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.499466</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.499515</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343651</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>[297, 43]</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.499466</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.499515</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.343629</td>\n",
       "      <td>0.992774</td>\n",
       "      <td>[99, 43]</td>\n",
       "      <td>196.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.499466</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.499515</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343702</td>\n",
       "      <td>0.992688</td>\n",
       "      <td>[66, 67]</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  click_size  time_diff_mean  active_level  click_environment  \\\n",
       "0        0    0.499466        0.000048      0.499515                  4   \n",
       "1        1    0.499466        0.000048      0.499515                  4   \n",
       "2        2    0.499466        0.000048      0.499515                  4   \n",
       "3        3    0.499466        0.000048      0.499515                  4   \n",
       "4        4    0.499466        0.000048      0.499515                  4   \n",
       "\n",
       "   click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                  1        17              1            25   \n",
       "1                  1        17              1            25   \n",
       "2                  3        20              1            25   \n",
       "3                  3         2              1            25   \n",
       "4                  1        12              1            16   \n",
       "\n",
       "   click_referrer_type  user_time_hob1  user_time_hob2   cate_list  word_hbo  \n",
       "0                    2        0.343715        0.992865   [281, 26]     266.0  \n",
       "1                    6        0.343618        0.992721  [133, 418]     169.0  \n",
       "2                    2        0.343651        0.992020   [297, 43]     210.0  \n",
       "3                    2        0.343629        0.992774    [99, 43]     196.5  \n",
       "4                    1        0.343702        0.992688    [66, 67]     220.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_info = pd.merge(user_act_fea, user_device_info, on=\"user_id\")\n",
    "user_info = user_info.merge(user_time_hob_info, on=\"user_id\")\n",
    "user_info = user_info.merge(user_cat_hob_info, on=\"user_id\")\n",
    "user_info = user_info.merge(user_wcou_info, on=\"user_id\")\n",
    "user_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据\n",
    "user_info.to_csv(save_path + \"user_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并特征数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 把用户信息直接读入进来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = pd.read_csv(save_path + 'user_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对召回数据的特征进行填补，构造更多有用的特征数据类型\n",
    "if os.path.exists(save_path + 'trn_user_item_feats_df.csv'):\n",
    "    trn_user_item_feats_df = pd.read_csv(save_path + 'trn_user_item_feats_df.csv')\n",
    "    \n",
    "if os.path.exists(save_path + 'tst_user_item_feats_df.csv'):\n",
    "    tst_user_item_feats_df = pd.read_csv(save_path + 'tst_user_item_feats_df.csv')\n",
    "\n",
    "if os.path.exists(save_path + 'val_user_item_feats_df.csv'):\n",
    "    val_user_item_feats_df = pd.read_csv(save_path + 'val_user_item_feats_df.csv')\n",
    "else:\n",
    "    val_user_item_feats_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼上用户特征\n",
    "# 下面是线下验证的\n",
    "trn_user_item_feats_df = trn_user_item_feats_df.merge(user_info, on='user_id', how='left')\n",
    "\n",
    "if val_user_item_feats_df is not None:\n",
    "    val_user_item_feats_df = val_user_item_feats_df.merge(user_info, on='user_id', how='left')\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = tst_user_item_feats_df.merge(user_info, on='user_id',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文章信息直接读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Mem. usage decreased to  5.56 Mb (50.0% reduction),time spend:0.00 min\n"
     ]
    }
   ],
   "source": [
    "articles =  pd.read_csv(\"./data/\"+'articles.csv')\n",
    "articles = reduce_mem(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼上文章特征\n",
    "trn_user_item_feats_df = trn_user_item_feats_df.merge(articles, left_on='click_article_id', right_on='article_id')\n",
    "\n",
    "if val_user_item_feats_df is not None:\n",
    "    val_user_item_feats_df = val_user_item_feats_df.merge(articles, left_on='click_article_id', right_on='article_id')\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "\n",
    "tst_user_item_feats_df = tst_user_item_feats_df.merge(articles, left_on='click_article_id', right_on='article_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 召回文章的主题是否在用户的爱好里面\n",
    "目的：查看召回结果是否优良"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_user_item_feats_df['is_cat_hab'] = trn_user_item_feats_df.apply(lambda x: 1 if x.category_id in set(x.cate_list) else 0, axis=1)\n",
    "if val_user_item_feats_df is not None:\n",
    "    val_user_item_feats_df['is_cat_hab'] = val_user_item_feats_df.apply(lambda x: 1 if x.category_id in set(x.cate_list) else 0, axis=1)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "tst_user_item_feats_df['is_cat_hab'] = tst_user_item_feats_df.apply(lambda x: 1 if x.category_id in set(x.cate_list) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线下验证\n",
    "del trn_user_item_feats_df['cate_list']\n",
    "\n",
    "if val_user_item_feats_df is not None:\n",
    "    del val_user_item_feats_df['cate_list']\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "del tst_user_item_feats_df['cate_list']\n",
    "\n",
    "del trn_user_item_feats_df['article_id']\n",
    "\n",
    "if val_user_item_feats_df is not None:\n",
    "    del val_user_item_feats_df['article_id']\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "del tst_user_item_feats_df['article_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练验证特征\n",
    "trn_user_item_feats_df.to_csv(save_path + 'trn_user_item_feats_df.csv', index=False)\n",
    "if val_user_item_feats_df is not None:\n",
    "    val_user_item_feats_df.to_csv(save_path + 'val_user_item_feats_df.csv', index=False)\n",
    "tst_user_item_feats_df.to_csv(save_path + 'tst_user_item_feats_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "\n",
    "[pandas中groupby函数中参数ax_index和group_keys的区别](https://my.oschina.net/u/4346988/blog/4535103)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 知识点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
