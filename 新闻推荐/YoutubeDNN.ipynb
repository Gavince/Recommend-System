{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat\n",
    "from preprocess import gen_data_set, gen_model_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "\n",
    "from deepmatch.models import *\n",
    "from deepmatch.utils import sampledsoftmaxloss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以movielens数据为例，取200条样例数据进行流程演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csvdata = pd.read_csv(\"./data/movielens_sample.txt\")\n",
    "sparse_features = [\"movie_id\", \"user_id\",\n",
    "                    \"gender\", \"age\", \"occupation\", \"zip\", ]\n",
    "SEQ_LEN = 50\n",
    "negsample = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  timestamp  \\\n",
       "0        1      1193       5  978300760   \n",
       "1        1       661       3  978302109   \n",
       "2        1       914       3  978301968   \n",
       "3        1      3408       4  978300275   \n",
       "4        1      2355       5  978824291   \n",
       "\n",
       "                                    title                        genres  \\\n",
       "0  One Flew Over the Cuckoo's Nest (1975)                         Drama   \n",
       "1        James and the Giant Peach (1996)  Animation|Children's|Musical   \n",
       "2                     My Fair Lady (1964)               Musical|Romance   \n",
       "3                  Erin Brockovich (2000)                         Drama   \n",
       "4                    Bug's Life, A (1998)   Animation|Children's|Comedy   \n",
       "\n",
       "  gender  age  occupation    zip  \n",
       "0      F    1          10  48067  \n",
       "1      F    1          10  48067  \n",
       "2      F    1          10  48067  \n",
       "3      F    1          10  48067  \n",
       "4      F    1          10  48067  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 233 entries, 0 to 232\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   user_id     233 non-null    int64 \n",
      " 1   movie_id    233 non-null    int64 \n",
      " 2   rating      233 non-null    int64 \n",
      " 3   timestamp   233 non-null    int64 \n",
      " 4   title       233 non-null    object\n",
      " 5   genres      233 non-null    object\n",
      " 6   gender      233 non-null    object\n",
      " 7   age         233 non-null    int64 \n",
      " 8   occupation  233 non-null    int64 \n",
      " 9   zip         233 non-null    int64 \n",
      "dtypes: int64(7), object(3)\n",
      "memory usage: 18.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 首先对于数据中的特征进行ID化编码，然后使用 `gen_date_set` and `gen_model_input`来生成带有用户历史行为序列的特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1771.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = ['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip']\n",
    "\n",
    "feature_max_idx = {}\n",
    "for feature in features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feature] = lbe.fit_transform(data[feature]) + 1  # 作为Embedding向量的大小设定\n",
    "    feature_max_idx[feature] = data[feature].max() + 1\n",
    "\n",
    "# 构建用户画像\n",
    "user_profile = data[[\"user_id\", \"gender\", \"age\", \"occupation\", \"zip\"]].drop_duplicates('user_id')\n",
    "\n",
    "# 构建物品画像\n",
    "item_profile = data[[\"movie_id\"]].drop_duplicates('movie_id')\n",
    "\n",
    "user_profile.set_index(\"user_id\", inplace=True)\n",
    "\n",
    "user_item_list = data.groupby(\"user_id\")['movie_id'].apply(list)\n",
    "\n",
    "train_set, test_set = gen_data_set(data, negsample)\n",
    "\n",
    "train_model_input, train_label = gen_model_input(train_set, user_profile, SEQ_LEN)\n",
    "test_model_input, test_label = gen_model_input(test_set, user_profile, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': array([2, 2, 2, 2, 2, 2, 3, 2, 1, 3, 2, 1, 2, 1, 1, 3, 2, 2, 2, 2, 2, 2,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 1, 2, 3, 1, 2, 3, 3, 3, 3,\n",
       "        1, 3, 2, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 3, 3, 2, 3, 3, 2, 2, 3,\n",
       "        3, 2, 2, 2, 2, 2, 3, 1, 3, 2, 3, 1, 2, 2, 1, 3, 2, 2, 2, 2, 2, 3,\n",
       "        2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 1, 1, 2, 2, 3, 3, 3, 2, 2,\n",
       "        2, 2, 1, 2, 1, 2, 2, 3, 2, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2,\n",
       "        2, 3, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 3, 3, 1, 2, 1, 2, 2, 1, 2,\n",
       "        2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 3, 1, 3, 1,\n",
       "        2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 3, 3, 2, 1, 2, 2, 2, 2,\n",
       "        3, 3, 1, 2, 2, 2, 2, 1, 1, 3, 1, 2, 1, 2, 1, 2, 3, 2, 2, 1, 1, 2,\n",
       "        2, 2, 1, 3, 3, 1, 1]),\n",
       " 'movie_id': array([141,   2,  10, 208, 205,  91,  37,  37, 147, 137,  46, 164, 157,\n",
       "         55,  66, 168,  42, 106,  24, 127, 171, 103, 150,  79, 111,  17,\n",
       "        189, 190,  90,  75,  11, 192, 130,  72,  47,   7,  15,  93, 158,\n",
       "         67,  68, 162, 183,  88, 172, 193,  14, 180, 207, 174, 194, 152,\n",
       "        204,  84,  80,  65,   9, 147,  31, 197, 120, 169,  28, 151, 113,\n",
       "          5,  83,  59, 206, 123, 177, 155, 130,  34,  64, 161,  97, 127,\n",
       "         71,  77, 119,  67, 188,  70, 179, 100,   4, 108, 107,  36,  56,\n",
       "         73,  45, 154,  98, 138, 136, 140, 139,  23,  13,  26,  29, 195,\n",
       "        203,  86, 126, 105, 118, 182,  99,  18, 131, 184, 145,  23,  31,\n",
       "        109,  63, 200, 185,  38, 132, 160, 124, 133,  95, 168,   6, 201,\n",
       "         77,  49, 114,  57,  53,  44,  61,  89,  87, 149, 144,  74,  50,\n",
       "        126, 163, 198,  41, 142,  32,  48,  16, 199,   1,  96,  51,  52,\n",
       "         43, 122,  19,  30, 148, 101,  78,  84,  25,  85,  76, 153, 170,\n",
       "         20, 196, 116, 135, 183, 202, 117,  21,   8,  35,  54,  70,  11,\n",
       "         66, 115, 166,  82,  40, 180, 121, 143,  80,  81, 175, 144,  62,\n",
       "        128, 125, 129,  69, 128, 102, 146,  58, 176,  12, 165, 159,  82,\n",
       "        132,  22,  68, 173,  33, 187,  71, 167, 178,  27, 191,  60,  94,\n",
       "        181,  39,  92, 156, 112, 104]),\n",
       " 'hist_movie_id': array([[130, 146,  96, ..., 143,  12, 177],\n",
       "        [188,  15, 107, ..., 199, 194,  62],\n",
       "        [187,  98, 138, ..., 195,  25, 118],\n",
       "        ...,\n",
       "        [ 56, 135, 152, ...,   0,   0,   0],\n",
       "        [186,   0,   0, ...,   0,   0,   0],\n",
       "        [ 45, 147, 142, ...,  84, 112, 186]], dtype=int32),\n",
       " 'hist_len': array([ 99,  94,  66,  72,  37, 104,  32, 102,  48,  19,  43,  34, 117,\n",
       "         19,  10,   1, 121, 115,  70,  32,  86, 105,  39,  54, 118, 112,\n",
       "        119,  48, 100,  55,  11,  88,  98,  12,  25,  21,  92,   9,  43,\n",
       "         28,  15,  33,  35,  39,  31,  37,   7,  26,  48,  38,  45,  27,\n",
       "         56,  41,  38,  73, 110,  46,  10,   2, 127,  13,  31, 101,  39,\n",
       "         49,   6,  19,  80,  40,  49,  82,  24,  46,  34,  41,   5,  20,\n",
       "          1,  71,  51,  12,  93,  13,  14,  74, 124,  23,  91,  67,  29,\n",
       "          2,  49,  20,  64,  63, 122,  62,  59,  22, 123,  41,  45,  18,\n",
       "         60,  17,   4,  20,  16,  81,  95,  87,  23,  24,   4,  90,  52,\n",
       "         45,  69,  40,  14,  26,  84,   3,  58,  22,  36,  10,  23,  35,\n",
       "         28,  31, 103,  42,  22, 108,  24,  27,   4,  75,  76,   6,  18,\n",
       "         15,  29,  47,  25,  47,  15,  12,  78,  46,  42,  96,  61,   3,\n",
       "         44,  30, 126,  85,  77, 125,  25,   2,  17,  26,  57, 107, 111,\n",
       "        116,  36,  34,  28,  33,   7,   5,  83,  89,  13,  36,   8,  11,\n",
       "          8, 114,   7,  79,   9,  17,  11,  51,  43,  21,   9,  35,  44,\n",
       "         42,  29, 120,  16,   3,  40,  97,  33,  21,  50,  27,  14,  44,\n",
       "         16, 109,  38,   5,  37,  65,  18,  47,  53,  32,   6,  68, 106,\n",
       "        113,  30,   8,  30,   1,  50]),\n",
       " 'gender': array([2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "        2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2,\n",
       "        2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1,\n",
       "        2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "        2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 2,\n",
       "        2, 2, 1, 2, 2, 1, 1]),\n",
       " 'age': array([3, 3, 3, 3, 3, 3, 2, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 3, 3, 3, 3, 3,\n",
       "        1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 3, 2, 1, 3, 2, 2, 2, 2,\n",
       "        1, 2, 3, 3, 2, 2, 3, 2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 2, 2, 3, 3, 2,\n",
       "        2, 3, 3, 3, 3, 3, 2, 1, 2, 3, 2, 1, 3, 3, 1, 2, 3, 3, 3, 3, 3, 2,\n",
       "        3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 1, 1, 3, 3, 2, 2, 2, 3, 3,\n",
       "        3, 3, 1, 3, 1, 3, 3, 2, 3, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3,\n",
       "        3, 2, 1, 3, 1, 3, 3, 3, 3, 3, 1, 1, 1, 2, 2, 1, 3, 1, 3, 3, 1, 3,\n",
       "        3, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 2, 1, 2, 1,\n",
       "        3, 3, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 3, 3, 2, 2, 3, 1, 3, 3, 3, 3,\n",
       "        2, 2, 1, 3, 3, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1, 3, 2, 3, 3, 1, 1, 3,\n",
       "        3, 3, 1, 2, 2, 1, 1]),\n",
       " 'occupation': array([3, 3, 3, 3, 3, 3, 2, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 3, 3, 3, 3, 3,\n",
       "        1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 3, 2, 1, 3, 2, 2, 2, 2,\n",
       "        1, 2, 3, 3, 2, 2, 3, 2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 2, 2, 3, 3, 2,\n",
       "        2, 3, 3, 3, 3, 3, 2, 1, 2, 3, 2, 1, 3, 3, 1, 2, 3, 3, 3, 3, 3, 2,\n",
       "        3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 1, 1, 3, 3, 2, 2, 2, 3, 3,\n",
       "        3, 3, 1, 3, 1, 3, 3, 2, 3, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3,\n",
       "        3, 2, 1, 3, 1, 3, 3, 3, 3, 3, 1, 1, 1, 2, 2, 1, 3, 1, 3, 3, 1, 3,\n",
       "        3, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 2, 1, 2, 1,\n",
       "        3, 3, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 3, 3, 2, 2, 3, 1, 3, 3, 3, 3,\n",
       "        2, 2, 1, 3, 3, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1, 3, 2, 3, 3, 1, 1, 3,\n",
       "        3, 3, 1, 2, 2, 1, 1]),\n",
       " 'zip': array([3, 3, 3, 3, 3, 3, 2, 3, 1, 2, 3, 1, 3, 1, 1, 2, 3, 3, 3, 3, 3, 3,\n",
       "        1, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 1, 1, 3, 2, 1, 3, 2, 2, 2, 2,\n",
       "        1, 2, 3, 3, 2, 2, 3, 2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 2, 2, 3, 3, 2,\n",
       "        2, 3, 3, 3, 3, 3, 2, 1, 2, 3, 2, 1, 3, 3, 1, 2, 3, 3, 3, 3, 3, 2,\n",
       "        3, 3, 2, 3, 1, 3, 3, 3, 3, 3, 3, 2, 3, 1, 1, 3, 3, 2, 2, 2, 3, 3,\n",
       "        3, 3, 1, 3, 1, 3, 3, 2, 3, 2, 2, 2, 3, 3, 3, 3, 2, 3, 3, 3, 1, 3,\n",
       "        3, 2, 1, 3, 1, 3, 3, 3, 3, 3, 1, 1, 1, 2, 2, 1, 3, 1, 3, 3, 1, 3,\n",
       "        3, 1, 1, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3, 3, 3, 3, 3, 3, 2, 1, 2, 1,\n",
       "        3, 3, 1, 1, 1, 1, 3, 3, 1, 3, 1, 1, 3, 3, 2, 2, 3, 1, 3, 3, 3, 3,\n",
       "        2, 2, 1, 3, 3, 3, 3, 1, 1, 2, 1, 3, 1, 3, 1, 3, 2, 3, 3, 1, 1, 3,\n",
       "        3, 3, 1, 2, 2, 1, 1])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 配置一下模型定义需要的特征列，主要是特征名和embedding词表的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "user_feature_columns = [SparseFeat('user_id', feature_max_idx['user_id'], embedding_dim),\n",
    "                        SparseFeat(\"gender\", feature_max_idx['gender'], embedding_dim),\n",
    "                        SparseFeat(\"age\", feature_max_idx['age'], embedding_dim),\n",
    "                        SparseFeat(\"occupation\", feature_max_idx['occupation'], embedding_dim),\n",
    "                        SparseFeat(\"zip\", feature_max_idx['zip'], embedding_dim),\n",
    "                        VarLenSparseFeat(SparseFeat('hist_movie_id', feature_max_idx['movie_id'], embedding_dim,\n",
    "                                                    embedding_name=\"movie_id\"), SEQ_LEN, 'mean', 'hist_len'),\n",
    "                        ]\n",
    "\n",
    "\n",
    "item_feature_columns = [SparseFeat('movie_id', feature_max_idx['movie_id'], embedding_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='user_id', vocabulary_size=4, embedding_dim=16, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f354b49fc40>, embedding_name='user_id', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='gender', vocabulary_size=3, embedding_dim=16, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f354b49ff70>, embedding_name='gender', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='age', vocabulary_size=4, embedding_dim=16, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f354b49f7f0>, embedding_name='age', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='occupation', vocabulary_size=4, embedding_dim=16, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f354b49fdc0>, embedding_name='occupation', group_name='default_group', trainable=True),\n",
       " SparseFeat(name='zip', vocabulary_size=4, embedding_dim=16, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f354b49f4c0>, embedding_name='zip', group_name='default_group', trainable=True),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_movie_id', vocabulary_size=209, embedding_dim=16, use_hash=False, dtype='int32', embeddings_initializer=<tensorflow.python.keras.initializers.initializers_v1.RandomNormal object at 0x7f354b49fe50>, embedding_name='movie_id', group_name='default_group', trainable=True), maxlen=50, combiner='mean', length_name='hist_len', weight_name=None, weight_norm=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 定义一个YoutubeDNN模型，分别传入用户侧特征列表`user_feature_columns`和物品侧特征列表`item_feature_columns`。然后配置优化器和损失函数，开始进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-292ba1ea5175>:1: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
      "Instructions for updating:\n",
      "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:tensorflow:From /home/oem/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:82: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 227 samples\n",
      "227/227 [==============================] - 0s 10us/sample - loss: 0.5877\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(True)\n",
    "import tensorflow as tf\n",
    "if tf.__version__ >= '2.0.0':\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "model = YoutubeDNN(user_feature_columns, item_feature_columns, num_sampled=5, user_dnn_hidden_units=(64, 16))\n",
    "# model = MIND(user_feature_columns,item_feature_columns,dynamic_k=True,p=1,k_max=2,num_sampled=5,user_dnn_hidden_units=(64,16),init_std=0.001)\n",
    "\n",
    "model.compile(optimizer=\"adagrad\", loss=sampledsoftmaxloss, experimental_run_tf_function=False)  # \"binary_crossentropy\")\n",
    "\n",
    "history = model.fit(train_model_input, train_label,  # train_label,\n",
    "                    batch_size=256, epochs=1, verbose=1, validation_split=0.0, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate user features for testing and full item features for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/oem/anaconda3/envs/zwynn/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "(3, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.42878300e-04, -2.90917342e-05,  5.11118524e-05,\n",
       "         2.78099560e-05,  1.21410012e-04,  4.24649261e-05,\n",
       "         7.85671582e-05,  7.21368269e-05,  3.23963613e-05,\n",
       "        -1.87562582e-05, -1.69102932e-04, -1.20822137e-04,\n",
       "         1.70499668e-04, -1.02522172e-04,  8.23799783e-05,\n",
       "        -1.01446785e-05],\n",
       "       [ 3.77329307e-05,  2.10743765e-05,  6.51213704e-05,\n",
       "         2.44242674e-05,  4.09079912e-05,  1.90657447e-05,\n",
       "         8.69532596e-05, -5.24726929e-05,  2.47771709e-06,\n",
       "        -6.45783584e-05,  6.87255815e-05,  3.87508808e-05,\n",
       "         1.55657690e-04, -1.09456290e-04,  1.91140789e-05,\n",
       "         4.37624039e-05],\n",
       "       [ 6.55593103e-05,  6.00543535e-05,  9.22585173e-07,\n",
       "        -7.92923529e-05,  5.48820135e-05,  2.55651648e-05,\n",
       "         1.08859722e-05,  7.00186501e-05, -1.22338985e-04,\n",
       "        -4.98426416e-05, -7.24236670e-05, -5.57290014e-06,\n",
       "         1.19872311e-04, -5.07092191e-05,  8.66251357e-05,\n",
       "         1.51961256e-04]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_user_model_input = test_model_input\n",
    "all_item_model_input = {\"movie_id\": item_profile['movie_id'].values}\n",
    "\n",
    "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "\n",
    "user_embs = user_embedding_model.predict(test_user_model_input, batch_size=2 ** 12)\n",
    "# user_embs = user_embs[:, i, :]  # i in [0,k_max) if MIND\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "print(user_embs.shape)\n",
    "user_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00037899],\n",
       "       [0.00026067],\n",
       "       [0.00030519]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.linalg.norm(user_embs, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37699947, -0.07676161,  0.13486402,  0.0733795 ,  0.32035312,\n",
       "         0.11204819,  0.20730773,  0.19034062,  0.08548122, -0.04949037,\n",
       "        -0.44619593, -0.31880194,  0.44988135, -0.27051556,  0.21736826,\n",
       "        -0.0267678 ],\n",
       "       [ 0.14475423,  0.08084729,  0.24982406,  0.09369843,  0.15693466,\n",
       "         0.07314161,  0.3335774 , -0.20130014,  0.00950523, -0.24774092,\n",
       "         0.26365083,  0.14865938,  0.5971471 , -0.4199054 ,  0.07332703,\n",
       "         0.167885  ],\n",
       "       [ 0.21481155,  0.19677402,  0.00302294, -0.25980923,  0.17982633,\n",
       "         0.08376679,  0.03566896,  0.22942302, -0.40085578, -0.16331434,\n",
       "        -0.2373033 , -0.01826016,  0.39277348, -0.16615376,  0.2838358 ,\n",
       "         0.49791607]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embs = user_embs / np.linalg.norm(user_embs, axis=1, keepdims=True)\n",
    "user_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999999975563176"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_ = 0 \n",
    "for i in user_embs[0]:\n",
    "    sum_ += i**2\n",
    "np.sqrt(sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3.61168059e-05, -1.15563525e-04,  9.50523681e-05, ...,\n",
       "        -6.13575903e-05,  1.92484094e-05, -7.59257673e-05],\n",
       "       [ 9.92620407e-05,  9.99673139e-05,  7.47564263e-05, ...,\n",
       "         2.79854867e-04, -1.13261231e-04,  4.59334333e-05],\n",
       "       [ 1.21779689e-04,  3.84851082e-05,  7.90571285e-05, ...,\n",
       "         1.18564902e-04,  1.54509089e-05, -5.47535274e-06],\n",
       "       ...,\n",
       "       [ 2.83916102e-04, -2.50865094e-04, -2.67599418e-04, ...,\n",
       "        -8.16918982e-05,  1.55319474e-04,  1.18487726e-04],\n",
       "       [ 1.37671668e-04,  1.70444968e-04, -3.06352231e-05, ...,\n",
       "        -9.51940820e-05, -2.41493690e-05,  4.39387040e-05],\n",
       "       [ 1.12890142e-04,  4.27755658e-05,  1.79081821e-04, ...,\n",
       "         7.08255102e-05,  1.83037235e-04,  3.75794953e-05]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(item_embs.shape)\n",
    "item_embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. [Optional] ANN search by faiss  and evaluate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 450.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall 0.0\n",
      "hr 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_true_label = {line[0]:[line[2]] for line in test_set}\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from deepmatch.utils import recall_N\n",
    "\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "# faiss.normalize_L2(item_embs)\n",
    "index.add(item_embs)\n",
    "# faiss.normalize_L2(user_embs)\n",
    "D, I = index.search(np.ascontiguousarray(user_embs), 50)\n",
    "s = []\n",
    "hit = 0\n",
    "for i, uid in tqdm(enumerate(test_user_model_input['user_id'])):\n",
    "    try:\n",
    "        pred = [item_profile['movie_id'].values[x] for x in I[i]]\n",
    "        filter_item = None\n",
    "        recall_score = recall_N(test_true_label[uid], pred, N=50)\n",
    "        s.append(recall_score)\n",
    "        if test_true_label[uid] in pred:\n",
    "            hit += 1\n",
    "    except:\n",
    "        print(i)\n",
    "print(\"recall\", np.mean(s))\n",
    "print(\"hr\", hit / len(test_user_model_input['user_id']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
