{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新闻推荐\n",
    "**问题描述**：赛题以新闻APP中的新闻推荐为背景，要求选手根据用户历史浏览点击新闻文章的数据信息预测用户未来点击行为，即用户的最后一次点击的新闻文章，测试集对最后一次点击行为进行了剔除。 \n",
    "\n",
    "**评价指标:**   \n",
    "$$\n",
    "score(user) = \\sum_{k=1}^5 \\frac{s(user, k)}{k}\n",
    "$$  \n",
    "\n",
    "**赛题理解：**  \n",
    "\n",
    "**使用方法：**\n",
    "Baseline使用协同过滤的方法进行确定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "SAVE_PATH = \"./checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 节约内存的一个标配函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    \"\"\"对于数值类型的数据进行内存节省\"\"\"\n",
    "    \n",
    "    starttime = time.time()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2  # 统计内存使用情况\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # 装换数据类型\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "                    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,\n",
    "                                                                                                           100*(start_mem-end_mem)/start_mem,\n",
    "                                                                                                           (time.time()-starttime)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取采样或全量数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_click_sample(data_path, samples = 10000):\n",
    "    \"\"\"对数据进行采样\"\"\"\n",
    "    \n",
    "    all_click = pd.read_csv(data_path + \"train_click_log.csv\")\n",
    "    all_user_id = all_click[\"user_id\"].unique()\n",
    "    sample_user_id =  np.random.choice(all_user_id, 10000)  # 进行无放回的采样数据\n",
    "    all_click = all_click[all_click[\"user_id\"].isin(sample_user_id)]\n",
    "\n",
    "    all_click = all_click.drop_duplicates(all_click.columns[:3])\n",
    "    \n",
    "    return all_click\n",
    "\n",
    "# 读取点击数据，这里分成线上和线下，如果是为了获取线上提交结果应该讲测试集中的点击数据合并到总的数据中\n",
    "# 如果是为了线下验证模型的有效性或者特征的有效性，可以只使用训练集\n",
    "def get_all_click_df(data_path='./data/', offline=True):\n",
    "    if offline:\n",
    "        all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    else:\n",
    "        trn_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "\n",
    "        all_click = trn_click.append(tst_click)\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_click_df = get_all_click_df(offline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取用户－文章－点击时间字典\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据点击时间获取用户的点击文章序列   {user1: [(item1, time1), (item2, time2)..]...}\n",
    "def get_user_item_time(click_df):\n",
    "    \n",
    "    click_df = click_df.sort_values('click_timestamp')  # 按照时间升序排列\n",
    "    \n",
    "    def make_item_time_pair(df):\n",
    "        return list(zip(df['click_article_id'], df['click_timestamp']))\n",
    "    \n",
    "    user_item_time_df = click_df.groupby('user_id')['click_article_id', 'click_timestamp'].apply(lambda x: make_item_time_pair(x))\\\n",
    "                                                            .reset_index().rename(columns={0: 'item_time_list'})\n",
    "    user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n",
    "    \n",
    "    return user_item_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取近期点击最多的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_topk_click(click_df, k):\n",
    "    \n",
    "    topk_click = click_df['click_article_id'].value_counts().index[:k]\n",
    "    \n",
    "    return topk_click"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ItemCF的物品相似度计算\n",
    "算法依据：ItemCF算法并不利用物品的内容属性计算物品之间的相似度， 主要通过分析用户的行为记录计算物品之间的相似度， 该算法认为， 物品a和物品c具有很大的相似度是因为喜欢物品a的用户大都喜欢物品c。改进之后，基于公式四进行编写  \n",
    "![](./imgs/item.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemcf_sim(df):\n",
    "    \"\"\"计算物品相似度\"\"\" \n",
    "    \n",
    "    user_item_time_df = get_user_item_time(df)\n",
    "    \n",
    "    i2i_sim = {}\n",
    "    item_cnt = defaultdict(int)  # 初始值为０\n",
    "\n",
    "    # 改进权重的基于物品的协同过滤算法\n",
    "    for user, item_time_list in tqdm(user_item_time_df.items()):\n",
    "            for i, i_click_time in item_time_list:\n",
    "                item_cnt[i] += 1  # 统计喜欢item的用户数目\n",
    "                i2i_sim.setdefault(i, {})\n",
    "                \n",
    "                for j, j_click_time in item_time_list:\n",
    "                    if (i == j):  # 自身和自身之间进行计算相似度\n",
    "                        continue\n",
    "                    i2i_sim[i].setdefault(j, 0)  \n",
    "                    i2i_sim[i][j] += 1/math.log(len(item_time_list) + 1)  # 既喜欢商品i，又喜欢商品j, 同一个用户喜欢的物品就是都喜欢\n",
    "                    \n",
    "    i2i_sim_ = i2i_sim.copy()\n",
    "    for i, related_items in i2i_sim.items():\n",
    "        for j, wij in related_items.items():\n",
    "            i2i_sim_[i][j] = wij/math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "    \n",
    "    # 保存数据\n",
    "    pickle.dump(i2i_sim_, open(SAVE_PATH + \"itemCF_sim.pkl\", \"wb\"))\n",
    "    \n",
    "    return i2i_sim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:25<00:00, 9621.65it/s] \n"
     ]
    }
   ],
   "source": [
    "i2i_sim = itemcf_sim(all_click_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ItemCF的文章推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    user_hist_items = user_item_time_dict[user_id]  # 找出用户历史文章点击\n",
    "    user_hist_items_ = {user_id for user_id, _ in user_hist_items}\n",
    "    \n",
    "    \n",
    "    item_rank = {}\n",
    "    for loc, (i, click_time) in enumerate(user_hist_items):\n",
    "        # 找出用户度过文章中最相似的文章回合,从高到底\n",
    "        for j, wij in sorted(i2i_sim[i].items(), key=lambda x:x[1], reverse=True)[:sim_item_topk]:  # 选择与当前文章最相似的k篇文章\n",
    "            if j in user_hist_items_:  # 已经存在的商品\n",
    "                continue\n",
    "                \n",
    "            item_rank.setdefault(j, 0) # 召回\n",
    "            item_rank[j] += wij\n",
    "    \n",
    "    # 不足10个商品，进行热门商品补全\n",
    "    if len(item_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in item_rank.items():\n",
    "                continue\n",
    "            item_rank[item] = - i - 100  # 后补全的商品应的重要性应不能高于已推荐商品的重要性\n",
    "    \n",
    "            if len(item_rank) == recall_item_num:\n",
    "                break\n",
    "                \n",
    "    item_rank = sorted(item_rank.items(), key=lambda x:x[1], reverse=True)[:recall_item_num]\n",
    "\n",
    "    return item_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## 给每位用户根据物品的协同过滤推荐文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [53:43<00:00, 77.56it/s] \n"
     ]
    }
   ],
   "source": [
    "# 统计召回\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "\n",
    "# 用户物品字典\n",
    "user_item_time_dict = get_user_item_time(all_click_df)\n",
    "\n",
    "i2i_sim = pickle.load(open(SAVE_PATH + \"itemCF_sim.pkl\", \"rb\"))\n",
    "\n",
    "# 相似文章数量\n",
    "sim_item_topk = 10\n",
    "\n",
    "# 召回文章数量\n",
    "recall_item_num = 10\n",
    "\n",
    "# 用户热度补全\n",
    "item_topk_click = get_item_topk_click(all_click_df, k = 50)\n",
    "\n",
    "# 为用户推荐商品\n",
    "for user in tqdm(all_click_df[\"user_id\"].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 装换数据到DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:04<00:00, 50649.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# 将字典的形式转换成df\n",
    "user_item_score_list = []\n",
    "\n",
    "for user, items in tqdm(user_recall_items_dict.items()):\n",
    "    for item, score in items:\n",
    "        user_item_score_list.append([user, item, score])\n",
    "\n",
    "recall_df = pd.DataFrame(user_item_score_list, columns=['user_id', 'click_article_id', 'pred_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199999</td>\n",
       "      <td>276970</td>\n",
       "      <td>0.172377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199999</td>\n",
       "      <td>158536</td>\n",
       "      <td>0.106969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199999</td>\n",
       "      <td>286321</td>\n",
       "      <td>0.097774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199999</td>\n",
       "      <td>108855</td>\n",
       "      <td>0.092462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199999</td>\n",
       "      <td>162655</td>\n",
       "      <td>0.091407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499995</th>\n",
       "      <td>200000</td>\n",
       "      <td>187005</td>\n",
       "      <td>0.071191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499996</th>\n",
       "      <td>200000</td>\n",
       "      <td>50573</td>\n",
       "      <td>0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499997</th>\n",
       "      <td>200000</td>\n",
       "      <td>63344</td>\n",
       "      <td>0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499998</th>\n",
       "      <td>200000</td>\n",
       "      <td>255153</td>\n",
       "      <td>0.068034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499999</th>\n",
       "      <td>200000</td>\n",
       "      <td>195603</td>\n",
       "      <td>0.065900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  pred_score\n",
       "0         199999            276970    0.172377\n",
       "1         199999            158536    0.106969\n",
       "2         199999            286321    0.097774\n",
       "3         199999            108855    0.092462\n",
       "4         199999            162655    0.091407\n",
       "...          ...               ...         ...\n",
       "2499995   200000            187005    0.071191\n",
       "2499996   200000             50573    0.071180\n",
       "2499997   200000             63344    0.071180\n",
       "2499998   200000            255153    0.068034\n",
       "2499999   200000            195603    0.065900\n",
       "\n",
       "[2500000 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成submit提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    \n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "#     判断是不是每个用户都有5篇文章及以上\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk\n",
    "    \n",
    "    del recall_df['pred_score']\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    save_name = SAVE_PATH + model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([249999, 249998, 249997, ..., 200002, 200001, 200000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取测试集\n",
    "tst_click = pd.read_csv(DATA_PATH + 'testA_click_log.csv')\n",
    "tst_users = tst_click['user_id'].unique()\n",
    "tst_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000000</th>\n",
       "      <td>249999</td>\n",
       "      <td>234698</td>\n",
       "      <td>0.280279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000001</th>\n",
       "      <td>249999</td>\n",
       "      <td>95716</td>\n",
       "      <td>0.245980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000002</th>\n",
       "      <td>249999</td>\n",
       "      <td>336223</td>\n",
       "      <td>0.244608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000003</th>\n",
       "      <td>249999</td>\n",
       "      <td>160132</td>\n",
       "      <td>0.227058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000004</th>\n",
       "      <td>249999</td>\n",
       "      <td>59057</td>\n",
       "      <td>0.205233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499995</th>\n",
       "      <td>200000</td>\n",
       "      <td>187005</td>\n",
       "      <td>0.071191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499996</th>\n",
       "      <td>200000</td>\n",
       "      <td>50573</td>\n",
       "      <td>0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499997</th>\n",
       "      <td>200000</td>\n",
       "      <td>63344</td>\n",
       "      <td>0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499998</th>\n",
       "      <td>200000</td>\n",
       "      <td>255153</td>\n",
       "      <td>0.068034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499999</th>\n",
       "      <td>200000</td>\n",
       "      <td>195603</td>\n",
       "      <td>0.065900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  pred_score\n",
       "2000000   249999            234698    0.280279\n",
       "2000001   249999             95716    0.245980\n",
       "2000002   249999            336223    0.244608\n",
       "2000003   249999            160132    0.227058\n",
       "2000004   249999             59057    0.205233\n",
       "...          ...               ...         ...\n",
       "2499995   200000            187005    0.071191\n",
       "2499996   200000             50573    0.071180\n",
       "2499997   200000             63344    0.071180\n",
       "2499998   200000            255153    0.068034\n",
       "2499999   200000            195603    0.065900\n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从所有的召回数据中将测试集中的用户选出来\n",
    "tst_recall = recall_df[recall_df['user_id'].isin(tst_users)]\n",
    "tst_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成提交文件\n",
    "submit(tst_recall, topk=5, model_name='itemcf_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参考\n",
    "[pandas内存优化](https://blog.csdn.net/weiyongle1996/article/details/78498603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id,article_1,article_2,article_3,article_4,article_5\n",
      "200000,237870,194619,194935,314048,195773\n",
      "200001,64329,272143,199198,324823,166581\n",
      "200002,300128,300923,61375,293301,298035\n",
      "200003,337143,272143,156619,235230,158536\n",
      "200004,235870,235616,336223,261612,156964\n",
      "200005,69932,160974,156964,160417,158536\n",
      "200006,199197,284547,235230,183176,206934\n",
      "200007,289003,157478,97530,218028,66672\n",
      "200008,235870,300082,156560,64409,336223\n"
     ]
    }
   ],
   "source": [
    "!head -10 checkpoints/itemcf_baseline_12-08.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
