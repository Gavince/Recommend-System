{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 多目标学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据\n",
    "### 人口普查数据简介\n",
    "\n",
    "\n",
    "数据集信息：\n",
    "```\n",
    "Barry Becker 从 1994 年人口普查数据库中提取。使用以下条件提取了一组合理干净的记录： ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "\n",
    "预测任务是确定一个人是否赚了超过 50K年。\n",
    "\n",
    ">50K，<=50K。\n",
    "属性列表：\n",
    "年龄：连续。\n",
    "工作班级：私人、Self-emp-not-inc、Self-emp-inc、联邦政府、地方政府、州政府、无薪、从未工作。\n",
    "fnlwgt：连续。\n",
    "教育：学士，一些大学，11th，HS-grad，教授学校，Assoc-acdm，Assoc-voc，9th，7th-8th，12th，硕士，1st-4th，10th，博士，5th-6th，学前班。\n",
    "教育编号：连续。\n",
    "婚姻状况：已婚公民配偶、离婚、未婚、分居、丧偶、已婚配偶缺席、已婚 AF 配偶。\n",
    "职业：技术支持、工艺维修、其他服务、销售、执行管理、专业教授、处理清洁工、机器操作检查、行政文员、农业-捕鱼、运输-搬家、私人住宅- serv，保护性服务，武装部队。\n",
    "关系：妻子、自己的孩子、丈夫、非家庭成员、其他亲属、未婚。\n",
    "种族：白人、亚太岛民、美洲印第安人-爱斯基摩人、其他、黑人。\n",
    "性别：女，男。\n",
    "资本收益：持续。\n",
    "资本损失：持续。\n",
    "每周小时数：连续。\n",
    "祖国：美国、柬埔寨、英国、波多黎各、加拿大、德国、美国边远地区（关岛-USVI-etc）、印度、日本、希腊、南部、中国、古巴、伊朗、洪都拉斯、菲律宾、意大利、波兰、牙买加、越南、墨西哥、葡萄牙、爱尔兰、法国、多米尼加共和国、老挝、厄瓜多尔、台湾、海地、哥伦比亚、匈牙利、危地马拉、尼加拉瓜、苏格兰、泰国、南斯拉夫、萨尔瓦多、特立纳达和多巴哥、秘鲁、香港，荷兰-荷兰。\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu102\n",
      "10.2\n",
      "7605\n",
      "GeForce GTX 950M\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "import torchsnooper\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "import sys\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets.py  Income  __init__.py\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=c8aad51c-2b72-468d-8bae-5a5f2603ad71 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('c8aad51c-2b72-468d-8bae-5a5f2603ad71').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country income_50k  \n",
       "0          2174             0              40   United-States      <=50K  \n",
       "1             0             0              13   United-States      <=50K  \n",
       "2             0             0              40   United-States      <=50K  \n",
       "3             0             0              40   United-States      <=50K  \n",
       "4             0             0              40            Cuba      <=50K  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation',\n",
    "                'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "                'income_50k']\n",
    "train_df = pd.read_csv(\"../data/Income/adult.data\", header=None, names=column_names)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education_num   32561 non-null  int64 \n",
      " 5   marital_status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital_gain    32561 non-null  int64 \n",
      " 11  capital_loss    32561 non-null  int64 \n",
      " 12  hours_per_week  32561 non-null  int64 \n",
      " 13  native_country  32561 non-null  object\n",
      " 14  income_50k      32561 non-null  object\n",
      " 15  tag             32561 non-null  int64 \n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=cd939b55-84f2-4a36-bbab-ad6410e934da style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('cd939b55-84f2-4a36-bbab-ad6410e934da').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>|1x3 Cross validator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323.0</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                    age   workclass    fnlwgt      education  education_num  \\\n",
       "0  |1x3 Cross validator         NaN       NaN            NaN            NaN   \n",
       "1                    25     Private  226802.0           11th            7.0   \n",
       "2                    38     Private   89814.0        HS-grad            9.0   \n",
       "3                    28   Local-gov  336951.0     Assoc-acdm           12.0   \n",
       "4                    44     Private  160323.0   Some-college           10.0   \n",
       "\n",
       "        marital_status          occupation relationship    race    sex  \\\n",
       "0                  NaN                 NaN          NaN     NaN    NaN   \n",
       "1        Never-married   Machine-op-inspct    Own-child   Black   Male   \n",
       "2   Married-civ-spouse     Farming-fishing      Husband   White   Male   \n",
       "3   Married-civ-spouse     Protective-serv      Husband   White   Male   \n",
       "4   Married-civ-spouse   Machine-op-inspct      Husband   Black   Male   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country income_50k  \n",
       "0           NaN           NaN             NaN             NaN        NaN  \n",
       "1           0.0           0.0            40.0   United-States     <=50K.  \n",
       "2           0.0           0.0            50.0   United-States     <=50K.  \n",
       "3           0.0           0.0            40.0   United-States      >50K.  \n",
       "4        7688.0           0.0            40.0   United-States      >50K.  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/Income/adult.test\", delimiter=\",\", names=column_names, header=None\n",
    "                      )\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置标记\n",
    "train_df[\"tag\"] = 1\n",
    "test_df[\"tag\"] = 0\n",
    "# 划分数据\n",
    "test_df.dropna(inplace=True)\n",
    "# 规范化数据\n",
    "test_df[\"income_50k\"] = test_df[\"income_50k\"].apply(lambda x: x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并数据\n",
    "data = pd.concat([train_df, test_df])\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns = ['income_50k', 'marital_status']\n",
    "\n",
    "# categorical columns\n",
    "categorical_columns = ['workclass', 'education', 'occupation',\n",
    "                       'relationship', 'race', 'sex', 'native_country']\n",
    "for col in label_columns:\n",
    "    if col == 'income_50k':\n",
    "        data[col] = data[col].apply(lambda x: 0 if x == ' <=50K' else 1)\n",
    "    else:\n",
    "        data[col] = data[col].apply(\n",
    "            lambda x: 0 if x == ' Never-married' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engine\n",
    "for col in column_names:\n",
    "    if col not in label_columns + ['tag']:\n",
    "        if col in categorical_columns:\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "        else:\n",
    "            mm = MinMaxScaler()\n",
    "            data[col] = mm.fit_transform(data[[col]]).reshape(-1)\n",
    "\n",
    "data = data[['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'occupation',\n",
    "             'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'income_50k', 'marital_status', 'tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码用户特征和物品特征\n",
    "user_feat_dict, item_feat_dict = dict(), dict()\n",
    "\n",
    "for idx, col in enumerate(data.columns):\n",
    "    if col not in label_columns + [\"tag\"]:\n",
    "        #　用户特征\n",
    "        if idx < 7:\n",
    "            if col in categorical_columns:\n",
    "                user_feat_dict[col] = (data[col].nunique() + 1, idx)\n",
    "            else:\n",
    "                user_feat_dict[col] = (1, idx)\n",
    "        # 物品特征\n",
    "        else:\n",
    "            if col in categorical_columns:\n",
    "                item_feat_dict[col] = (data[col].nunique() + 1, idx)\n",
    "            else:\n",
    "                item_feat_dict[col] = (1, idx)\n",
    "\n",
    "                user_feat_dict, item_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新划分数据集\n",
    "train_data, test_data = data[data[\"tag\"] == 1], data[data[\"tag\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns=\"tag\", inplace=True)\n",
    "test_data.drop(columns=\"tag\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': (1, 0),\n",
       " 'workclass': (10, 1),\n",
       " 'fnlwgt': (1, 2),\n",
       " 'education': (17, 3),\n",
       " 'education_num': (1, 4),\n",
       " 'occupation': (16, 5),\n",
       " 'relationship': (7, 6)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/Income/user_feat_dict.npy\", user_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../data/Income/item_feat_dict.npy\", item_feat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=1688f88e-4de5-4a3c-af05-08524d762672 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('1688f88e-4de5-4a3c-af05-08524d762672').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_50k</th>\n",
       "      <th>marital_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.301370</td>\n",
       "      <td>7</td>\n",
       "      <td>0.044131</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.452055</td>\n",
       "      <td>6</td>\n",
       "      <td>0.048052</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.287671</td>\n",
       "      <td>4</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>11</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.493151</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150486</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.150685</td>\n",
       "      <td>4</td>\n",
       "      <td>0.220635</td>\n",
       "      <td>9</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.397959</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education_num  occupation  \\\n",
       "0  0.301370          7  0.044131          9       0.800000           1   \n",
       "1  0.452055          6  0.048052          9       0.800000           4   \n",
       "2  0.287671          4  0.137581         11       0.533333           6   \n",
       "3  0.493151          4  0.150486          1       0.400000           6   \n",
       "4  0.150685          4  0.220635          9       0.800000          10   \n",
       "\n",
       "   relationship  race  sex  capital_gain  capital_loss  hours_per_week  \\\n",
       "0             1     4    1       0.02174           0.0        0.397959   \n",
       "1             0     4    1       0.00000           0.0        0.122449   \n",
       "2             1     4    1       0.00000           0.0        0.397959   \n",
       "3             0     2    1       0.00000           0.0        0.397959   \n",
       "4             5     2    0       0.00000           0.0        0.397959   \n",
       "\n",
       "   native_country  income_50k  marital_status  \n",
       "0              39           0               0  \n",
       "1              39           0               1  \n",
       "2              39           0               1  \n",
       "3              39           0               1  \n",
       "4               5           0               1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义数据格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDateSet(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "\n",
    "        self.features = data[0]\n",
    "        self.label1 = data[1]\n",
    "        self.label2 = data[2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        return self.features[index], self.label1[index], self.label2[index]\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载Dataloader\n",
    "train_datasets = (train_data.iloc[:, :-2].values,\n",
    "                  train_data.iloc[:, -2].values, train_data.iloc[:, -1].values)\n",
    "test_datasets = (test_data.iloc[:, :-2].values,\n",
    "                 test_data.iloc[:, -2].values, test_data.iloc[:, -1].values)\n",
    "train_datasets = TrainDateSet(train_datasets)\n",
    "test_datasets = TrainDateSet(test_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SharedBottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layer import DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedBottom(nn.Module):\n",
    "\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, activation=\"relu\",\n",
    "                 bottom_hidden_size=[256, 128], tower_hidden_size=[128, 64], num_tasks=2, tasks_name=[\"ctr\", \"cvr\"],\n",
    "                 use_bn=False, dropout_rate=0, seed=1024):\n",
    "        \"\"\"\n",
    "\n",
    "        :param user_feature_dict:\n",
    "        :param item_feature_dict:\n",
    "        :param emb_dim:\n",
    "        :param activation:\n",
    "        :param bottom_hidden_size:\n",
    "        :param tower_hidden_size:\n",
    "        :param num_tasks:\n",
    "        :param tasks_num:\n",
    "        :param use_bn:\n",
    "        :param dropout_rate:\n",
    "        :param seed:\n",
    "        \"\"\"\n",
    "\n",
    "        super(SharedBottom, self).__init__()\n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            Exception(\"用户特征和物品特征不能为空！\")\n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict):\n",
    "            Exception(\"输入数据类型必须为字典类型！\")\n",
    "\n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "        self.num_tasks = num_tasks\n",
    "        self.tasks_name = tasks_name\n",
    "\n",
    "        # 构建Embedding输入\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            # 必须为Spase Feature\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "        # 物品特征\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # Spase feat + Dense feat\n",
    "        input_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) \\\n",
    "            + (len(self.user_feature_dict) - user_cate_feature_nums) \\\n",
    "            + (len(self.item_feature_dict) - item_cate_feature_nums)\n",
    "        # 共享层\n",
    "        self.shared_bottom_layer = DNN(input_dim=input_size, hidden_units=bottom_hidden_size,\n",
    "                                       activation=activation, use_bn=use_bn, dropout_rate=dropout_rate)\n",
    "        # 子任务层\n",
    "        for i in range(num_tasks):\n",
    "            setattr(self, \"tower_{}_dnn\".format(tasks_name[i]), nn.Sequential(DNN(input_dim=bottom_hidden_size[-1],\n",
    "                                                                                  hidden_units=tower_hidden_size,\n",
    "                                                                                  activation=activation,\n",
    "                                                                                  use_bn=use_bn,\n",
    "                                                                                  dropout_rate=dropout_rate),\n",
    "                                                                              nn.Linear(tower_hidden_size[-1], 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_embed_list, item_embed_list = list(), list()\n",
    "        for user_feature, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_embed_list.append(\n",
    "                    getattr(self, user_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                user_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        for item_feature, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_embed_list.append(\n",
    "                    getattr(self, item_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                item_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        # 拼接向量\n",
    "        user_embed = torch.cat(user_embed_list, dim=1)\n",
    "        item_embed = torch.cat(item_embed_list, dim=1)\n",
    "        dnn_input = torch.cat([user_embed, item_embed], axis=1).float()\n",
    "        # bottom_layer\n",
    "        shared_bottom_output = self.shared_bottom_layer(dnn_input)\n",
    "        # tower_layer\n",
    "        task_outputs = []\n",
    "        for i in range(self.num_tasks):\n",
    "            net = getattr(self, \"tower_{}_dnn\".format(self.tasks_name[i]))\n",
    "            dnn_output = net(shared_bottom_output)\n",
    "            task_outputs.append(dnn_output)\n",
    "\n",
    "        return task_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SharedBottom(\n",
       "  (user_id): Embedding(11, 128)\n",
       "  (user_list): Embedding(12, 128)\n",
       "  (item_id): Embedding(8, 128)\n",
       "  (item_cate): Embedding(6, 128)\n",
       "  (shared_bottom_layer): DNN(\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=514, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (activation_layers): ModuleList(\n",
       "      (0): ReLU(inplace=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (tower_ctr_dnn): Sequential(\n",
       "    (0): DNN(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (activation_layers): ModuleList(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (tower_cvr_dnn): Sequential(\n",
       "    (0): DNN(\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "      (linears): ModuleList(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (activation_layers): ModuleList(\n",
       "        (0): ReLU(inplace=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([[1, 2, 4, 2, 0.5, 0.1],\n",
    "                               [4, 5, 3, 8, 0.6, 0.43],\n",
    "                               [6, 3, 2, 9, 0.12, 0.32],\n",
    "                               [9, 1, 1, 1, 0.12, 0.45],\n",
    "                               [8, 3, 1, 4, 0.21, 0.67]]))\n",
    "\n",
    "user_cate_dict = {'user_id': (11, 0), 'user_list': (12, 3), 'user_num': (1, 4)}\n",
    "item_cate_dict = {'item_id': (8, 1), 'item_cate': (6, 2), 'item_num': (1, 5)}\n",
    "sharedbottom = SharedBottom(user_cate_dict, item_cate_dict)\n",
    "sharedbottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0296],\n",
       "         [0.0277],\n",
       "         [0.0427],\n",
       "         [0.0281],\n",
       "         [0.0316]], grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.0012],\n",
       "         [-0.0032],\n",
       "         [-0.0080],\n",
       "         [ 0.0052],\n",
       "         [-0.0049]], grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharedbottom(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = SummaryWriter(log_dir=\"./log\", comment=\"sharedbottom\")\n",
    "w.add_graph(sharedbottom, a)\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESMM模型\n",
    "![](./imgs/ESMM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESMM(nn.Module):\n",
    "\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, hidden_dim=[128, 64], dropouts=[0.5, 0.5],\n",
    "                 output_size=1, task_name=[\"ctr\", \"cvr\"]):\n",
    "        \"\"\"\n",
    "\n",
    "        :param user_feature_dict: 用户特征\n",
    "        :param item_feature_dict:　物品特征\n",
    "        :param emb_dim: 128\n",
    "        :param hidden_dim: [128, 64]\n",
    "        :param dropout: 0.5\n",
    "        :param output_size: 1\n",
    "        :param num_tasks:2\n",
    "        \"\"\"\n",
    "        super(ESMM, self).__init__()\n",
    "\n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            Exception(\"用户特征和物品特征不能为空！\")\n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict):\n",
    "            Exception(\"输入数据类型必须为字典类型！\")\n",
    "\n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "        self.num_tasks = len(task_name)\n",
    "        self.task_name = task_name\n",
    "\n",
    "        # 共享Embedding(Share bottom)\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "        # 用户特征Embedding编码\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            # 必须为Spase Feature\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "        # 物品特征\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # 构建独立任务（tower）\n",
    "        # Spase feat + Dense feat\n",
    "        hidden_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) \\\n",
    "            + (len(self.user_feature_dict) - user_cate_feature_nums) \\\n",
    "            + (len(self.item_feature_dict) - item_cate_feature_nums)\n",
    "\n",
    "        for i in range(self.num_tasks):\n",
    "            setattr(self, 'task_{}_dnn'.format(\n",
    "                self.task_name[i]), nn.ModuleList())\n",
    "            hid_dim = [hidden_size] + hidden_dim\n",
    "            for j in range(len(hid_dim) - 1):\n",
    "                getattr(self, 'task_{}_dnn'.format(self.task_name[i])).add_module('hidden_{}'.format(j),\n",
    "                                                                                  nn.Linear(hid_dim[j], hid_dim[j + 1]))\n",
    "                getattr(self, 'task_{}_dnn'.format(self.task_name[i])).add_module('batchnorm_{}'.format(j),\n",
    "                                                                                  nn.BatchNorm1d(hid_dim[j + 1]))\n",
    "                getattr(self, \"task_{}_dnn\".format(self.task_name[i])).add_module(\n",
    "                    \"{}_activation\".format(task_name[i]), nn.ReLU())\n",
    "                getattr(self, 'task_{}_dnn'.format(self.task_name[i])).add_module('dropout_{}'.format(j),\n",
    "                                                                                  nn.Dropout(dropouts[j]))\n",
    "            getattr(self, 'task_{}_dnn'.format(self.task_name[i])).add_module('task_{}_last_layer'.format(j),\n",
    "                                                                              nn.Linear(hid_dim[-1], output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #         assert x.size()[1] != len(self.item_feature_dict) + len(self.user_feature_dict)\n",
    "        # 编码Embedding向量\n",
    "        user_embed_list, item_embed_list = list(), list()\n",
    "        for user_feature, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_embed_list.append(\n",
    "                    getattr(self, user_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                user_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        for item_feature, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_embed_list.append(\n",
    "                    getattr(self, item_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                item_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        # 拼接向量\n",
    "        user_embed = torch.cat(user_embed_list, dim=1)\n",
    "        item_embed = torch.cat(item_embed_list, dim=1)\n",
    "        # hidden_input\n",
    "        hidden = torch.cat([user_embed, item_embed], axis=1).float()\n",
    "\n",
    "        # 子网络\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_tasks):\n",
    "            x = hidden\n",
    "            # 　Module list\n",
    "            for mod in getattr(self, 'task_{}_dnn'.format(self.task_name[i])):\n",
    "                x = mod(x)\n",
    "            task_outputs.append(x)\n",
    "\n",
    "        if self.num_tasks == 2:\n",
    "\n",
    "            pCTCVR = torch.mul(task_outputs[0], task_outputs[1])\n",
    "            pCVR = task_outputs[0]\n",
    "\n",
    "            return pCTCVR, pCVR\n",
    "        elif len(self.num_tasks) == 1:\n",
    "            return task_outputs\n",
    "        else:\n",
    "            Exception(\"目标数目为：1或２!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESMM(\n",
       "  (user_id): Embedding(11, 128)\n",
       "  (user_list): Embedding(12, 128)\n",
       "  (item_id): Embedding(8, 128)\n",
       "  (item_cate): Embedding(6, 128)\n",
       "  (task_ctr_dnn): ModuleList(\n",
       "    (hidden_0): Linear(in_features=514, out_features=128, bias=True)\n",
       "    (batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (ctr_activation): ReLU()\n",
       "    (dropout_0): Dropout(p=0.5, inplace=False)\n",
       "    (hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "    (task_1_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (task_cvr_dnn): ModuleList(\n",
       "    (hidden_0): Linear(in_features=514, out_features=128, bias=True)\n",
       "    (batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (cvr_activation): ReLU()\n",
       "    (dropout_0): Dropout(p=0.5, inplace=False)\n",
       "    (hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_1): Dropout(p=0.5, inplace=False)\n",
       "    (task_1_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([[1, 2, 4, 2, 0.5, 0.1],\n",
    "                               [4, 5, 3, 8, 0.6, 0.43],\n",
    "                               [6, 3, 2, 9, 0.12, 0.32],\n",
    "                               [9, 1, 1, 1, 0.12, 0.45],\n",
    "                               [8, 3, 1, 4, 0.21, 0.67]]))\n",
    "\n",
    "user_cate_dict = {'user_id': (11, 0), 'user_list': (12, 3), 'user_num': (1, 4)}\n",
    "item_cate_dict = {'item_id': (8, 1), 'item_cate': (6, 2), 'item_num': (1, 5)}\n",
    "esmm = ESMM(user_cate_dict, item_cate_dict)\n",
    "esmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[-0.1273],\n",
      "        [-0.0721],\n",
      "        [ 1.5535],\n",
      "        [-1.1940],\n",
      "        [ 0.3143]], grad_fn=<MulBackward0>), tensor([[ 0.1851],\n",
      "        [-0.0953],\n",
      "        [ 1.0790],\n",
      "        [-0.7394],\n",
      "        [-0.7482]], grad_fn=<AddmmBackward>))\n"
     ]
    }
   ],
   "source": [
    "tasks = esmm(a)\n",
    "print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = SummaryWriter(log_dir=\"./log\", comment=\"model info\")\n",
    "# w.add_graph(esmm, a)\n",
    "# w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMoE\n",
    "![](./imgs/mmoe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torchsnooper.snoop()\n",
    "class MMoE(nn.Module):\n",
    "\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, n_expert=3, mmoe_hidden_dim=128,\n",
    "                 hidden_dim=[128, 64], output_size=1, num_tasks=2, expert_activation=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param user_feature_dict:\n",
    "        :param item_feature_dict:\n",
    "        :param emb_dim:\n",
    "        :param n_expert:\n",
    "        :param mmoe_hidden_dim:\n",
    "        :param hidden_dim:\n",
    "        :param output_size:\n",
    "        :param num_tasks:\n",
    "        \"\"\"\n",
    "        super(MMoE, self).__init__()\n",
    "\n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            Exception(\"用户特征和物品特征不能为空！\")\n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict):\n",
    "            Exception(\"输入数据类型必须为字典类型！\")\n",
    "\n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        # 共享Embedding(Share bottom)\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "        # 用户特征Embedding编码\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            # 必须为Spase Feature\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "        # 物品特征\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # 构建独立任务（tower）\n",
    "        # Spase feat + Dense feat\n",
    "        hidden_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) \\\n",
    "            + (len(self.user_feature_dict) - user_cate_feature_nums) \\\n",
    "            + (len(self.item_feature_dict) - item_cate_feature_nums)\n",
    "\n",
    "        # 专家网络\n",
    "        self.erperts = torch.nn.Parameter(torch.rand(\n",
    "            hidden_size, mmoe_hidden_dim, n_expert), requires_grad=True)\n",
    "        self.erperts.data.normal_(0, 1)\n",
    "        self.erperts_bias = torch.nn.Parameter(torch.rand(\n",
    "            mmoe_hidden_dim, n_expert), requires_grad=True)\n",
    "\n",
    "        # 门控网络\n",
    "        self.gates = torch.nn.ParameterList([torch.nn.Parameter(torch.rand(hidden_size, n_expert), requires_grad=True)\n",
    "                                             for _ in range(num_tasks)])\n",
    "        for gate in self.gates:\n",
    "            gate.data.normal_(0, 1,)\n",
    "\n",
    "        self.gate_bias = torch.nn.ParameterList([torch.nn.Parameter(\n",
    "            torch.rand(n_expert), requires_grad=True) for _ in range(num_tasks)])\n",
    "\n",
    "        for i in range(self.num_tasks):\n",
    "            setattr(self, 'task_{}_dnn'.format(i + 1), nn.ModuleList())\n",
    "            # input: mmoe_hidden_dim + hidden_dim\n",
    "            hid_dim = [mmoe_hidden_dim] + hidden_dim\n",
    "            for j in range(len(hid_dim) - 1):\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('hidden_{}'.format(j),\n",
    "                                                                      nn.Linear(hid_dim[j], hid_dim[j + 1]))\n",
    "                getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('batchnorm_{}'.format(j),\n",
    "                                                                      nn.BatchNorm1d(hid_dim[j + 1]))\n",
    "            getattr(self, 'task_{}_dnn'.format(i + 1)).add_module('task_last_layer',\n",
    "                                                                  nn.Linear(hid_dim[-1], output_size))\n",
    "\n",
    "        self.Softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        assert x.size()[1] == len(self.item_feature_dict) + \\\n",
    "            len(self.user_feature_dict)\n",
    "        # 编码Embedding向量\n",
    "        user_embed_list, item_embed_list = list(), list()\n",
    "        for user_feature, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_embed_list.append(\n",
    "                    getattr(self, user_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                user_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        for item_feature, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_embed_list.append(\n",
    "                    getattr(self, item_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                item_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        # 拼接向量\n",
    "        user_embed = torch.cat(user_embed_list, dim=1)\n",
    "        item_embed = torch.cat(item_embed_list, dim=1)\n",
    "        # hidden_input\n",
    "        # B*hidden\n",
    "        hidden = torch.cat([user_embed, item_embed], dim=1).float()\n",
    "        # MMoE\n",
    "        expert_outs = torch.matmul(hidden, self.erperts.permute(\n",
    "            1, 0, 2)).permute(1, 0, 2)  # B*mmoe_hidden_dim*experts\n",
    "        expert_outs += self.erperts_bias\n",
    "        # 门控单元\n",
    "        gates_out = list()\n",
    "        for idx, gate in enumerate(self.gates):\n",
    "            gate_out = torch.mm(hidden, gate)  # B * num_experts\n",
    "            if self.gate_bias:\n",
    "                gate_out += self.gate_bias[idx]\n",
    "            # 归一化\n",
    "            gate_out = self.Softmax(gate_out)\n",
    "            gates_out.append(gate_out)\n",
    "        # 各个模块\n",
    "        outs = list()\n",
    "        for gate_out in gates_out:\n",
    "            expand_gate_out = torch.unsqueeze(\n",
    "                gate_out, dim=1)  # B * 1 * experts\n",
    "            weighted_expert_output = expert_outs * \\\n",
    "                expand_gate_out.expand_as(\n",
    "                    expert_outs)  # B * mmoe_hidden * expert\n",
    "            # B * mmoe_hidden\n",
    "            outs.append(torch.sum(weighted_expert_output, 2))\n",
    "\n",
    "        # task_tower\n",
    "        task_outputs = list()\n",
    "        for i in range(self.num_tasks):\n",
    "            x = outs[i]\n",
    "            for mod in getattr(self, 'task_{}_dnn'.format(i + 1)):\n",
    "                x = mod(x)\n",
    "            task_outputs.append(x)\n",
    "\n",
    "        return task_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMoE(\n",
       "  (user_id): Embedding(11, 128)\n",
       "  (user_list): Embedding(12, 128)\n",
       "  (item_id): Embedding(8, 128)\n",
       "  (item_cate): Embedding(6, 128)\n",
       "  (gates): ParameterList(\n",
       "      (0): Parameter containing: [torch.FloatTensor of size 514x3]\n",
       "      (1): Parameter containing: [torch.FloatTensor of size 514x3]\n",
       "  )\n",
       "  (gate_bias): ParameterList(\n",
       "      (0): Parameter containing: [torch.FloatTensor of size 3]\n",
       "      (1): Parameter containing: [torch.FloatTensor of size 3]\n",
       "  )\n",
       "  (task_1_dnn): ModuleList(\n",
       "    (hidden_0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (task_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (task_2_dnn): ModuleList(\n",
       "    (hidden_0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (batchnorm_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (hidden_1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (batchnorm_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (task_last_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (Softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([[1, 2, 4, 2, 0.5, 0.1],\n",
    "                               [4, 5, 3, 8, 0.6, 0.43],\n",
    "                               [6, 3, 2, 9, 0.12, 0.32],\n",
    "                               [9, 1, 1, 1, 0.12, 0.45],\n",
    "                               [8, 3, 1, 4, 0.21, 0.67]]))\n",
    "\n",
    "user_cate_dict = {'user_id': (11, 0), 'user_list': (12, 3), 'user_num': (1, 4)}\n",
    "item_cate_dict = {'item_id': (8, 1), 'item_cate': (6, 2), 'item_num': (1, 5)}\n",
    "mmoe = MMoE(user_cate_dict, item_cate_dict)\n",
    "mmoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.2559],\n",
       "         [ 0.3708],\n",
       "         [-1.9316],\n",
       "         [ 1.0627],\n",
       "         [-0.3213]], grad_fn=<AddmmBackward>),\n",
       " tensor([[ 0.2990],\n",
       "         [-0.6616],\n",
       "         [ 0.7363],\n",
       "         [-0.4751],\n",
       "         [ 0.6892]], grad_fn=<AddmmBackward>)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = mmoe(a)\n",
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = SummaryWriter(log_dir=\"./log\", comment=\"model info\")\n",
    "# w.add_graph(mmoe, a)\n",
    "# w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 问题\n",
    "1. 如何解决负迁移和跷跷板现象（模型角度）？  \n",
    "答：与MMOE相比，CGC消除了任务的塔式网络与其他任务的特定任务专家之间的连接，使不同类型的专家能够不受干扰地集中精力学习不同的知识\n",
    "2. 如何设计损失函数（损失函数角度）？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型架构\n",
    "说明：多层多任务网络结构中，底层特征抽取结构中，给上层A任务提供的独有专家网络的信号来自于A专家网络和共享网络，但给上层结构提供共享专家网络的信号来源于A+B+共享网络。然后，最后一层连接多塔的结构跟CGC是一样的。PLE采用渐进式分离路由，吸收所有底层专家的信息，提取高层共享知识，逐步分离任务相关参数。  \n",
    "<img src = \"./imgs/ple.png\" width = 500 align=\"middle\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型代码\n",
    "<font color=\"red\">注意</font> ：门控网络的输入输出选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tower(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, drouout=0.5):\n",
    "        super(Tower, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drouout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert_shared(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\\\n",
    "        \n",
    "        super(Expert_shared, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Expert_task1(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Expert_task1, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Expert_task2(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Expert_task2, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Gate_shared(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Gate_shared, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Gate_task1(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Gate_task1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Gate_task2(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Gate_task2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatingNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, input_units, units, num_experts, selectors):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "\n",
    "        self.experts_shared = nn.ModuleList([Expert_shared(input_units, units)\n",
    "                                             for i in range(num_experts)])\n",
    "        self.experts_task1 = nn.ModuleList([Expert_task1(input_units, units)\n",
    "                                            for i in range(num_experts)])\n",
    "        self.experts_task2 = nn.ModuleList([Expert_task2(input_units, units)\n",
    "                                            for i in range(num_experts)])\n",
    "        self.expert_activation = nn.ReLU()\n",
    "\n",
    "        self.gate_shared = Gate_shared(input_units, num_experts * 3)\n",
    "        # B*n*hidden B*Expert*Hiddeng\n",
    "        self.gate_task1 = Gate_task1(input_units, selectors * num_experts)\n",
    "        self.gate_task2 = Gate_task2(input_units, selectors * num_experts)\n",
    "\n",
    "        self.gate_activation = nn.Softmax(dim=-1)\n",
    "        self.units = units\n",
    "        self.num_expers = num_experts\n",
    "\n",
    "    def forward(self, gate_output_shared_final, gate_output_task1_final, gate_output_task2_final):\n",
    "        # expert shared\n",
    "        expert_shared_o = [e(gate_output_shared_final)\n",
    "                           for e in self.experts_shared]\n",
    "        expert_shared_tensors = torch.cat(expert_shared_o, dim=0)\n",
    "        expert_shared_tensors = expert_shared_tensors.view(\n",
    "            -1, self.num_expers, self.units)\n",
    "        expert_shared_tensors = self.expert_activation(expert_shared_tensors)\n",
    "        # expert task1\n",
    "        expert_task1_o = [e(gate_output_task1_final)\n",
    "                          for e in self.experts_task1]\n",
    "        expert_task1_tensors = torch.cat(expert_task1_o, dim=0)\n",
    "        expert_task1_tensors = expert_task1_tensors.view(\n",
    "            -1, self.num_expers, self.units)\n",
    "        expert_task1_tensors = self.expert_activation(expert_task1_tensors)\n",
    "        # expert task2\n",
    "        expert_task2_o = [e(gate_output_task2_final)\n",
    "                          for e in self.experts_task2]\n",
    "        expert_task2_tensors = torch.cat(expert_task2_o, dim=0)\n",
    "        expert_task2_tensors = expert_task2_tensors.view(\n",
    "            -1, self.num_expers, self.units)\n",
    "        expert_task2_tensors = self.expert_activation(expert_task2_tensors)\n",
    "\n",
    "        # gate task1\n",
    "        # 每一个门控接收来自上一门控的输出作为输入：task1 --> task2\n",
    "        gate_output_task1 = self.gate_task1(gate_output_task1_final)\n",
    "        # 获取相对应的权值\n",
    "        gate_output_task1 = self.gate_activation(gate_output_task1)\n",
    "        # 选择向量\n",
    "        gate_expert_output1 = torch.cat(\n",
    "            [expert_shared_tensors, expert_task1_tensors], dim=1)\n",
    "        # 计算加权求和\n",
    "        gate_output_task1 = torch.einsum(\n",
    "            'be,beu ->beu', gate_output_task1, gate_expert_output1)\n",
    "        gate_output_task1 = gate_output_task1.sum(dim=1)\n",
    "        # gate task2\n",
    "        gate_output_task2 = self.gate_task2(gate_output_task2_final)\n",
    "        gate_output_task2 = self.gate_activation(gate_output_task2)\n",
    "\n",
    "        gate_expert_output2 = torch.cat(\n",
    "            [expert_shared_tensors, expert_task2_tensors], dim=1)\n",
    "\n",
    "        gate_output_task2 = torch.einsum(\n",
    "            'be,beu ->beu', gate_output_task2, gate_expert_output2)\n",
    "        gate_output_task2 = gate_output_task2.sum(dim=1)\n",
    "\n",
    "        # gate shared\n",
    "        gate_output_shared = self.gate_shared(gate_output_shared_final)\n",
    "        gate_output_shared = self.gate_activation(gate_output_shared)\n",
    "\n",
    "        gate_expert_output_shared = torch.cat(\n",
    "            [expert_task1_tensors, expert_shared_tensors, expert_task2_tensors], dim=1)\n",
    "\n",
    "        gate_output_shared = torch.einsum(\n",
    "            'be,beu ->beu', gate_output_shared, gate_expert_output_shared)\n",
    "        gate_output_shared = gate_output_shared.sum(dim=1)\n",
    "\n",
    "        return gate_output_shared, gate_output_task1, gate_output_task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLE(nn.Module):\n",
    "\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, hidden_out_size=64, num_experts=8,\n",
    "                 selectors=2):\n",
    "\n",
    "        super(PLE, self).__init__()\n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            Exception(\"用户特征和物品特征不能为空！\")\n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict):\n",
    "            Exception(\"输入数据类型必须为字典类型！\")\n",
    "\n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "\n",
    "        # 共享Embedding(Share bottom)\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "\n",
    "        # 用户特征Embedding编码\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            # 必须为Spase Feature\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # 物品特征\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # 构建独立任务（tower）\n",
    "        # Spase feat + Dense feat\n",
    "        input_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) \\\n",
    "            + (len(self.user_feature_dict) - user_cate_feature_nums) \\\n",
    "            + (len(self.item_feature_dict) - item_cate_feature_nums)\n",
    "        # 实例Multi Layer\n",
    "        self.gate1 = GatingNetwork(\n",
    "            input_size, hidden_out_size, num_experts, selectors)\n",
    "\n",
    "        self.gate2 = GatingNetwork(\n",
    "            hidden_out_size, hidden_out_size, num_experts, selectors)\n",
    "\n",
    "        # 实例Tower\n",
    "        self.towers = nn.ModuleList(\n",
    "            [Tower(hidden_out_size, 1, 16) for _ in range(num_experts)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        user_embed_list, item_embed_list = list(), list()\n",
    "        for user_feature, num in self.user_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                user_embed_list.append(\n",
    "                    getattr(self, user_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                user_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        for item_feature, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_embed_list.append(\n",
    "                    getattr(self, item_feature)(x[:, num[1]].long()))\n",
    "            else:\n",
    "                item_embed_list.append(x[:, num[1]].unsqueeze(1))\n",
    "        # 拼接向量\n",
    "        user_embed = torch.cat(user_embed_list, dim=1)\n",
    "        item_embed = torch.cat(item_embed_list, dim=1)\n",
    "        # hidden_input\n",
    "        hidden = torch.cat([user_embed, item_embed], axis=1).float()\n",
    "\n",
    "        gate_output_shared, gate_output_task1, gate_output_task2 = self.gate1(\n",
    "            hidden, hidden, hidden)\n",
    "        _, task1_o, task2_o = self.gate2(\n",
    "            gate_output_shared, gate_output_task1, gate_output_task2)\n",
    "\n",
    "        final_output = [tower(task) for tower, task in zip(\n",
    "            self.towers, [task1_o, task2_o])]\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PLE(\n",
       "  (user_id): Embedding(11, 128)\n",
       "  (user_list): Embedding(12, 128)\n",
       "  (item_id): Embedding(8, 128)\n",
       "  (item_cate): Embedding(6, 128)\n",
       "  (gate1): GatingNetwork(\n",
       "    (experts_shared): ModuleList(\n",
       "      (0): Expert_shared(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Expert_shared(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Expert_shared(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (3): Expert_shared(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (4): Expert_shared(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (5): Expert_shared(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (6): Expert_shared(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (7): Expert_shared(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (experts_task1): ModuleList(\n",
       "      (0): Expert_task1(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Expert_task1(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Expert_task1(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (3): Expert_task1(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (4): Expert_task1(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (5): Expert_task1(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (6): Expert_task1(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (7): Expert_task1(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (experts_task2): ModuleList(\n",
       "      (0): Expert_task2(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Expert_task2(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Expert_task2(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (3): Expert_task2(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (4): Expert_task2(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (5): Expert_task2(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (6): Expert_task2(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "      (7): Expert_task2(\n",
       "        (fc1): Linear(in_features=514, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (expert_activation): ReLU()\n",
       "    (gate_shared): Gate_shared(\n",
       "      (fc1): Linear(in_features=514, out_features=24, bias=True)\n",
       "    )\n",
       "    (gate_task1): Gate_task1(\n",
       "      (fc1): Linear(in_features=514, out_features=16, bias=True)\n",
       "    )\n",
       "    (gate_task2): Gate_task2(\n",
       "      (fc1): Linear(in_features=514, out_features=16, bias=True)\n",
       "    )\n",
       "    (gate_activation): Softmax(dim=-1)\n",
       "  )\n",
       "  (gate2): GatingNetwork(\n",
       "    (experts_shared): ModuleList(\n",
       "      (0): Expert_shared(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Expert_shared(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Expert_shared(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (3): Expert_shared(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (4): Expert_shared(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (5): Expert_shared(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (6): Expert_shared(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (7): Expert_shared(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (experts_task1): ModuleList(\n",
       "      (0): Expert_task1(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Expert_task1(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Expert_task1(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (3): Expert_task1(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (4): Expert_task1(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (5): Expert_task1(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (6): Expert_task1(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (7): Expert_task1(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (experts_task2): ModuleList(\n",
       "      (0): Expert_task2(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (1): Expert_task2(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (2): Expert_task2(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (3): Expert_task2(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (4): Expert_task2(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (5): Expert_task2(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (6): Expert_task2(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (7): Expert_task2(\n",
       "        (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (expert_activation): ReLU()\n",
       "    (gate_shared): Gate_shared(\n",
       "      (fc1): Linear(in_features=64, out_features=24, bias=True)\n",
       "    )\n",
       "    (gate_task1): Gate_task1(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "    )\n",
       "    (gate_task2): Gate_task2(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "    )\n",
       "    (gate_activation): Softmax(dim=-1)\n",
       "  )\n",
       "  (towers): ModuleList(\n",
       "    (0): Tower(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (1): Tower(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (2): Tower(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (3): Tower(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (4): Tower(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (5): Tower(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (6): Tower(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (7): Tower(\n",
       "      (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc2): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (dropout): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.from_numpy(np.array([[1, 2, 4, 2, 0.5, 0.1],\n",
    "                               [4, 5, 3, 8, 0.6, 0.43],\n",
    "                               [6, 3, 2, 9, 0.12, 0.32],\n",
    "                               [9, 1, 1, 1, 0.12, 0.45],\n",
    "                               [8, 3, 1, 4, 0.21, 0.67]]))\n",
    "\n",
    "user_cate_dict = {'user_id': (11, 0), 'user_list': (12, 3), 'user_num': (1, 4)}\n",
    "item_cate_dict = {'item_id': (8, 1), 'item_cate': (6, 2), 'item_num': (1, 5)}\n",
    "ple = PLE(user_cate_dict, item_cate_dict)\n",
    "ple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.1539],\n",
      "        [0.1186],\n",
      "        [0.1474],\n",
      "        [0.1750],\n",
      "        [0.1511]], grad_fn=<AddmmBackward>), tensor([[ 0.0960],\n",
      "        [ 0.0164],\n",
      "        [ 0.0123],\n",
      "        [ 0.0523],\n",
      "        [-0.0026]], grad_fn=<AddmmBackward>)]\n"
     ]
    }
   ],
   "source": [
    "print(ple(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化\n",
    "# w = SummaryWriter(log_dir=\"./log\", comment=\"model info\")\n",
    "# w.add_graph(ple, a)\n",
    "# w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-f6317e2a0af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_feat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_feat_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# 定义超参数\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "count = 0\n",
    "writer = SummaryWriter(\"../log\", comment=\"mertics\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = PLE(user_feat_dict, item_feat_dict)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fun = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_dataload = DataLoader(train_datasets, batch_size=128, shuffle=True)\n",
    "test_dataload = DataLoader(test_datasets, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d4f2086f5834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0my_train_income_true\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_train_marry_true\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-b0f7d3becf79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0mitem_embed_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# 拼接向量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0muser_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_embed_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mitem_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_embed_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# hidden_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs)):\n",
    "    y_train_income_true = []\n",
    "    y_train_income_predict = []\n",
    "    y_train_marry_true = []\n",
    "    y_train_marry_predict = []\n",
    "    total_loss, count = 0, 0\n",
    "    for x, y1, y2 in train_dataload:\n",
    "        x, y1, y2 = x.to(device), y1.to(device), y2.to(device)\n",
    "        predict = model(x)\n",
    "        y_train_income_true += list(y1.squeeze().cpu().numpy())\n",
    "        y_train_marry_true += list(y2.squeeze().cpu().numpy())\n",
    "\n",
    "        y_train_income_predict += list(\n",
    "            predict[0].squeeze().cpu().detach().numpy())\n",
    "        y_train_marry_predict += list(\n",
    "            predict[1].squeeze().cpu().detach().numpy())\n",
    "\n",
    "        loss1 = loss_fun(predict[0], y1.unsqueeze(1).float())\n",
    "        loss2 = loss_fun(predict[1], y2.unsqueeze(1).float())\n",
    "        loss = loss1 + loss2\n",
    "        # 梯度更新\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss)\n",
    "        count += 1\n",
    "\n",
    "    y1_auc = roc_auc_score(y_train_income_true, y_train_income_predict)\n",
    "    y2_auc = roc_auc_score(y_train_marry_true, y_train_marry_predict)\n",
    "    loss_value = total_loss / count\n",
    "    print(\"Epoch %d train loss is %.3f, y1_auc is %.3f and y2_auc is %.3f\" % (epoch + 1, loss_value,\n",
    "                                                                              y1_auc, y2_auc))\n",
    "    writer.add_scalar(\"Train loss\", loss_value, global_step=epoch + 1)\n",
    "    writer.add_scalar(\"Train_y1_auc\", y1_auc, global_step=epoch + 1)\n",
    "    writer.add_scalar(\"Train_y2_auc\", y2_auc, global_step=epoch + 1)\n",
    "\n",
    "    # 验证\n",
    "    total_eval_loss = 0\n",
    "    model.eval()\n",
    "    count_eval = 0\n",
    "    y_val_income_true = []\n",
    "    y_val_marry_true = []\n",
    "    y_val_income_predict = []\n",
    "    y_val_marry_predict = []\n",
    "    for x, y1, y2 in test_dataload:\n",
    "        x, y1, y2 = x.to(device), y1.to(device), y2.to(device)\n",
    "        predict = model(x)\n",
    "        y_val_income_true += list(y1.squeeze().cpu().numpy())\n",
    "        y_val_marry_true += list(y2.squeeze().cpu().numpy())\n",
    "\n",
    "        y_val_income_predict += list(\n",
    "            predict[0].squeeze().cpu().detach().numpy())\n",
    "        y_val_marry_predict += list(\n",
    "            predict[1].squeeze().cpu().detach().numpy())\n",
    "        loss_1 = loss_fun(predict[0], y1.unsqueeze(1).float())\n",
    "        loss_2 = loss_fun(predict[1], y2.unsqueeze(1).float())\n",
    "        loss = loss_1 + loss_2\n",
    "        total_eval_loss += float(loss)\n",
    "        count_eval += 1\n",
    "\n",
    "    y1_val_auc = roc_auc_score(y_val_income_true, y_val_income_predict)\n",
    "    y2_val_auc = roc_auc_score(y_val_marry_true, y_val_marry_predict)\n",
    "    val_loss_value = total_eval_loss / count_eval\n",
    "    print(\"Epoch %d val loss is %.3f, y1_auc is %.3f and y2_auc is %.3f\" % (epoch + 1, val_loss_value,\n",
    "                                                                            y1_auc, y2_auc))\n",
    "    writer.add_scalar(\"Val loss\", val_loss_value, global_step=epoch + 1)\n",
    "    writer.add_scalar(\"Val_y1_auc\", y1_val_auc, global_step=epoch + 1)\n",
    "    writer.add_scalar(\"Val_y2_auc\", y2_val_auc, global_step=epoch + 1)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Sequential和nn.ModuleList\n",
    "[Pytorch学习（三）： Sequential 和ModuleList学习](https://blog.csdn.net/happyday_d/article/details/85629119?spm=1001.2101.3001.6650.6&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-6.fixedcolumn&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Edefault-6.fixedcolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BCELoss和BCEWithLogitsLoss的区别\n",
    "[BCELoss和BCEWithLogitsLoss](https://blog.csdn.net/qq_22210253/article/details/85222093)\n",
    "\n",
    "$$\n",
    "BCELoss = − n/1∑(y_{n}×lnx_{n}+(1−y_{n})×ln(1−x_{n}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0158, 0.8989, 0.3383],\n",
       "        [0.8715, 0.3984, 0.7840],\n",
       "        [0.4525, 0.0914, 0.8614]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ = torch.rand(3, 3)\n",
    "input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5040, 0.7107, 0.5838],\n",
       "        [0.7051, 0.5983, 0.6865],\n",
       "        [0.6112, 0.5228, 0.7029]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.FloatTensor([[0, 1, 1], [0, 0, 1], [1, 0, 1]])\n",
    "activation = nn.Sigmoid()\n",
    "predict = activation(input_)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6305)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss()\n",
    "loss(predict, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6305)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sigmoid + BCEloss\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "loss(input_, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## einsum函数\n",
    "[一文学会 Pytorch 中的 einsum](https://zhuanlan.zhihu.com/p/361209187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = torch.tensor([[5], [3]])\n",
    "\n",
    "B = torch.tensor([[[0, 1, 0],\n",
    "                   [1, 1, 0],\n",
    "\n",
    "                   [1, 1, 1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.einsum('ij,jkl->ikl', A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = B.permute(1, 0, 2)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(A, C).permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Parameter的使用\n",
    "[pytorch学习笔记（十六）：Parameters](https://blog.csdn.net/qq_43328040/article/details/107761093?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-1.no_search_link&spm=1001.2101.3001.4242.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0.8, 0.2], [0.9, 0.1], [0.2, 0.7],\n",
    "              [0.2, 0.5], [0.2, 0.8], [0.2, 0.8]])\n",
    "b = np.array([[1, 0], [1, 0], [0, 1], [1, 0], [0, 1], [1, 0]])\n",
    "print(metrics.roc_auc_score(b, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = [0.8, 0.9, 0.2, 0.2, 0.2, 0.2]\n",
    "b1 = [1, 1, 0, 1, 1, 0]\n",
    "print(metrics.roc_auc_score(b1, a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = [0.2, 0.1, 0.7, 0.5, 0.8, 0.8]\n",
    "b2 = [0, 0, 1, 0, 1, 0]\n",
    "print(metrics.roc_auc_score(b2, a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 教学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat2 = [\"male\", \"famale\"]\n",
    "feat1 = [\"small\", \"large\", \"mid\", \"samler\", \"larger\"]\n",
    "\n",
    "dense1 = [178, 155]\n",
    "\n",
    "smaple = [\"feat0\":male, \"feat1\":mid, \"dense1\":178]\n",
    "\n",
    "# 预处理 str->int\n",
    "# 编码：labelecode\n",
    "# multi_onehot\n",
    "# feat: {A, B}\n",
    "[1, 1, 0, 0, 0, 0...]\n",
    "{A}\n",
    "samlpe_pro = [0, 3, 0.8]\n",
    "\n",
    "smaple = [[1.1, 1.5, 6.3], [1.2, 0.4, 0.3], [8.6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = LabelEncoder()\n",
    "feat_ecode = la.fit_transform(feat)\n",
    "feat_ecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(5, 3)  # 定义一个具有5个单词，维度为3的查询矩阵\n",
    "print(embedding.weight)  # 展示该矩阵的具体内容\n",
    "test = torch.LongTensor(feat_ecode)  # 该test矩阵用于被embed，其size为[2, 4]\n",
    "# 其中的第一行为[0, 2, 0, 1]，表示获取查询矩阵中ID为0, 2, 0, 1的查询向量\n",
    "# 可以在之后的test输出中与embed的输出进行比较\n",
    "test = embedding(test[0])\n",
    "print(\"Embedding：\")\n",
    "print(test.size())  # 输出embed后test的size，为[2, 4, 3]，增加\n",
    "# 的3，是因为查询向量的维度为3\n",
    "print(test)  # 输出embed后的test的内容a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
