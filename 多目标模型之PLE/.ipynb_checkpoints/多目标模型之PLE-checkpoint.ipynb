{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多目标模型之PLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tower(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, drouout=0.4):\n",
    "        super(Tower, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropoutd(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tower(\n",
       "  (fc1): Linear(in_features=4, out_features=4, bias=True)\n",
       "  (fc2): Linear(in_features=4, out_features=5, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tower(4, 5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建各个专家子网络和共享网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert_shared(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Expert_shared, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Expert_task1(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Expert_task1, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Expert_task2(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Expert_task2, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Gate_shared(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Gate_shared, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Gate_task1(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Gate_task1, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class Gate_task2(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Gate_task2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, output_shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatingNetwork:\n",
    "\n",
    "    def __init__(self, input_units, units, num_experts, selectors):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "\n",
    "        self.experts_shared = nn.ModuleList([Expert_shared(input_units, units)\n",
    "                                             for i in range(num_experts)])\n",
    "        self.experts_task1 = nn.ModuleList([Expert_task1(input_units, units)\n",
    "                                            for i in range(num_experts)])\n",
    "        self.experts_task2 = nn.ModuleList([Expert_task2(input_units, units)\n",
    "                                            for i in range(num_experts)])\n",
    "        self.expert_activation = nn.ReLU()\n",
    "\n",
    "        self.gate_shared = Gate_shared(input_units, num_experts*3)\n",
    "        self.gate_task1 = Gate_task1(input_units, selectors*num_experts)\n",
    "        self.gate_task2 = Gate_task2(input_units, selectors*num_experts)\n",
    "\n",
    "        self.gate_activation = nn.Softmax(dim=-1)\n",
    "        self.units = units\n",
    "        self.num_expers = num_experts\n",
    "\n",
    "    def forward(self, gate_output_shared_final, gate_output_task1_final, gate_output_task2_final):\n",
    "\n",
    "        # expert shared\n",
    "        expert_shared_o = [e(gate_output_shared_final)\n",
    "                           for e in self.experts_shared]\n",
    "        expert_shared_tensors = torch.cat(expert_shared_o, dim=0)\n",
    "        expert_shared_tensors = expert_shared_tensors.view(\n",
    "            -1, self.num_expers, self.units)\n",
    "        expert_shared_tensors = self.expert_activation(expert_shared_tensors)\n",
    "        # expert task1\n",
    "        expert_task1_o = [e(gate_output_task1_final)\n",
    "                          for e in self.experts_task1]\n",
    "        expert_task1_tensors = torch.cat(expert_task1_o, dim=0)\n",
    "        expert_task1_tensors = expert_task1_tensors.view(\n",
    "            -1, self.num_expers, self.units)\n",
    "        expert_task1_tensors = self.expert_activation(expert_task1_tensors)\n",
    "        # expert task2\n",
    "        expert_task2_o = [e(gate_output_task2_final)\n",
    "                          for e in self.experts_task2]\n",
    "        expert_task2_tensors = torch.cat(expert_task2_o, dim=0)\n",
    "        expert_task2_tensors = expert_task2_tensors.view(\n",
    "            -1, self.num_expers, self.units)\n",
    "        expert_task2_tensors = self.expert_activation(expert_task2_tensors)\n",
    "\n",
    "        # gate task1\n",
    "        gate_output_task1 = self.gate_task1(gate_output_task1_final)\n",
    "        gate_output_task1 = self.gate_activation(gate_output_task1)\n",
    "\n",
    "        gate_expert_output1 = torch.cat(\n",
    "            [expert_shared_tensors, expert_task1_tensors], dim=1)\n",
    "        # B*experts *  B*experts*units\n",
    "        gate_output_task1 = torch.einsum(\n",
    "            'be,beu ->beu', gate_output_task1, gate_expert_output1)\n",
    "        gate_output_task1 = gate_output_task1.sum(dim=1)\n",
    "        \n",
    "        # gate task2\n",
    "        gate_output_task2 = self.gate_task2(gate_output_task2_final)\n",
    "        gate_output_task2 = self.gate_activation(gate_output_task2)\n",
    "\n",
    "        gate_expert_output2 = torch.cat(\n",
    "            [expert_shared_tensors, expert_task2_tensors], dim=1)\n",
    "\n",
    "        gate_output_task2 = torch.einsum(\n",
    "            'be,beu ->beu', gate_output_task2, gate_expert_output2)\n",
    "        gate_output_task2 = gate_output_task2.sum(dim=1)\n",
    "        \n",
    "        # gate shared\n",
    "        gate_output_shared = self.gate_shared(gate_output_shared_final)\n",
    "        gate_output_shared = self.gate_activation(gate_output_shared)\n",
    "\n",
    "        gate_expert_output_shared = torch.cat(\n",
    "            [expert_task1_tensors, expert_shared_tensors, expert_task2_tensors], dim=1)\n",
    "\n",
    "        gate_output_shared = torch.einsum(\n",
    "            'be,beu ->beu', gate_output_shared, gate_expert_output_shared)\n",
    "        gate_output_shared = gate_output_shared.sum(dim=1)\n",
    "\n",
    "        return gate_output_shared, gate_output_task1, gate_output_task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.GatingNetwork at 0x7f4658967730>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GatingNetwork(5, 6, 3, 3)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-2410405460c5>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-2410405460c5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    class PLE(nn.Module)\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class PLE(nn.Module):\n",
    "\n",
    "    def __init__(self, user_feature_dict, item_feature_dict, emb_dim=128, hidden_out_size=128, num_experts=2, selectors=2):\n",
    "        \n",
    "        if user_feature_dict is None or item_feature_dict is None:\n",
    "            Exception(\"用户特征和物品特征不能为空！\")\n",
    "        if isinstance(user_feature_dict, dict) is False or isinstance(item_feature_dict, dict):\n",
    "            Exception(\"输入数据类型必须为字典类型！\")\n",
    "\n",
    "        self.user_feature_dict = user_feature_dict\n",
    "        self.item_feature_dict = item_feature_dict\n",
    "\n",
    "        # 共享Embedding(Share bottom)\n",
    "        user_cate_feature_nums, item_cate_feature_nums = 0, 0\n",
    "\n",
    "        # 用户特征Embedding编码\n",
    "        for user_cate, num in self.user_feature_dict.items():\n",
    "            # 必须为Spase Feature\n",
    "            if num[0] > 1:\n",
    "                user_cate_feature_nums += 1\n",
    "                setattr(self, user_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # 物品特征\n",
    "        for item_cate, num in self.item_feature_dict.items():\n",
    "            if num[0] > 1:\n",
    "                item_cate_feature_nums += 1\n",
    "                setattr(self, item_cate, nn.Embedding(num[0], emb_dim))\n",
    "\n",
    "        # 构建独立任务（tower）\n",
    "        # Spase feat + Dense feat\n",
    "        input_size = emb_dim * (user_cate_feature_nums + item_cate_feature_nums) \\\n",
    "            + (len(self.user_feature_dict) - user_cate_feature_nums) \\\n",
    "            + (len(self.item_feature_dict) - item_cate_feature_nums)\n",
    "        # 实例Multi Layer\n",
    "        self.gate1 = GatingNetwork(input_size, hidden_out_size, num_experts, selectors)\n",
    "        self.gate1 = GatingNetwork(hidden_out_size, hidden_out_size, num_experts, selectors)\n",
    "        \n",
    "        # 实例Tower\n",
    "        self.tower = nn.ModuleList([Tower(hidden_out_size, 1, )])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算加权求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8654, 0.1746, 0.0825, 0.7956],\n",
       "         [0.2113, 0.0699, 0.1199, 0.3511]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(1, 2, 4)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2753, 0.0556, 0.0262, 0.2531],\n",
       "         [0.1834, 0.0607, 0.1041, 0.3049]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.einsum('be,beu ->beu', a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4587, 0.1163, 0.1303, 0.5580]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27528374"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3181*0.8654"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05554026"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3181*0.1746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
